{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "twenty-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "{\n",
      "    \"Session_Status\": {\n",
      "        \"active\": \"In Progress\",\n",
      "        \"budget_left_until_checkpoint\": 77,\n",
      "        \"budget_used\": 408,\n",
      "        \"current_dataset\": {\n",
      "            \"classes\": [\n",
      "                \"push\",\n",
      "                \"cartwheel\",\n",
      "                \"dribble\",\n",
      "                \"pullup\",\n",
      "                \"jump\",\n",
      "                \"shoot_gun\",\n",
      "                \"smile\",\n",
      "                \"dive\",\n",
      "                \"shake_hands\",\n",
      "                \"draw_sword\",\n",
      "                \"fencing\",\n",
      "                \"climb\",\n",
      "                \"clap\",\n",
      "                \"kick_ball\",\n",
      "                \"sword_exercise\",\n",
      "                \"pour\",\n",
      "                \"punch\",\n",
      "                \"walk\",\n",
      "                \"sit\",\n",
      "                \"brush_hair\",\n",
      "                \"shoot_ball\",\n",
      "                \"ride_horse\",\n",
      "                \"throw\",\n",
      "                \"pick\",\n",
      "                \"smoke\",\n",
      "                \"pushup\",\n",
      "                \"wave\",\n",
      "                \"golf\",\n",
      "                \"kick\",\n",
      "                \"hit\",\n",
      "                \"hug\",\n",
      "                \"handstand\",\n",
      "                \"catch\",\n",
      "                \"fall_floor\",\n",
      "                \"shoot_bow\",\n",
      "                \"sword\",\n",
      "                \"situp\",\n",
      "                \"talk\",\n",
      "                \"kiss\",\n",
      "                \"somersault\",\n",
      "                \"swing_baseball\",\n",
      "                \"flic_flac\",\n",
      "                \"stand\",\n",
      "                \"run\",\n",
      "                \"laugh\",\n",
      "                \"eat\",\n",
      "                \"ride_bike\",\n",
      "                \"turn\",\n",
      "                \"climb_stairs\",\n",
      "                \"chew\",\n",
      "                \"drink\"\n",
      "            ],\n",
      "            \"dataset_type\": \"video_classification\",\n",
      "            \"license_citation\": \"Kuehne, Hildegard, Hueihan Jhuang, Est\\u00edbaliz Garrote, Tomaso Poggio, and Thomas Serre. \\\"HMDB: a large video database for human motion recognition.\\\" In 2011 International conference on computer vision, pp. 2556-2563. IEEE, 2011.\",\n",
      "            \"license_link\": \"https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads\",\n",
      "            \"license_requirements\": \"None\",\n",
      "            \"name\": \"hmdb\",\n",
      "            \"number_of_channels\": 1,\n",
      "            \"number_of_classes\": 51,\n",
      "            \"number_of_samples_test\": 100,\n",
      "            \"number_of_samples_train\": 816,\n",
      "            \"uid\": \"hmdb\"\n",
      "        },\n",
      "        \"current_label_budget_stages\": [\n",
      "            51,\n",
      "            102,\n",
      "            204,\n",
      "            408,\n",
      "            485,\n",
      "            577,\n",
      "            686,\n",
      "            816\n",
      "        ],\n",
      "        \"date_created\": 1616506441000,\n",
      "        \"date_last_interacted\": 1616506445557,\n",
      "        \"pair_stage\": \"base\",\n",
      "        \"session_name\": \"reproduce_error\",\n",
      "        \"task_id\": \"problem_test_video_classification\",\n",
      "        \"uid\": \"nb3EgysQsPKFHkQ6jEUD\",\n",
      "        \"user_name\": \"Brown\",\n",
      "        \"using_sample_datasets\": true\n",
      "    }\n",
      "}\n",
      "budget_left is 77\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Failed to open local file '/lwll/external/hmdb/labels_sample/meta_train.feather'. Detail: [errno 2] No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f0211613e30b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mimages_to_be_labeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_labels_from_train_dataset_vid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASETS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;31m#images_to_be_labeled = ['426597.jpg', '444854.jpg', '293426.jpg', '394143.jpg', '475104.jpg', '466700.jpg', '434541.jpg', '403310.jpg', '463886.jpg', '419271.jpg', '499764.jpg', '383900.jpg', '473090.jpg', '351779.jpg', '397958.jpg', '351810.jpg', '322990.jpg', '393386.jpg', '482671.jpg', '505782.jpg', '353192.jpg', '405677.jpg', '327915.jpg', '312268.jpg', '411502.jpg', '463282.jpg', '488973.jpg', '330913.jpg', '418090.jpg', '450558.jpg', '406777.jpg', '381549.jpg', '487051.jpg', '463913.jpg', '453865.jpg', '478428.jpg', '394477.jpg', '305002.jpg', '485933.jpg', '254062.jpg', '322078.jpg', '431623.jpg', '171340.jpg', '469255.jpg', '412119.jpg', '392331.jpg', '409253.jpg', '305048.jpg', '378614.jpg', '492679.jpg', '384504.jpg', '390812.jpg', '352550.jpg', '485559.jpg', '455513.jpg', '321446.jpg', '317903.jpg', '408780.jpg', '473579.jpg', '467482.jpg', '334252.jpg', '403188.jpg', '486968.jpg', '400517.jpg', '343077.jpg', '485851.jpg', '412094.jpg', '484619.jpg', '381466.jpg', '506106.jpg', '485837.jpg', '501087.jpg', '398532.jpg', '454979.jpg', '321680.jpg', '503566.jpg', '426574.jpg']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f0211613e30b>\u001b[0m in \u001b[0;36mget_random_labels_from_train_dataset_vid\u001b[0;34m(dataset_path, session_token, n, data_type)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mmeta_train_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{current_dataset_name}/labels_{data_type}/meta_train.feather\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mmeta_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_train_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mrandom_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrandom_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pandas/io/feather_format.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(path, columns, use_threads)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthreads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint_use_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeather\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_feather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36mread_feather\u001b[0;34m(source, columns, use_threads)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatherReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/feather.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0m_check_pandas_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/feather.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.FeatherReader.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.get_reader\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib._get_native_file\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.memory_map\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/io.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.MemoryMappedFile._open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/cris/cristina/lib/python3.8/site-packages/pyarrow/error.pxi\u001b[0m in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Failed to open local file '/lwll/external/hmdb/labels_sample/meta_train.feather'. Detail: [errno 2] No such file or directory"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "import random\n",
    "import torch\n",
    "\n",
    "\n",
    "def get_test_images_and_classes_vid(dataset_path: Path, session_token: str, data_type: str='sample') -> Tuple[List[str],List[str]]:\n",
    "    \"\"\"\n",
    "    Helper method to dynamically get the test labels and give us the possible classes that can be submitted\n",
    "    for the current dataset\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    \n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` dataset. \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Tuple[List[str], List[str]]\n",
    "        The list of test image ids needed to submit a prediction and the list of class names that you can predict against\n",
    "    \"\"\"\n",
    "    # Then we can just reference our current metadata to get our dataset name and use that in the path\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    current_dataset_classes = current_dataset['classes']\n",
    "\n",
    "    test_meta = pd.read_feather(dataset_path.joinpath(f\"{current_dataset_name}/labels_{data_type}/meta_test.feather\"))\n",
    "    test_ids = test_meta['id'].tolist()\n",
    "    return test_ids, current_dataset_classes\n",
    "\n",
    "\n",
    "\n",
    "def generate_random_predictions_on_test_set(test_imgs: List[str], current_dataset_classes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a prediction dataframe for image classification based on random sampling from our available classes\n",
    "    \"\"\"\n",
    "    rand_lbls = [str(random.choice(current_dataset_classes)) for _ in range(len(test_imgs))]\n",
    "    df = pd.DataFrame({'id': test_imgs, 'class': rand_lbls})\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_random_labels_from_train_dataset_vid(dataset_path: Path, session_token: str, n: int=None, data_type: str='sample') -> List[str]:\n",
    "    \"\"\"\n",
    "    Helper function to get random `n` video segment ids from our train dataset to request labels for\n",
    "    from the api\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` size dataset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    List[str]\n",
    "        A list of n unique image ids for the current session dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    budget_left = r.json()['Session_Status']['budget_left_until_checkpoint'] \n",
    "    if not n:\n",
    "        n = budget_left\n",
    "        \n",
    "        print(f\"budget_left is {budget_left}\")\n",
    "      \n",
    "    meta_train_path = dataset_path.joinpath(f\"{current_dataset_name}/labels_{data_type}/meta_train.feather\")\n",
    "    meta_train = pd.read_feather(meta_train_path)\n",
    "    random_ids = meta_train['id'].sample(n=n).tolist()\n",
    "    return random_ids\n",
    "\n",
    "\n",
    "\n",
    "secret = 'a5aed2a8-db80-4b22-bf72-11f2d0765572'# my-group-secret (Brown)\n",
    "gov_secret = 'mock-secret'\n",
    "url = 'https://api-dev.lollllz.com'\n",
    "\n",
    "headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "\n",
    "# This is a convenience for development purposes, IN EVAL ALWAYS USE `full`\n",
    "data_type = 'sample' # can either be `sample` or `full`\n",
    "\n",
    "r = requests.post(f\"{url}/auth/create_session\", json={'session_name': 'reproduce_error', 'data_type': data_type, 'task_id': 'problem_test_video_classification'}, headers=headers)\n",
    "r.json()\n",
    "session_token = r.json()['session_token']\n",
    "\n",
    "\n",
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/seed_labels\", headers=headers)\n",
    "\n",
    "\n",
    "DATASETS_PATH = Path.home().joinpath('/lwll/external')\n",
    "test_ids, current_dataset_classes = get_test_images_and_classes_vid(dataset_path=DATASETS_PATH, session_token=session_token, data_type='sample')\n",
    "df = generate_random_predictions_on_test_set(test_ids, current_dataset_classes)\n",
    "\n",
    "\n",
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    print(i+1)\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "    r = requests.get(f\"{url}/seed_labels\", headers=headers)\n",
    "    r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "print(json.dumps(r.json(), indent=4))\n",
    "\n",
    "images_to_be_labeled = get_random_labels_from_train_dataset_vid(DATASETS_PATH, session_token)\n",
    "\n",
    "#images_to_be_labeled = ['426597.jpg', '444854.jpg', '293426.jpg', '394143.jpg', '475104.jpg', '466700.jpg', '434541.jpg', '403310.jpg', '463886.jpg', '419271.jpg', '499764.jpg', '383900.jpg', '473090.jpg', '351779.jpg', '397958.jpg', '351810.jpg', '322990.jpg', '393386.jpg', '482671.jpg', '505782.jpg', '353192.jpg', '405677.jpg', '327915.jpg', '312268.jpg', '411502.jpg', '463282.jpg', '488973.jpg', '330913.jpg', '418090.jpg', '450558.jpg', '406777.jpg', '381549.jpg', '487051.jpg', '463913.jpg', '453865.jpg', '478428.jpg', '394477.jpg', '305002.jpg', '485933.jpg', '254062.jpg', '322078.jpg', '431623.jpg', '171340.jpg', '469255.jpg', '412119.jpg', '392331.jpg', '409253.jpg', '305048.jpg', '378614.jpg', '492679.jpg', '384504.jpg', '390812.jpg', '352550.jpg', '485559.jpg', '455513.jpg', '321446.jpg', '317903.jpg', '408780.jpg', '473579.jpg', '467482.jpg', '334252.jpg', '403188.jpg', '486968.jpg', '400517.jpg', '343077.jpg', '485851.jpg', '412094.jpg', '484619.jpg', '381466.jpg', '506106.jpg', '485837.jpg', '501087.jpg', '398532.jpg', '454979.jpg', '321680.jpg', '503566.jpg', '426574.jpg']\n",
    "\n",
    "query = {\n",
    "    'example_ids': images_to_be_labeled\n",
    "}\n",
    "\n",
    "r = requests.post(f\"{url}/query_labels\", json=query, headers=headers)\n",
    "len(r.json()['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "important-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'sample'\n",
    "\n",
    "DATASETS_PATH = Path.home().joinpath('/lwll/external')\n",
    "meta_train_path = DATASETS_PATH.joinpath(f\"hmdb/labels_{data_type}/meta_test.feather\")\n",
    "meta_train = pd.read_feather(meta_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "civic-celebrity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "      <th>start_frame</th>\n",
       "      <th>end_frame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5503</td>\n",
       "      <td>5503</td>\n",
       "      <td>514892</td>\n",
       "      <td>514971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5855</td>\n",
       "      <td>5855</td>\n",
       "      <td>546636</td>\n",
       "      <td>546694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6188</td>\n",
       "      <td>6188</td>\n",
       "      <td>577992</td>\n",
       "      <td>578139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5894</td>\n",
       "      <td>5894</td>\n",
       "      <td>549850</td>\n",
       "      <td>549930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6485</td>\n",
       "      <td>6485</td>\n",
       "      <td>604761</td>\n",
       "      <td>605087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6138</td>\n",
       "      <td>6138</td>\n",
       "      <td>573674</td>\n",
       "      <td>573751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5513</td>\n",
       "      <td>5513</td>\n",
       "      <td>515867</td>\n",
       "      <td>516215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6521</td>\n",
       "      <td>6521</td>\n",
       "      <td>608567</td>\n",
       "      <td>608590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6095</td>\n",
       "      <td>6095</td>\n",
       "      <td>569428</td>\n",
       "      <td>569506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6427</td>\n",
       "      <td>6427</td>\n",
       "      <td>598658</td>\n",
       "      <td>598736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  video_id  start_frame  end_frame\n",
       "0   5503      5503       514892     514971\n",
       "1   5855      5855       546636     546694\n",
       "2   6188      6188       577992     578139\n",
       "3   5894      5894       549850     549930\n",
       "4   6485      6485       604761     605087\n",
       "..   ...       ...          ...        ...\n",
       "95  6138      6138       573674     573751\n",
       "96  5513      5513       515867     516215\n",
       "97  6521      6521       608567     608590\n",
       "98  6095      6095       569428     569506\n",
       "99  6427      6427       598658     598736\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "seventh-compound",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thousand-sequence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "centered-juice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "governing-description",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': ['06023f86-a66b-4b2c-8b8b-951f5edd0f22',\n",
       "  '4d924004-347e-4043-8dd2-f4f8b0f52efd',\n",
       "  '6d5e1f85-5d8f-4cc9-8184-299db03713f4',\n",
       "  '7c103ece-fd8e-483b-bede-b55e5ea57fe9',\n",
       "  '923cbe9c-1e4f-4a05-a156-dc972ef5edf5',\n",
       "  'b01a6738-0b85-46c2-9318-16c3e2ef0f6d',\n",
       "  'bbfadb2c-c7c3-4596-b548-3dd01a6d1d2c',\n",
       "  'd48f8a99-ba12-4df8-a74a-d06413b0f1ba',\n",
       "  'problem_test_image_classification',\n",
       "  'problem_test_obj_detection',\n",
       "  'problem_test_video_classification']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spoken-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "biological-impact",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.json()['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "behind-oasis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "threaded-cloud",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optimum-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 51,\n",
       "  'budget_used': 51,\n",
       "  'current_dataset': {'classes': ['shoot_ball',\n",
       "    'somersault',\n",
       "    'stand',\n",
       "    'smile',\n",
       "    'pour',\n",
       "    'climb_stairs',\n",
       "    'flic_flac',\n",
       "    'situp',\n",
       "    'golf',\n",
       "    'pick',\n",
       "    'draw_sword',\n",
       "    'smoke',\n",
       "    'clap',\n",
       "    'walk',\n",
       "    'dribble',\n",
       "    'talk',\n",
       "    'pushup',\n",
       "    'fall_floor',\n",
       "    'catch',\n",
       "    'sword',\n",
       "    'kick_ball',\n",
       "    'cartwheel',\n",
       "    'punch',\n",
       "    'sword_exercise',\n",
       "    'shoot_bow',\n",
       "    'brush_hair',\n",
       "    'push',\n",
       "    'wave',\n",
       "    'eat',\n",
       "    'hug',\n",
       "    'swing_baseball',\n",
       "    'ride_horse',\n",
       "    'throw',\n",
       "    'run',\n",
       "    'sit',\n",
       "    'pullup',\n",
       "    'dive',\n",
       "    'turn',\n",
       "    'climb',\n",
       "    'chew',\n",
       "    'handstand',\n",
       "    'hit',\n",
       "    'laugh',\n",
       "    'kiss',\n",
       "    'drink',\n",
       "    'ride_bike',\n",
       "    'shake_hands',\n",
       "    'kick',\n",
       "    'fencing',\n",
       "    'jump',\n",
       "    'shoot_gun'],\n",
       "   'dataset_type': 'video_classification',\n",
       "   'license_citation': 'Kuehne, Hildegard, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre. \"HMDB: a large video database for human motion recognition.\" In 2011 International conference on computer vision, pp. 2556-2563. IEEE, 2011.',\n",
       "   'license_link': 'https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'hmdb',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 51,\n",
       "   'number_of_samples_test': 100,\n",
       "   'number_of_samples_train': 816,\n",
       "   'uid': 'hmdb'},\n",
       "  'current_label_budget_stages': [51, 102, 204, 408, 485, 577, 686, 816],\n",
       "  'date_created': 1616457974000,\n",
       "  'date_last_interacted': 1616457975989,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'reproduce_error',\n",
       "  'task_id': 'problem_test_video_classification',\n",
       "  'uid': '8JKYCv3FoPcG5RUetrw4',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "documented-walker",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "solved-johnston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "magnetic-assumption",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_to_be_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "structural-hospital",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': 'run',\n",
       "   'end_frame': 463335,\n",
       "   'id': 4942,\n",
       "   'start_frame': 463256,\n",
       "   'video_id': 4942},\n",
       "  {'class': 'draw_sword',\n",
       "   'end_frame': 473661,\n",
       "   'id': 5061,\n",
       "   'start_frame': 473564,\n",
       "   'video_id': 5061},\n",
       "  {'class': 'ride_horse',\n",
       "   'end_frame': 383912,\n",
       "   'id': 4112,\n",
       "   'start_frame': 383730,\n",
       "   'video_id': 4112},\n",
       "  {'class': 'pour',\n",
       "   'end_frame': 305109,\n",
       "   'id': 3273,\n",
       "   'start_frame': 304785,\n",
       "   'video_id': 3273},\n",
       "  {'class': 'pullup',\n",
       "   'end_frame': 419317,\n",
       "   'id': 4497,\n",
       "   'start_frame': 419239,\n",
       "   'video_id': 4497},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 487224,\n",
       "   'id': 5206,\n",
       "   'start_frame': 486865,\n",
       "   'video_id': 5206},\n",
       "  {'class': 'throw',\n",
       "   'end_frame': 381552,\n",
       "   'id': 4086,\n",
       "   'start_frame': 381398,\n",
       "   'video_id': 4086},\n",
       "  {'class': 'eat',\n",
       "   'end_frame': 492716,\n",
       "   'id': 5268,\n",
       "   'start_frame': 492615,\n",
       "   'video_id': 5268},\n",
       "  {'class': 'pour',\n",
       "   'end_frame': 317909,\n",
       "   'id': 3398,\n",
       "   'start_frame': 317694,\n",
       "   'video_id': 3398},\n",
       "  {'class': 'somersault',\n",
       "   'end_frame': 411578,\n",
       "   'id': 4400,\n",
       "   'start_frame': 411499,\n",
       "   'video_id': 4400},\n",
       "  {'class': 'smoke',\n",
       "   'end_frame': 503775,\n",
       "   'id': 5384,\n",
       "   'start_frame': 503492,\n",
       "   'video_id': 5384},\n",
       "  {'class': 'fencing',\n",
       "   'end_frame': 353440,\n",
       "   'id': 3768,\n",
       "   'start_frame': 353142,\n",
       "   'video_id': 3768},\n",
       "  {'class': 'jump',\n",
       "   'end_frame': 467485,\n",
       "   'id': 4988,\n",
       "   'start_frame': 467445,\n",
       "   'video_id': 4988},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 487224,\n",
       "   'id': 5206,\n",
       "   'start_frame': 486865,\n",
       "   'video_id': 5206},\n",
       "  {'class': 'shoot_bow',\n",
       "   'end_frame': 312452,\n",
       "   'id': 3346,\n",
       "   'start_frame': 312213,\n",
       "   'video_id': 3346},\n",
       "  {'class': 'shake_hands',\n",
       "   'end_frame': 412134,\n",
       "   'id': 4408,\n",
       "   'start_frame': 412057,\n",
       "   'video_id': 4408},\n",
       "  {'class': 'swing_baseball',\n",
       "   'end_frame': 406848,\n",
       "   'id': 4350,\n",
       "   'start_frame': 406734,\n",
       "   'video_id': 4350},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 378830,\n",
       "   'id': 4058,\n",
       "   'start_frame': 378545,\n",
       "   'video_id': 4058},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 485951,\n",
       "   'id': 5190,\n",
       "   'start_frame': 485486,\n",
       "   'video_id': 5190},\n",
       "  {'class': 'ride_horse',\n",
       "   'end_frame': 384569,\n",
       "   'id': 4119,\n",
       "   'start_frame': 384460,\n",
       "   'video_id': 4119},\n",
       "  {'class': 'jump',\n",
       "   'end_frame': 484646,\n",
       "   'id': 5180,\n",
       "   'start_frame': 484593,\n",
       "   'video_id': 5180},\n",
       "  {'class': 'kiss',\n",
       "   'end_frame': 394602,\n",
       "   'id': 4223,\n",
       "   'start_frame': 394384,\n",
       "   'video_id': 4223},\n",
       "  {'class': 'shoot_gun',\n",
       "   'end_frame': 450642,\n",
       "   'id': 4803,\n",
       "   'start_frame': 450545,\n",
       "   'video_id': 4803},\n",
       "  {'class': 'shake_hands',\n",
       "   'end_frame': 412134,\n",
       "   'id': 4408,\n",
       "   'start_frame': 412057,\n",
       "   'video_id': 4408},\n",
       "  {'class': 'golf',\n",
       "   'end_frame': 408832,\n",
       "   'id': 4370,\n",
       "   'start_frame': 408755,\n",
       "   'video_id': 4370},\n",
       "  {'class': 'throw',\n",
       "   'end_frame': 381552,\n",
       "   'id': 4086,\n",
       "   'start_frame': 381398,\n",
       "   'video_id': 4086},\n",
       "  {'class': 'jump',\n",
       "   'end_frame': 397960,\n",
       "   'id': 4262,\n",
       "   'start_frame': 397915,\n",
       "   'video_id': 4262},\n",
       "  {'class': 'situp',\n",
       "   'end_frame': 478457,\n",
       "   'id': 5104,\n",
       "   'start_frame': 478379,\n",
       "   'video_id': 5104},\n",
       "  {'class': 'smoke',\n",
       "   'end_frame': 321458,\n",
       "   'id': 3428,\n",
       "   'start_frame': 321334,\n",
       "   'video_id': 3428},\n",
       "  {'class': 'eat',\n",
       "   'end_frame': 489021,\n",
       "   'id': 5228,\n",
       "   'start_frame': 488919,\n",
       "   'video_id': 5228},\n",
       "  {'class': 'brush_hair',\n",
       "   'end_frame': 351848,\n",
       "   'id': 3751,\n",
       "   'start_frame': 351491,\n",
       "   'video_id': 3751},\n",
       "  {'class': 'brush_hair',\n",
       "   'end_frame': 390846,\n",
       "   'id': 4184,\n",
       "   'start_frame': 390691,\n",
       "   'video_id': 4184},\n",
       "  {'class': 'brush_hair',\n",
       "   'end_frame': 351848,\n",
       "   'id': 3751,\n",
       "   'start_frame': 351491,\n",
       "   'video_id': 3751},\n",
       "  {'class': 'ride_horse',\n",
       "   'end_frame': 466757,\n",
       "   'id': 4978,\n",
       "   'start_frame': 466668,\n",
       "   'video_id': 4978},\n",
       "  {'class': 'walk',\n",
       "   'end_frame': 455599,\n",
       "   'id': 4858,\n",
       "   'start_frame': 455493,\n",
       "   'video_id': 4858},\n",
       "  {'class': 'pour',\n",
       "   'end_frame': 305109,\n",
       "   'id': 3273,\n",
       "   'start_frame': 304785,\n",
       "   'video_id': 3273},\n",
       "  {'class': 'jump',\n",
       "   'end_frame': 293430,\n",
       "   'id': 3153,\n",
       "   'start_frame': 293389,\n",
       "   'video_id': 3153},\n",
       "  {'class': 'talk',\n",
       "   'end_frame': 403396,\n",
       "   'id': 4318,\n",
       "   'start_frame': 403178,\n",
       "   'video_id': 4318},\n",
       "  {'class': 'throw',\n",
       "   'end_frame': 473127,\n",
       "   'id': 5054,\n",
       "   'start_frame': 473018,\n",
       "   'video_id': 5054},\n",
       "  {'class': 'climb_stairs',\n",
       "   'end_frame': 409263,\n",
       "   'id': 4374,\n",
       "   'start_frame': 409189,\n",
       "   'video_id': 4374},\n",
       "  {'class': 'talk',\n",
       "   'end_frame': 394152,\n",
       "   'id': 4219,\n",
       "   'start_frame': 394012,\n",
       "   'video_id': 4219},\n",
       "  {'class': 'fall_floor',\n",
       "   'end_frame': 321710,\n",
       "   'id': 3432,\n",
       "   'start_frame': 321665,\n",
       "   'video_id': 3432},\n",
       "  {'class': 'eat',\n",
       "   'end_frame': 352611,\n",
       "   'id': 3760,\n",
       "   'start_frame': 352486,\n",
       "   'video_id': 3760},\n",
       "  {'class': 'sit',\n",
       "   'end_frame': 506140,\n",
       "   'id': 5405,\n",
       "   'start_frame': 506069,\n",
       "   'video_id': 5405},\n",
       "  {'class': 'talk',\n",
       "   'end_frame': 403396,\n",
       "   'id': 4318,\n",
       "   'start_frame': 403178,\n",
       "   'video_id': 4318},\n",
       "  {'class': 'run',\n",
       "   'end_frame': 323045,\n",
       "   'id': 3450,\n",
       "   'start_frame': 322973,\n",
       "   'video_id': 3450},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 505828,\n",
       "   'id': 5401,\n",
       "   'start_frame': 505657,\n",
       "   'video_id': 5401},\n",
       "  {'class': 'dive',\n",
       "   'end_frame': 405950,\n",
       "   'id': 4340,\n",
       "   'start_frame': 405529,\n",
       "   'video_id': 4340},\n",
       "  {'class': 'brush_hair',\n",
       "   'end_frame': 453886,\n",
       "   'id': 4837,\n",
       "   'start_frame': 453633,\n",
       "   'video_id': 4837},\n",
       "  {'class': 'sword_exercise',\n",
       "   'end_frame': 463958,\n",
       "   'id': 4949,\n",
       "   'start_frame': 463754,\n",
       "   'video_id': 4949},\n",
       "  {'class': 'talk',\n",
       "   'end_frame': 431655,\n",
       "   'id': 4625,\n",
       "   'start_frame': 431446,\n",
       "   'video_id': 4625},\n",
       "  {'class': 'clap',\n",
       "   'end_frame': 444859,\n",
       "   'id': 4743,\n",
       "   'start_frame': 444807,\n",
       "   'video_id': 4743},\n",
       "  {'class': 'pour',\n",
       "   'end_frame': 400532,\n",
       "   'id': 4288,\n",
       "   'start_frame': 400439,\n",
       "   'video_id': 4288},\n",
       "  {'class': 'kiss',\n",
       "   'end_frame': 392710,\n",
       "   'id': 4204,\n",
       "   'start_frame': 392220,\n",
       "   'video_id': 4204},\n",
       "  {'class': 'dribble',\n",
       "   'end_frame': 499800,\n",
       "   'id': 5342,\n",
       "   'start_frame': 499723,\n",
       "   'video_id': 5342},\n",
       "  {'class': 'pullup',\n",
       "   'end_frame': 469307,\n",
       "   'id': 5010,\n",
       "   'start_frame': 469228,\n",
       "   'video_id': 5010},\n",
       "  {'class': 'wave',\n",
       "   'end_frame': 482746,\n",
       "   'id': 5158,\n",
       "   'start_frame': 482668,\n",
       "   'video_id': 5158},\n",
       "  {'class': 'turn',\n",
       "   'end_frame': 327957,\n",
       "   'id': 3507,\n",
       "   'start_frame': 327867,\n",
       "   'video_id': 3507},\n",
       "  {'class': 'ride_bike',\n",
       "   'end_frame': 418128,\n",
       "   'id': 4481,\n",
       "   'start_frame': 418013,\n",
       "   'video_id': 4481},\n",
       "  {'class': 'push',\n",
       "   'end_frame': 322080,\n",
       "   'id': 3437,\n",
       "   'start_frame': 322002,\n",
       "   'video_id': 3437},\n",
       "  {'class': 'talk',\n",
       "   'end_frame': 426623,\n",
       "   'id': 4576,\n",
       "   'start_frame': 426561,\n",
       "   'video_id': 4576},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 485951,\n",
       "   'id': 5190,\n",
       "   'start_frame': 485486,\n",
       "   'video_id': 5190},\n",
       "  {'class': 'sword_exercise',\n",
       "   'end_frame': 463958,\n",
       "   'id': 4949,\n",
       "   'start_frame': 463754,\n",
       "   'video_id': 4949},\n",
       "  {'class': 'throw',\n",
       "   'end_frame': 343148,\n",
       "   'id': 3660,\n",
       "   'start_frame': 343070,\n",
       "   'video_id': 3660},\n",
       "  {'class': 'walk',\n",
       "   'end_frame': 334319,\n",
       "   'id': 3573,\n",
       "   'start_frame': 334195,\n",
       "   'video_id': 3573},\n",
       "  {'class': 'cartwheel',\n",
       "   'end_frame': 475120,\n",
       "   'id': 5072,\n",
       "   'start_frame': 475039,\n",
       "   'video_id': 5072},\n",
       "  {'class': 'hug',\n",
       "   'end_frame': 330988,\n",
       "   'id': 3537,\n",
       "   'start_frame': 330910,\n",
       "   'video_id': 3537},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 485951,\n",
       "   'id': 5190,\n",
       "   'start_frame': 485486,\n",
       "   'video_id': 5190},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 485951,\n",
       "   'id': 5190,\n",
       "   'start_frame': 485486,\n",
       "   'video_id': 5190},\n",
       "  {'class': 'brush_hair',\n",
       "   'end_frame': 254206,\n",
       "   'id': 2742,\n",
       "   'start_frame': 253706,\n",
       "   'video_id': 2742},\n",
       "  {'class': 'talk',\n",
       "   'end_frame': 426623,\n",
       "   'id': 4576,\n",
       "   'start_frame': 426561,\n",
       "   'video_id': 4576},\n",
       "  {'class': 'punch',\n",
       "   'end_frame': 434560,\n",
       "   'id': 4650,\n",
       "   'start_frame': 434476,\n",
       "   'video_id': 4650},\n",
       "  {'class': 'climb',\n",
       "   'end_frame': 398560,\n",
       "   'id': 4266,\n",
       "   'start_frame': 398210,\n",
       "   'video_id': 4266},\n",
       "  {'class': 'pullup',\n",
       "   'end_frame': 501116,\n",
       "   'id': 5359,\n",
       "   'start_frame': 501039,\n",
       "   'video_id': 5359},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 454990,\n",
       "   'id': 4849,\n",
       "   'start_frame': 454851,\n",
       "   'video_id': 4849},\n",
       "  {'class': 'climb',\n",
       "   'end_frame': 393509,\n",
       "   'id': 4213,\n",
       "   'start_frame': 393384,\n",
       "   'video_id': 4213}],\n",
       " 'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 485,\n",
       "  'current_dataset': {'classes': ['shoot_ball',\n",
       "    'somersault',\n",
       "    'stand',\n",
       "    'smile',\n",
       "    'pour',\n",
       "    'climb_stairs',\n",
       "    'flic_flac',\n",
       "    'situp',\n",
       "    'golf',\n",
       "    'pick',\n",
       "    'draw_sword',\n",
       "    'smoke',\n",
       "    'clap',\n",
       "    'walk',\n",
       "    'dribble',\n",
       "    'talk',\n",
       "    'pushup',\n",
       "    'fall_floor',\n",
       "    'catch',\n",
       "    'sword',\n",
       "    'kick_ball',\n",
       "    'cartwheel',\n",
       "    'punch',\n",
       "    'sword_exercise',\n",
       "    'shoot_bow',\n",
       "    'brush_hair',\n",
       "    'push',\n",
       "    'wave',\n",
       "    'eat',\n",
       "    'hug',\n",
       "    'swing_baseball',\n",
       "    'ride_horse',\n",
       "    'throw',\n",
       "    'run',\n",
       "    'sit',\n",
       "    'pullup',\n",
       "    'dive',\n",
       "    'turn',\n",
       "    'climb',\n",
       "    'chew',\n",
       "    'handstand',\n",
       "    'hit',\n",
       "    'laugh',\n",
       "    'kiss',\n",
       "    'drink',\n",
       "    'ride_bike',\n",
       "    'shake_hands',\n",
       "    'kick',\n",
       "    'fencing',\n",
       "    'jump',\n",
       "    'shoot_gun'],\n",
       "   'dataset_type': 'video_classification',\n",
       "   'license_citation': 'Kuehne, Hildegard, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre. \"HMDB: a large video database for human motion recognition.\" In 2011 International conference on computer vision, pp. 2556-2563. IEEE, 2011.',\n",
       "   'license_link': 'https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'hmdb',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 51,\n",
       "   'number_of_samples_test': 100,\n",
       "   'number_of_samples_train': 816,\n",
       "   'uid': 'hmdb'},\n",
       "  'current_label_budget_stages': [51, 102, 204, 408, 485, 577, 686, 816],\n",
       "  'date_created': 1616457974000,\n",
       "  'date_last_interacted': 1616458083909,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'reproduce_error',\n",
       "  'task_id': 'problem_test_video_classification',\n",
       "  'uid': '8JKYCv3FoPcG5RUetrw4',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "happy-jamaica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r.json()['Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-brazil",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-essex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "honest-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aerial-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'user_secret': secret,\n",
    "           'govteam_secret': gov_secret,\n",
    "           'session_token': session_token}\n",
    "\n",
    "r = requests.get(url + \"/seed_labels\", headers=headers)\n",
    "labels = r.json()['Labels']\n",
    "\n",
    "if video:\n",
    "    seed_labels = []\n",
    "    dictionary_clips = {}\n",
    "    for clip in labels:\n",
    "        action_frames = [str(i)+'.jpg' for i in range(clip['start_frame'], clip['end_frame'])]\n",
    "        dictionary_clips[clip[\"id\"]] = action_frames\n",
    "        seed_labels.append([clip[\"class\"], clip[\"id\"]])\n",
    "    #return seed_labels, dictionary_clips\n",
    "\n",
    "else:\n",
    "    seed_labels = []\n",
    "    for image in labels:\n",
    "        seed_labels.append([image[\"class\"], image[\"id\"]])\n",
    "    #return seed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dirty-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([881, 1366, 93, 561, 294, 679, 1064, 1428, 360, 145, 209, 1697, 110, 1637, 1783, 893, 1726, 1689, 1424, 46, 1321, 1283, 564, 2017, 581, 818, 443, 259, 1343, 1066, 540, 1759, 142, 287, 1665, 1396, 983, 198, 750, 542, 647, 89, 1363, 103, 2036, 1854, 716, 484, 216, 118, 370])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_clips.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "elder-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50991.jpg',\n",
       " '50992.jpg',\n",
       " '50993.jpg',\n",
       " '50994.jpg',\n",
       " '50995.jpg',\n",
       " '50996.jpg',\n",
       " '50997.jpg',\n",
       " '50998.jpg',\n",
       " '50999.jpg',\n",
       " '51000.jpg',\n",
       " '51001.jpg',\n",
       " '51002.jpg',\n",
       " '51003.jpg',\n",
       " '51004.jpg',\n",
       " '51005.jpg',\n",
       " '51006.jpg',\n",
       " '51007.jpg',\n",
       " '51008.jpg',\n",
       " '51009.jpg',\n",
       " '51010.jpg',\n",
       " '51011.jpg',\n",
       " '51012.jpg',\n",
       " '51013.jpg',\n",
       " '51014.jpg',\n",
       " '51015.jpg',\n",
       " '51016.jpg',\n",
       " '51017.jpg',\n",
       " '51018.jpg',\n",
       " '51019.jpg',\n",
       " '51020.jpg',\n",
       " '51021.jpg',\n",
       " '51022.jpg',\n",
       " '51023.jpg',\n",
       " '51024.jpg',\n",
       " '51025.jpg',\n",
       " '51026.jpg',\n",
       " '51027.jpg',\n",
       " '51028.jpg',\n",
       " '51029.jpg',\n",
       " '51030.jpg',\n",
       " '51031.jpg',\n",
       " '51032.jpg',\n",
       " '51033.jpg',\n",
       " '51034.jpg',\n",
       " '51035.jpg',\n",
       " '51036.jpg',\n",
       " '51037.jpg',\n",
       " '51038.jpg',\n",
       " '51039.jpg',\n",
       " '51040.jpg',\n",
       " '51041.jpg',\n",
       " '51042.jpg',\n",
       " '51043.jpg',\n",
       " '51044.jpg',\n",
       " '51045.jpg',\n",
       " '51046.jpg',\n",
       " '51047.jpg',\n",
       " '51048.jpg',\n",
       " '51049.jpg',\n",
       " '51050.jpg',\n",
       " '51051.jpg',\n",
       " '51052.jpg',\n",
       " '51053.jpg',\n",
       " '51054.jpg',\n",
       " '51055.jpg',\n",
       " '51056.jpg',\n",
       " '51057.jpg',\n",
       " '51058.jpg',\n",
       " '51059.jpg',\n",
       " '51060.jpg',\n",
       " '51061.jpg',\n",
       " '51062.jpg',\n",
       " '51063.jpg',\n",
       " '51064.jpg',\n",
       " '51065.jpg',\n",
       " '51066.jpg',\n",
       " '51067.jpg',\n",
       " '51068.jpg',\n",
       " '51069.jpg',\n",
       " '51070.jpg',\n",
       " '51071.jpg',\n",
       " '51072.jpg',\n",
       " '51073.jpg',\n",
       " '51074.jpg',\n",
       " '51075.jpg',\n",
       " '51076.jpg',\n",
       " '51077.jpg',\n",
       " '51078.jpg',\n",
       " '51079.jpg',\n",
       " '51080.jpg',\n",
       " '51081.jpg',\n",
       " '51082.jpg',\n",
       " '51083.jpg',\n",
       " '51084.jpg',\n",
       " '51085.jpg',\n",
       " '51086.jpg',\n",
       " '51087.jpg',\n",
       " '51088.jpg',\n",
       " '51089.jpg',\n",
       " '51090.jpg',\n",
       " '51091.jpg',\n",
       " '51092.jpg',\n",
       " '51093.jpg',\n",
       " '51094.jpg',\n",
       " '51095.jpg',\n",
       " '51096.jpg',\n",
       " '51097.jpg',\n",
       " '51098.jpg',\n",
       " '51099.jpg',\n",
       " '51100.jpg',\n",
       " '51101.jpg',\n",
       " '51102.jpg',\n",
       " '51103.jpg',\n",
       " '51104.jpg',\n",
       " '51105.jpg',\n",
       " '51106.jpg',\n",
       " '51107.jpg',\n",
       " '51108.jpg',\n",
       " '51109.jpg',\n",
       " '51110.jpg',\n",
       " '51111.jpg',\n",
       " '51112.jpg',\n",
       " '51113.jpg',\n",
       " '51114.jpg',\n",
       " '51115.jpg',\n",
       " '51116.jpg',\n",
       " '51117.jpg',\n",
       " '51118.jpg',\n",
       " '51119.jpg',\n",
       " '51120.jpg',\n",
       " '51121.jpg',\n",
       " '51122.jpg',\n",
       " '51123.jpg',\n",
       " '51124.jpg',\n",
       " '51125.jpg',\n",
       " '51126.jpg']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_clips[581]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "amateur-shoulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_images_and_classes_vid(dataset_path: Path, session_token: str, data_type: str='sample') -> Tuple[List[str],List[str]]:\n",
    "    \"\"\"\n",
    "    Helper method to dynamically get the test labels and give us the possible classes that can be submitted\n",
    "    for the current dataset\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    \n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` dataset. \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Tuple[List[str], List[str]]\n",
    "        The list of test image ids needed to submit a prediction and the list of class names that you can predict against\n",
    "    \"\"\"\n",
    "    # Then we can just reference our current metadata to get our dataset name and use that in the path\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    current_dataset_classes = current_dataset['classes']\n",
    "\n",
    "    test_meta = pd.read_feather(dataset_path.joinpath(f\"{current_dataset_name}/{current_dataset_name}_{data_type}/meta_test.feather\"))\n",
    "    test_ids = test_meta['id'].tolist()\n",
    "    return test_meta, test_ids, current_dataset_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "industrial-standing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_images_and_classes_vid(dataset_path: Path, session_token: str, data_type: str='sample') -> Tuple[List[str],List[str]]:\n",
    "    \"\"\"\n",
    "    Helper method to dynamically get the test labels and give us the possible classes that can be submitted\n",
    "    for the current dataset\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    \n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` dataset. \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Tuple[List[str], List[str]]\n",
    "        The list of test image ids needed to submit a prediction and the list of class names that you can predict against\n",
    "    \"\"\"\n",
    "    # Then we can just reference our current metadata to get our dataset name and use that in the path\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    current_dataset_classes = current_dataset['classes']\n",
    "\n",
    "    test_meta = pd.read_feather(dataset_path.joinpath(f\"{current_dataset_name}/labels_{data_type}/meta_test.feather\"))\n",
    "    test_ids = test_meta['id'].tolist()\n",
    "    return test_meta, test_ids, current_dataset_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "worthy-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = Path.home().joinpath('/lwll/external')#/hmdb/hmdb_sample/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "macro-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/lwll/external')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASETS_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "developed-spare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir(DATASETS_PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "noticed-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    " test_meta, test_ids, current_dataset_classes = get_test_images_and_classes_vid(dataset_path=DATASETS_PATH, session_token=session_token, data_type='sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "colonial-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "dictionary_clips = {}\n",
    "for clip in test_meta.iterrows():\n",
    "    row = clip[1]\n",
    "    action_frames = [str(i)+'.jpg' for i in range(row['start_frame'], row['end_frame'])]\n",
    "    dictionary_clips[row[\"id\"]] = action_frames\n",
    "    image_paths.append('ciao' + str(row[\"id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "lesbian-caribbean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ciao5503',\n",
       " 'ciao5855',\n",
       " 'ciao6188',\n",
       " 'ciao5894',\n",
       " 'ciao6485',\n",
       " 'ciao6222',\n",
       " 'ciao5968',\n",
       " 'ciao5959',\n",
       " 'ciao5627',\n",
       " 'ciao6505',\n",
       " 'ciao6098',\n",
       " 'ciao6434',\n",
       " 'ciao5794',\n",
       " 'ciao6754',\n",
       " 'ciao5958',\n",
       " 'ciao6148',\n",
       " 'ciao5460',\n",
       " 'ciao5700',\n",
       " 'ciao5616',\n",
       " 'ciao6184',\n",
       " 'ciao6490',\n",
       " 'ciao5737',\n",
       " 'ciao6083',\n",
       " 'ciao6725',\n",
       " 'ciao6445',\n",
       " 'ciao6595',\n",
       " 'ciao6481',\n",
       " 'ciao5472',\n",
       " 'ciao5415',\n",
       " 'ciao5727',\n",
       " 'ciao6179',\n",
       " 'ciao6156',\n",
       " 'ciao6538',\n",
       " 'ciao6530',\n",
       " 'ciao6092',\n",
       " 'ciao5613',\n",
       " 'ciao6482',\n",
       " 'ciao6389',\n",
       " 'ciao5715',\n",
       " 'ciao5660',\n",
       " 'ciao6537',\n",
       " 'ciao6370',\n",
       " 'ciao5579',\n",
       " 'ciao5500',\n",
       " 'ciao6693',\n",
       " 'ciao6304',\n",
       " 'ciao6726',\n",
       " 'ciao6518',\n",
       " 'ciao6554',\n",
       " 'ciao6475',\n",
       " 'ciao5431',\n",
       " 'ciao5820',\n",
       " 'ciao5492',\n",
       " 'ciao6105',\n",
       " 'ciao5753',\n",
       " 'ciao6477',\n",
       " 'ciao6580',\n",
       " 'ciao5679',\n",
       " 'ciao6560',\n",
       " 'ciao5742',\n",
       " 'ciao6178',\n",
       " 'ciao5589',\n",
       " 'ciao6303',\n",
       " 'ciao6429',\n",
       " 'ciao6450',\n",
       " 'ciao5961',\n",
       " 'ciao6609',\n",
       " 'ciao5844',\n",
       " 'ciao6392',\n",
       " 'ciao6311',\n",
       " 'ciao5527',\n",
       " 'ciao6495',\n",
       " 'ciao6588',\n",
       " 'ciao5840',\n",
       " 'ciao6514',\n",
       " 'ciao5876',\n",
       " 'ciao5787',\n",
       " 'ciao6579',\n",
       " 'ciao6744',\n",
       " 'ciao6009',\n",
       " 'ciao5905',\n",
       " 'ciao6157',\n",
       " 'ciao5477',\n",
       " 'ciao6373',\n",
       " 'ciao5520',\n",
       " 'ciao5815',\n",
       " 'ciao6727',\n",
       " 'ciao6037',\n",
       " 'ciao6321',\n",
       " 'ciao5993',\n",
       " 'ciao6306',\n",
       " 'ciao5651',\n",
       " 'ciao6368',\n",
       " 'ciao6050',\n",
       " 'ciao6657',\n",
       " 'ciao6138',\n",
       " 'ciao5513',\n",
       " 'ciao6521',\n",
       " 'ciao6095',\n",
       " 'ciao6427']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "rough-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_labels_from_train_dataset(dataset_path: Path, session_token: str, n: int=None, data_type: str='sample') -> List[str]:\n",
    "    \"\"\"\n",
    "    Helper function to get a random `n` image ids from our train dataset to request labels for\n",
    "    from the api\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` size dataset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    List[str]\n",
    "        A list of n unique image ids for the current session dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    budget_left = r.json()['Session_Status']['budget_left_until_checkpoint']\n",
    "    print(f\"budget_left is {budget_left}\")\n",
    "    if not n:\n",
    "        n = budget_left\n",
    "    \n",
    "    train_imgs_dir = dataset_path.joinpath(f\"{current_dataset_name}/{current_dataset_name}_{data_type}/train\")\n",
    "    train_imgs = [f.name for f in train_imgs_dir.iterdir() if f.is_file()]\n",
    "    print(f\"train_imgs: {train_imgs[0:4]}\")\n",
    "    \n",
    "    random_ids = random.sample(train_imgs, k=n)\n",
    "    return random_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "greater-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget_left is 51\n",
      "train_imgs: ['10304.jpg', '10305.jpg', '10306.jpg', '10307.jpg']\n"
     ]
    }
   ],
   "source": [
    "images_to_be_labeled = get_random_labels_from_train_dataset(DATASETS_PATH, session_token, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "interstate-throat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['290066.jpg', '506621.jpg']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_be_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "proprietary-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\n",
    "    'example_ids': images_to_be_labeled\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ranging-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': 'ride_bike',\n",
       "   'end_frame': 506636,\n",
       "   'id': 5411,\n",
       "   'start_frame': 506558,\n",
       "   'video_id': 5411},\n",
       "  {'class': 'stand',\n",
       "   'end_frame': 290102,\n",
       "   'id': 3122,\n",
       "   'start_frame': 290056,\n",
       "   'video_id': 3122}],\n",
       " 'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 49,\n",
       "  'budget_used': 2,\n",
       "  'current_dataset': {'classes': ['shoot_ball',\n",
       "    'somersault',\n",
       "    'stand',\n",
       "    'smile',\n",
       "    'pour',\n",
       "    'climb_stairs',\n",
       "    'flic_flac',\n",
       "    'situp',\n",
       "    'golf',\n",
       "    'pick',\n",
       "    'draw_sword',\n",
       "    'smoke',\n",
       "    'clap',\n",
       "    'walk',\n",
       "    'dribble',\n",
       "    'talk',\n",
       "    'pushup',\n",
       "    'fall_floor',\n",
       "    'catch',\n",
       "    'sword',\n",
       "    'kick_ball',\n",
       "    'cartwheel',\n",
       "    'punch',\n",
       "    'sword_exercise',\n",
       "    'shoot_bow',\n",
       "    'brush_hair',\n",
       "    'push',\n",
       "    'wave',\n",
       "    'eat',\n",
       "    'hug',\n",
       "    'swing_baseball',\n",
       "    'ride_horse',\n",
       "    'throw',\n",
       "    'run',\n",
       "    'sit',\n",
       "    'pullup',\n",
       "    'dive',\n",
       "    'turn',\n",
       "    'climb',\n",
       "    'chew',\n",
       "    'handstand',\n",
       "    'hit',\n",
       "    'laugh',\n",
       "    'kiss',\n",
       "    'drink',\n",
       "    'ride_bike',\n",
       "    'shake_hands',\n",
       "    'kick',\n",
       "    'fencing',\n",
       "    'jump',\n",
       "    'shoot_gun'],\n",
       "   'dataset_type': 'video_classification',\n",
       "   'license_citation': 'Kuehne, Hildegard, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre. \"HMDB: a large video database for human motion recognition.\" In 2011 International conference on computer vision, pp. 2556-2563. IEEE, 2011.',\n",
       "   'license_link': 'https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'hmdb',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 51,\n",
       "   'number_of_samples_test': 1354,\n",
       "   'number_of_samples_train': 5412,\n",
       "   'uid': 'hmdb'},\n",
       "  'current_label_budget_stages': [51, 102, 204, 408, 779, 1486, 2836, 5412],\n",
       "  'date_created': 1616024809000,\n",
       "  'date_last_interacted': 1616024809000,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_video_classification',\n",
       "  'uid': 'Q5yYpJkCO745cBx7RZd6',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': False}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "r = requests.post(f\"{url}/query_labels\", json=query, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "compatible-heath",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api-dev.lollllz.com'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "auburn-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"task_metadata\": {\n",
      "    \"adaptation_dataset\": \"hmdb\",\n",
      "    \"adaptation_evaluation_metrics\": [\n",
      "      \"accuracy\"\n",
      "    ],\n",
      "    \"adaptation_label_budget_full\": [\n",
      "      51,\n",
      "      102,\n",
      "      204,\n",
      "      408,\n",
      "      779,\n",
      "      1486,\n",
      "      2836,\n",
      "      5412\n",
      "    ],\n",
      "    \"adaptation_label_budget_sample\": [\n",
      "      51,\n",
      "      102,\n",
      "      204,\n",
      "      408,\n",
      "      485,\n",
      "      577,\n",
      "      686,\n",
      "      816\n",
      "    ],\n",
      "    \"base_dataset\": \"hmdb\",\n",
      "    \"base_evaluation_metrics\": [\n",
      "      \"accuracy\"\n",
      "    ],\n",
      "    \"base_label_budget_full\": [\n",
      "      51,\n",
      "      102,\n",
      "      204,\n",
      "      408,\n",
      "      779,\n",
      "      1486,\n",
      "      2836,\n",
      "      5412\n",
      "    ],\n",
      "    \"base_label_budget_sample\": [\n",
      "      51,\n",
      "      102,\n",
      "      204,\n",
      "      408,\n",
      "      485,\n",
      "      577,\n",
      "      686,\n",
      "      816\n",
      "    ],\n",
      "    \"problem_type\": \"video_classification\",\n",
      "    \"task_id\": \"problem_test_video_classification\",\n",
      "    \"whitelist\": [\n",
      "      \"imagenet_1k\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "r = requests.get(f\"{url}/task_metadata/problem_test_video_classification\", headers=headers)\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statistical-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagenet_1k']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['task_metadata']['whitelist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "positive-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset_metadata\": {\n",
      "    \"classes\": [\n",
      "      \"Cat furniture\",\n",
      "      \"Cheese\",\n",
      "      \"Kettle\",\n",
      "      \"Bicycle\",\n",
      "      \"Chest of drawers\",\n",
      "      \"Shorts\",\n",
      "      \"Desk\",\n",
      "      \"Fox\",\n",
      "      \"Plant\",\n",
      "      \"Footwear\",\n",
      "      \"Bathroom accessory\",\n",
      "      \"Flute\",\n",
      "      \"Light switch\",\n",
      "      \"Sea lion\",\n",
      "      \"Whisk\",\n",
      "      \"Flowerpot\",\n",
      "      \"Treadmill\",\n",
      "      \"Bicycle helmet\",\n",
      "      \"Cheetah\",\n",
      "      \"Glove\",\n",
      "      \"Blue jay\",\n",
      "      \"Grape\",\n",
      "      \"Tent\",\n",
      "      \"Microphone\",\n",
      "      \"Clothing\",\n",
      "      \"Moths and butterflies\",\n",
      "      \"Radish\",\n",
      "      \"Pancake\",\n",
      "      \"Owl\",\n",
      "      \"Furniture\",\n",
      "      \"Banana\",\n",
      "      \"Helmet\",\n",
      "      \"Digital clock\",\n",
      "      \"Strawberry\",\n",
      "      \"Measuring cup\",\n",
      "      \"Girl\",\n",
      "      \"Candy\",\n",
      "      \"Bat (Animal)\",\n",
      "      \"Jaguar (Animal)\",\n",
      "      \"Scissors\",\n",
      "      \"Ipod\",\n",
      "      \"Canoe\",\n",
      "      \"Pencil sharpener\",\n",
      "      \"Willow\",\n",
      "      \"Human head\",\n",
      "      \"Submarine sandwich\",\n",
      "      \"Waste container\",\n",
      "      \"Axe\",\n",
      "      \"Spoon\",\n",
      "      \"Lavender (Plant)\",\n",
      "      \"Bell pepper\",\n",
      "      \"Accordion\",\n",
      "      \"Sandwich\",\n",
      "      \"Bicycle wheel\",\n",
      "      \"Dessert\",\n",
      "      \"Baked goods\",\n",
      "      \"Weapon\",\n",
      "      \"Bird\",\n",
      "      \"Plastic bag\",\n",
      "      \"Turkey\",\n",
      "      \"Piano\",\n",
      "      \"Koala\",\n",
      "      \"Van\",\n",
      "      \"Human foot\",\n",
      "      \"Caterpillar\",\n",
      "      \"Computer keyboard\",\n",
      "      \"Swimwear\",\n",
      "      \"Harbor seal\",\n",
      "      \"Salt and pepper shakers\",\n",
      "      \"Camera\",\n",
      "      \"Stairs\",\n",
      "      \"Fork\",\n",
      "      \"Barge\",\n",
      "      \"Snowmobile\",\n",
      "      \"Parachute\",\n",
      "      \"Tennis ball\",\n",
      "      \"Vehicle\",\n",
      "      \"Antelope\",\n",
      "      \"Poster\",\n",
      "      \"Guitar\",\n",
      "      \"Crown\",\n",
      "      \"Centipede\",\n",
      "      \"Surfboard\",\n",
      "      \"Mixer\",\n",
      "      \"Fast food\",\n",
      "      \"Bread\",\n",
      "      \"Pen\",\n",
      "      \"Bowling equipment\",\n",
      "      \"Alarm clock\",\n",
      "      \"Taco\",\n",
      "      \"Fire hydrant\",\n",
      "      \"Torch\",\n",
      "      \"Person\",\n",
      "      \"Golf cart\",\n",
      "      \"Ant\",\n",
      "      \"Hair spray\",\n",
      "      \"Wood-burning stove\",\n",
      "      \"Tomato\",\n",
      "      \"Frog\",\n",
      "      \"Rays and skates\",\n",
      "      \"Bottle\",\n",
      "      \"Coffee table\",\n",
      "      \"Mug\",\n",
      "      \"Dress\",\n",
      "      \"Pressure cooker\",\n",
      "      \"Lantern\",\n",
      "      \"Drinking straw\",\n",
      "      \"Loveseat\",\n",
      "      \"Shrimp\",\n",
      "      \"Stationary bicycle\",\n",
      "      \"Snack\",\n",
      "      \"Waffle\",\n",
      "      \"Cannon\",\n",
      "      \"Cabbage\",\n",
      "      \"Insect\",\n",
      "      \"Pretzel\",\n",
      "      \"Shelf\",\n",
      "      \"Tennis racket\",\n",
      "      \"Shotgun\",\n",
      "      \"Cookie\",\n",
      "      \"Pizza\",\n",
      "      \"Red panda\",\n",
      "      \"Skateboard\",\n",
      "      \"Turtle\",\n",
      "      \"Cattle\",\n",
      "      \"Wine rack\",\n",
      "      \"Cosmetics\",\n",
      "      \"Door handle\",\n",
      "      \"Computer mouse\",\n",
      "      \"Infant bed\",\n",
      "      \"Castle\",\n",
      "      \"Sword\",\n",
      "      \"Doughnut\",\n",
      "      \"Goggles\",\n",
      "      \"Monkey\",\n",
      "      \"Seat belt\",\n",
      "      \"Crutch\",\n",
      "      \"Maracas\",\n",
      "      \"Zebra\",\n",
      "      \"Kitchen appliance\",\n",
      "      \"Toothbrush\",\n",
      "      \"Spice rack\",\n",
      "      \"Beer\",\n",
      "      \"Polar bear\",\n",
      "      \"Paper towel\",\n",
      "      \"Ski\",\n",
      "      \"Missile\",\n",
      "      \"Racket\",\n",
      "      \"Golf ball\",\n",
      "      \"Nail (Construction)\",\n",
      "      \"Swim cap\",\n",
      "      \"Billboard\",\n",
      "      \"Mammal\",\n",
      "      \"Roller skates\",\n",
      "      \"Eagle\",\n",
      "      \"Kitchen knife\",\n",
      "      \"Billiard table\",\n",
      "      \"Coconut\",\n",
      "      \"Lily\",\n",
      "      \"Harmonica\",\n",
      "      \"Backpack\",\n",
      "      \"Candle\",\n",
      "      \"Bottle opener\",\n",
      "      \"Indoor rower\",\n",
      "      \"Training bench\",\n",
      "      \"Door\",\n",
      "      \"Couch\",\n",
      "      \"Dog\",\n",
      "      \"Towel\",\n",
      "      \"Flying disc\",\n",
      "      \"Jacuzzi\",\n",
      "      \"Miniskirt\",\n",
      "      \"Woman\",\n",
      "      \"Ball\",\n",
      "      \"Bow and arrow\",\n",
      "      \"Tree house\",\n",
      "      \"Potato\",\n",
      "      \"Woodpecker\",\n",
      "      \"Handbag\",\n",
      "      \"Sock\",\n",
      "      \"Cream\",\n",
      "      \"Doll\",\n",
      "      \"Tablet computer\",\n",
      "      \"Carrot\",\n",
      "      \"Tripod\",\n",
      "      \"Sheep\",\n",
      "      \"Table tennis racket\",\n",
      "      \"Hot dog\",\n",
      "      \"Hedgehog\",\n",
      "      \"Bull\",\n",
      "      \"Convenience store\",\n",
      "      \"Falcon\",\n",
      "      \"Ambulance\",\n",
      "      \"Panda\",\n",
      "      \"Deer\",\n",
      "      \"Suit\",\n",
      "      \"Tank\",\n",
      "      \"Wardrobe\",\n",
      "      \"Hair dryer\",\n",
      "      \"Window\",\n",
      "      \"Beetle\",\n",
      "      \"Fashion accessory\",\n",
      "      \"Chicken\",\n",
      "      \"Wheelchair\",\n",
      "      \"Drum\",\n",
      "      \"Fruit\",\n",
      "      \"Microwave oven\",\n",
      "      \"Stool\",\n",
      "      \"Watermelon\",\n",
      "      \"Traffic sign\",\n",
      "      \"Pineapple\",\n",
      "      \"Kite\",\n",
      "      \"Ladybug\",\n",
      "      \"Dolphin\",\n",
      "      \"Lemon\",\n",
      "      \"House\",\n",
      "      \"Ostrich\",\n",
      "      \"Sink\",\n",
      "      \"Bust\",\n",
      "      \"Marine mammal\",\n",
      "      \"Dragonfly\",\n",
      "      \"Balloon\",\n",
      "      \"Calculator\",\n",
      "      \"Bowl\",\n",
      "      \"Fax\",\n",
      "      \"Boat\",\n",
      "      \"Sofa bed\",\n",
      "      \"Tableware\",\n",
      "      \"Countertop\",\n",
      "      \"Food processor\",\n",
      "      \"Sparrow\",\n",
      "      \"Laptop\",\n",
      "      \"Telephone\",\n",
      "      \"Lion\",\n",
      "      \"Snake\",\n",
      "      \"Balance beam\",\n",
      "      \"Canary\",\n",
      "      \"Wheel\",\n",
      "      \"Hamburger\",\n",
      "      \"Tower\",\n",
      "      \"Shower\",\n",
      "      \"Soap dispenser\",\n",
      "      \"Garden Asparagus\",\n",
      "      \"Coat\",\n",
      "      \"Mule\",\n",
      "      \"Boy\",\n",
      "      \"Taxi\",\n",
      "      \"Paper cutter\",\n",
      "      \"Seafood\",\n",
      "      \"Nightstand\",\n",
      "      \"Mouse\",\n",
      "      \"Tart\",\n",
      "      \"Beehive\",\n",
      "      \"Picture frame\",\n",
      "      \"Cucumber\",\n",
      "      \"Toilet\",\n",
      "      \"Washing machine\",\n",
      "      \"Sports uniform\",\n",
      "      \"Tortoise\",\n",
      "      \"Office building\",\n",
      "      \"Sewing machine\",\n",
      "      \"Rugby ball\",\n",
      "      \"Leopard\",\n",
      "      \"Sandal\",\n",
      "      \"Raccoon\",\n",
      "      \"Horse\",\n",
      "      \"Skyscraper\",\n",
      "      \"Slow cooker\",\n",
      "      \"Hiking equipment\",\n",
      "      \"Motorcycle\",\n",
      "      \"Squash (Plant)\",\n",
      "      \"Serving tray\",\n",
      "      \"Scale\",\n",
      "      \"Ruler\",\n",
      "      \"Curtain\",\n",
      "      \"Artichoke\",\n",
      "      \"Pitcher (Container)\",\n",
      "      \"Ice cream\",\n",
      "      \"Human nose\",\n",
      "      \"Tap\",\n",
      "      \"Earrings\",\n",
      "      \"Mushroom\",\n",
      "      \"Wine glass\",\n",
      "      \"Cello\",\n",
      "      \"Dumbbell\",\n",
      "      \"Beaker\",\n",
      "      \"Harpsichord\",\n",
      "      \"Snail\",\n",
      "      \"Lizard\",\n",
      "      \"Broccoli\",\n",
      "      \"Skull\",\n",
      "      \"Light bulb\",\n",
      "      \"Box\",\n",
      "      \"Fedora\",\n",
      "      \"Pumpkin\",\n",
      "      \"Sun hat\",\n",
      "      \"Violin\",\n",
      "      \"Crocodile\",\n",
      "      \"Scarf\",\n",
      "      \"Teddy bear\",\n",
      "      \"Burrito\",\n",
      "      \"Parking meter\",\n",
      "      \"Grapefruit\",\n",
      "      \"Shirt\",\n",
      "      \"Trombone\",\n",
      "      \"Winter melon\",\n",
      "      \"Briefcase\",\n",
      "      \"Dinosaur\",\n",
      "      \"Drawer\",\n",
      "      \"Ratchet (Device)\",\n",
      "      \"Vegetable\",\n",
      "      \"Milk\",\n",
      "      \"Boot\",\n",
      "      \"Helicopter\",\n",
      "      \"Gas stove\",\n",
      "      \"Toy\",\n",
      "      \"Egg (Food)\",\n",
      "      \"Swan\",\n",
      "      \"Corded phone\",\n",
      "      \"Human arm\",\n",
      "      \"Guacamole\",\n",
      "      \"Swimming pool\",\n",
      "      \"Lamp\",\n",
      "      \"Toaster\",\n",
      "      \"Necklace\",\n",
      "      \"Car\",\n",
      "      \"Land vehicle\",\n",
      "      \"Sombrero\",\n",
      "      \"Rocket\",\n",
      "      \"Magpie\",\n",
      "      \"Human eye\",\n",
      "      \"Vehicle registration plate\",\n",
      "      \"Fountain\",\n",
      "      \"Ladle\",\n",
      "      \"Cassette deck\",\n",
      "      \"Hat\",\n",
      "      \"Eraser\",\n",
      "      \"Human beard\",\n",
      "      \"Television\",\n",
      "      \"Mechanical fan\",\n",
      "      \"Reptile\",\n",
      "      \"Can opener\",\n",
      "      \"Snowboard\",\n",
      "      \"Pasta\",\n",
      "      \"Gondola\",\n",
      "      \"Otter\",\n",
      "      \"Barrel\",\n",
      "      \"Human leg\",\n",
      "      \"Chopsticks\",\n",
      "      \"Waffle iron\",\n",
      "      \"Sea turtle\",\n",
      "      \"Baseball bat\",\n",
      "      \"Human mouth\",\n",
      "      \"Human hand\",\n",
      "      \"Stapler\",\n",
      "      \"Tea\",\n",
      "      \"Medical equipment\",\n",
      "      \"Facial tissue holder\",\n",
      "      \"Human hair\",\n",
      "      \"Lobster\",\n",
      "      \"Seahorse\",\n",
      "      \"Starfish\",\n",
      "      \"Musical instrument\",\n",
      "      \"Pomegranate\",\n",
      "      \"Sculpture\",\n",
      "      \"Screwdriver\",\n",
      "      \"Flashlight\",\n",
      "      \"Bear\",\n",
      "      \"Dagger\",\n",
      "      \"Blender\",\n",
      "      \"Umbrella\",\n",
      "      \"Grinder\",\n",
      "      \"Bee\",\n",
      "      \"Human body\",\n",
      "      \"Pizza cutter\",\n",
      "      \"Cooking spray\",\n",
      "      \"Truck\",\n",
      "      \"Goat\",\n",
      "      \"Kitchen utensil\",\n",
      "      \"Vase\",\n",
      "      \"Invertebrate\",\n",
      "      \"Oven\",\n",
      "      \"Palm tree\",\n",
      "      \"Cupboard\",\n",
      "      \"Watercraft\",\n",
      "      \"Saucer\",\n",
      "      \"Penguin\",\n",
      "      \"Alpaca\",\n",
      "      \"Spider\",\n",
      "      \"Personal flotation device\",\n",
      "      \"Saxophone\",\n",
      "      \"Jet ski\",\n",
      "      \"Pillow\",\n",
      "      \"Kitchen & dining room table\",\n",
      "      \"Chair\",\n",
      "      \"Dishwasher\",\n",
      "      \"Christmas tree\",\n",
      "      \"Punching bag\",\n",
      "      \"Traffic light\",\n",
      "      \"Rose\",\n",
      "      \"Tick\",\n",
      "      \"Bed\",\n",
      "      \"Human ear\",\n",
      "      \"Flag\",\n",
      "      \"Sushi\",\n",
      "      \"Carnivore\",\n",
      "      \"Clock\",\n",
      "      \"Football helmet\",\n",
      "      \"Plate\",\n",
      "      \"Hammer\",\n",
      "      \"Chime\",\n",
      "      \"Tiara\",\n",
      "      \"Bathroom cabinet\",\n",
      "      \"Power plugs and sockets\",\n",
      "      \"Tire\",\n",
      "      \"Window blind\",\n",
      "      \"Trumpet\",\n",
      "      \"Goose\",\n",
      "      \"Porch\",\n",
      "      \"Auto part\",\n",
      "      \"Cutting board\",\n",
      "      \"French horn\",\n",
      "      \"Mobile phone\",\n",
      "      \"Common sunflower\",\n",
      "      \"Coffee\",\n",
      "      \"Banjo\",\n",
      "      \"Spatula\",\n",
      "      \"Popcorn\",\n",
      "      \"Glasses\",\n",
      "      \"Zucchini\",\n",
      "      \"Shellfish\",\n",
      "      \"Stethoscope\",\n",
      "      \"Snowman\",\n",
      "      \"Croissant\",\n",
      "      \"Personal care\",\n",
      "      \"Brown bear\",\n",
      "      \"Sports equipment\",\n",
      "      \"Camel\",\n",
      "      \"Honeycomb\",\n",
      "      \"Kangaroo\",\n",
      "      \"Peach\",\n",
      "      \"Office supplies\",\n",
      "      \"Trousers\",\n",
      "      \"Rabbit\",\n",
      "      \"Duck\",\n",
      "      \"Table\",\n",
      "      \"Goldfish\",\n",
      "      \"Salad\",\n",
      "      \"Tree\",\n",
      "      \"Baseball glove\",\n",
      "      \"Home appliance\",\n",
      "      \"Porcupine\",\n",
      "      \"Man\",\n",
      "      \"Scoreboard\",\n",
      "      \"Jug\",\n",
      "      \"Ring binder\",\n",
      "      \"Chisel\",\n",
      "      \"Remote control\",\n",
      "      \"Book\",\n",
      "      \"Dice\",\n",
      "      \"Isopod\",\n",
      "      \"Building\",\n",
      "      \"Rifle\",\n",
      "      \"Oboe\",\n",
      "      \"Studio couch\",\n",
      "      \"Harp\",\n",
      "      \"High heels\",\n",
      "      \"Segway\",\n",
      "      \"Humidifier\",\n",
      "      \"Pencil case\",\n",
      "      \"Skirt\",\n",
      "      \"Pear\",\n",
      "      \"Cricket ball\",\n",
      "      \"Jellyfish\",\n",
      "      \"Brassiere\",\n",
      "      \"Bagel\",\n",
      "      \"Drill (Tool)\",\n",
      "      \"Tiger\",\n",
      "      \"Horizontal bar\",\n",
      "      \"Plumbing fixture\",\n",
      "      \"Submarine\",\n",
      "      \"Hand dryer\",\n",
      "      \"Heater\",\n",
      "      \"Animal\",\n",
      "      \"Food\",\n",
      "      \"Houseplant\",\n",
      "      \"Snowplow\",\n",
      "      \"Organ (Musical Instrument)\",\n",
      "      \"Fireplace\",\n",
      "      \"Closet\",\n",
      "      \"Dairy Product\",\n",
      "      \"Squid\",\n",
      "      \"Chainsaw\",\n",
      "      \"Common fig\",\n",
      "      \"Ceiling fan\",\n",
      "      \"Whale\",\n",
      "      \"Bathtub\",\n",
      "      \"Platter\",\n",
      "      \"Belt\",\n",
      "      \"Handgun\",\n",
      "      \"Giraffe\",\n",
      "      \"Unicycle\",\n",
      "      \"Perfume\",\n",
      "      \"Tin can\",\n",
      "      \"French fries\",\n",
      "      \"Orange\",\n",
      "      \"Ladder\",\n",
      "      \"Cake stand\",\n",
      "      \"Band-aid\",\n",
      "      \"Marine invertebrates\",\n",
      "      \"Wine\",\n",
      "      \"Maple\",\n",
      "      \"Raven\",\n",
      "      \"Picnic basket\",\n",
      "      \"Sunglasses\",\n",
      "      \"Cart\",\n",
      "      \"Street light\",\n",
      "      \"Oyster\",\n",
      "      \"Mango\",\n",
      "      \"Crab\",\n",
      "      \"Face powder\",\n",
      "      \"Parrot\",\n",
      "      \"Lynx\",\n",
      "      \"Refrigerator\",\n",
      "      \"Scorpion\",\n",
      "      \"Pastry\",\n",
      "      \"Watch\",\n",
      "      \"Fish\",\n",
      "      \"Envelope\",\n",
      "      \"Cocktail shaker\",\n",
      "      \"Skunk\",\n",
      "      \"Drink\",\n",
      "      \"Teapot\",\n",
      "      \"Human face\",\n",
      "      \"Apple\",\n",
      "      \"Cantaloupe\",\n",
      "      \"Lighthouse\",\n",
      "      \"Shark\",\n",
      "      \"Cocktail\",\n",
      "      \"Bidet\",\n",
      "      \"Computer monitor\",\n",
      "      \"Airplane\",\n",
      "      \"Rhinoceros\",\n",
      "      \"Paddle\",\n",
      "      \"Bronze sculpture\",\n",
      "      \"Juice\",\n",
      "      \"Aircraft\",\n",
      "      \"Coffeemaker\",\n",
      "      \"Cabinetry\",\n",
      "      \"Stop sign\",\n",
      "      \"Toilet paper\",\n",
      "      \"Bomb\",\n",
      "      \"Adhesive tape\",\n",
      "      \"Hippopotamus\",\n",
      "      \"Pig\",\n",
      "      \"Diaper\",\n",
      "      \"Cat\",\n",
      "      \"Coffee cup\",\n",
      "      \"Suitcase\",\n",
      "      \"Luggage and bags\",\n",
      "      \"Bookcase\",\n",
      "      \"Train\",\n",
      "      \"Stretcher\",\n",
      "      \"Squirrel\",\n",
      "      \"Wrench\",\n",
      "      \"Musical keyboard\",\n",
      "      \"Tie\",\n",
      "      \"Jeans\",\n",
      "      \"Limousine\",\n",
      "      \"Wok\",\n",
      "      \"Volleyball (Ball)\",\n",
      "      \"Hamster\",\n",
      "      \"Knife\",\n",
      "      \"Tool\",\n",
      "      \"Bench\",\n",
      "      \"Elephant\",\n",
      "      \"Armadillo\",\n",
      "      \"Wall clock\",\n",
      "      \"Headphones\",\n",
      "      \"Whiteboard\",\n",
      "      \"Flower\",\n",
      "      \"Mixing bowl\",\n",
      "      \"Frying pan\",\n",
      "      \"Bus\",\n",
      "      \"Football\",\n",
      "      \"Syringe\",\n",
      "      \"Lipstick\",\n",
      "      \"Jacket\",\n",
      "      \"Filing cabinet\",\n",
      "      \"Container\",\n",
      "      \"Dog bed\",\n",
      "      \"Muffin\",\n",
      "      \"Coin\",\n",
      "      \"Kitchenware\",\n",
      "      \"Butterfly\",\n",
      "      \"Cake\",\n",
      "      \"Cowboy hat\",\n",
      "      \"Binoculars\",\n",
      "      \"Printer\",\n",
      "      \"Worm\",\n",
      "      \"Mirror\"\n",
      "    ],\n",
      "    \"dataset_type\": \"object_detection\",\n",
      "    \"full_number_of_classes\": 601,\n",
      "    \"full_number_of_samples_test\": 37306,\n",
      "    \"full_number_of_samples_train\": 1743042,\n",
      "    \"license_citation\": \"@article{kuznetsova2018open,title={The open images dataset v4:                                 Unified image classification, object detection, and visual relationship                                 detection at scale}, author={Kuznetsova, Alina and Rom, Hassan and Alldrin,                                 Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali,                                 Shahab and Popov, Stefan and Malloci, Matteo and Duerig, Tom and others},                                 journal={arXiv preprint arXiv:1811.00982}, year={2018}}\",\n",
      "    \"license_link\": \"https://storage.googleapis.com/openimages/web/factsfigures.html\",\n",
      "    \"license_requirements\": \"The annotations are licensed by Google LLC under CC BY 4.0                                 license. The images are listed as having a CC BY 2.0 license. Note: while we                                 tried to identify images that are licensed under a Creative Commons Attribution                                 license, we make no representations or warranties regarding the license status                                 of each image and you should verify the license for each image yourself.\",\n",
      "    \"name\": \"google_open_image\",\n",
      "    \"number_of_channels\": 3,\n",
      "    \"sample_number_of_classes\": 601,\n",
      "    \"sample_number_of_samples_test\": 1000,\n",
      "    \"sample_number_of_samples_train\": 20000,\n",
      "    \"uid\": \"google_open_image\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "r = requests.get(f\"{url}/dataset_metadata/google_open_image\", headers=headers)\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confident-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def get_task_subset_by_type(subset_type: str, url: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Helper function that returns the task ids in a list that match a specified\n",
    "    problem type\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    subset_type : str\n",
    "        The task_type subset you want to get back\n",
    "    \"\"\"\n",
    "    headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "    tasks = requests.get(f\"{url}/list_tasks\", headers=headers)\n",
    "    task_list = tasks.json()['tasks']\n",
    "    subset_tasks = []\n",
    "    for _task in task_list:\n",
    "        r = requests.get(f\"{url}/task_metadata/{_task}\", headers=headers)\n",
    "        task_metadata = r.json()\n",
    "        try:\n",
    "            if task_metadata['task_metadata']['problem_type'] == subset_type:\n",
    "                subset_tasks.append(_task)\n",
    "        except Exception as e:\n",
    "            print(_task)\n",
    "            print(e)\n",
    "    return subset_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "large-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_classification_tasks = get_task_subset_by_type('video_classification', url)\n",
    "img_classification_tasks = get_task_subset_by_type('image_classification', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opening-liabilities",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem_test_video_classification']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_classification_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "designed-parallel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6d5e1f85-5d8f-4cc9-8184-299db03713f4',\n",
       " 'b01a6738-0b85-46c2-9318-16c3e2ef0f6d',\n",
       " 'bbfadb2c-c7c3-4596-b548-3dd01a6d1d2c',\n",
       " 'problem_test_image_classification']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_classification_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "built-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_token': 'rP42SIPvvFPYTAe56lbW'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "\n",
    "# This is a convenience for development purposes, IN EVAL ALWAYS USE `full`\n",
    "data_type = 'sample' # can either be `sample` or `full`\n",
    "\n",
    "# Option to customize the session name \n",
    "r = requests.post(f\"{url}/auth/create_session\", json={'session_name': 'testing', 'data_type': data_type, \n",
    "                                                      'task_id': 'problem_test_video_classification'},\n",
    "                  headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "billion-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_token = r.json()['session_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conditional-jewelry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 51,\n",
       "  'budget_used': 0,\n",
       "  'current_dataset': {'classes': ['shoot_ball',\n",
       "    'somersault',\n",
       "    'stand',\n",
       "    'smile',\n",
       "    'pour',\n",
       "    'climb_stairs',\n",
       "    'flic_flac',\n",
       "    'situp',\n",
       "    'golf',\n",
       "    'pick',\n",
       "    'draw_sword',\n",
       "    'smoke',\n",
       "    'clap',\n",
       "    'walk',\n",
       "    'dribble',\n",
       "    'talk',\n",
       "    'pushup',\n",
       "    'fall_floor',\n",
       "    'catch',\n",
       "    'sword',\n",
       "    'kick_ball',\n",
       "    'cartwheel',\n",
       "    'punch',\n",
       "    'sword_exercise',\n",
       "    'shoot_bow',\n",
       "    'brush_hair',\n",
       "    'push',\n",
       "    'wave',\n",
       "    'eat',\n",
       "    'hug',\n",
       "    'swing_baseball',\n",
       "    'ride_horse',\n",
       "    'throw',\n",
       "    'run',\n",
       "    'sit',\n",
       "    'pullup',\n",
       "    'dive',\n",
       "    'turn',\n",
       "    'climb',\n",
       "    'chew',\n",
       "    'handstand',\n",
       "    'hit',\n",
       "    'laugh',\n",
       "    'kiss',\n",
       "    'drink',\n",
       "    'ride_bike',\n",
       "    'shake_hands',\n",
       "    'kick',\n",
       "    'fencing',\n",
       "    'jump',\n",
       "    'shoot_gun'],\n",
       "   'dataset_type': 'video_classification',\n",
       "   'license_citation': 'Kuehne, Hildegard, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre. \"HMDB: a large video database for human motion recognition.\" In 2011 International conference on computer vision, pp. 2556-2563. IEEE, 2011.',\n",
       "   'license_link': 'https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'hmdb',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 51,\n",
       "   'number_of_samples_test': 100,\n",
       "   'number_of_samples_train': 816,\n",
       "   'uid': 'hmdb'},\n",
       "  'current_label_budget_stages': [51, 102, 204, 408, 485, 577, 686, 816],\n",
       "  'date_created': 1615944140000,\n",
       "  'date_last_interacted': 1615944140000,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_video_classification',\n",
       "  'uid': 'rP42SIPvvFPYTAe56lbW',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "graphic-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_sessions': ['07HRMjQx2FhKg5ePG9ES',\n",
       "  '0axbLnk9q8Edbe8Uto6B',\n",
       "  '2hiyDBNkIvjSxfsAJiWE',\n",
       "  '31IT4UtOCge9Z4588186',\n",
       "  '3LnrRHLKTcv39xguM7SM',\n",
       "  '3TuOcOxeOlqBRWntguk3',\n",
       "  '44RHjL8nBADJqHRwdyaF',\n",
       "  '4l47oy8FJiYfvN4bOb8U',\n",
       "  '5Jca2i4tNkZtW0XJQX6y',\n",
       "  '5WmYxgcTdXUZbGxOQVHT',\n",
       "  '5gM8ximMNgsogk9md5NX',\n",
       "  '5x1qcLiikkWPtdKO9BpM',\n",
       "  '6UmGVewydWxxgVBScAQp',\n",
       "  '828JXK1wA7BFLYjWDLo8',\n",
       "  '8UtrWLtmswwDQvv5VhaK',\n",
       "  '8zjJi4Xoaqf41er56neT',\n",
       "  '9R0iWvrberOt3DiCUdcw',\n",
       "  'Ba3Co8fSrhH1x8TuygA4',\n",
       "  'BtRQMbs75CRyd044cIRo',\n",
       "  'CHJuyAawICW1xeC9uOXQ',\n",
       "  'Dqa1NuHE4ik7rp7Ns1nj',\n",
       "  'EafoOLXGie384F4slQIO',\n",
       "  'EipSnGK0q8WeFdyyBtH8',\n",
       "  'FEve9SZoGkKwkgD17RUs',\n",
       "  'Gj5N3bfuX6TXVZ7eKaZy',\n",
       "  'J81dKtsVxLqsQbpvhouP',\n",
       "  'JjwONCZK0GnI3nQgwRMg',\n",
       "  'K5xPNejwR7FQInPFdwi3',\n",
       "  'LY7rsV9S0bohJQQWQfIQ',\n",
       "  'MnCVhHzptNsQs8w3X3w4',\n",
       "  'NHcd7GvqPKQvUe9TGrGU',\n",
       "  'NMFa4DG6i7cautR3aZvX',\n",
       "  'Ota4oh4wSha0ZxOzHWJl',\n",
       "  'TOxPWTXjFqeaYduMWz7Z',\n",
       "  'UIM9qlksZjJwAJDYUtsl',\n",
       "  'UdsuSn03PL07nKGPQaec',\n",
       "  'UpCLBHcG3EEHSPl9cDvV',\n",
       "  'aTDsEM7mz5uUoAH67op1',\n",
       "  'bOGZbfRDlk4IIXdB9HIV',\n",
       "  'c02DKrCCuCww4H4UlNal',\n",
       "  'ctzxDl5zOiPNi7r138aL',\n",
       "  'el21fLZRB171YS7L0Hws',\n",
       "  'gAZ860ExLfRW5uW5PG4H',\n",
       "  'hch5L9KmsbRWUeofslRi',\n",
       "  'jIBIEKSUYdw9baMFCE2r',\n",
       "  'jdrCPyFGQ2AQfdkCbnHb',\n",
       "  'kfo9ZiNqTE8WbZoKCWNA',\n",
       "  'l0qskSkOG4yPlbQxSK5V',\n",
       "  'lSg8Qk3Q7uxcDlXmCBde',\n",
       "  'nOWbG1WlaDtoUunwNOj2',\n",
       "  'nio5bytmO3rKbOvxZLFF',\n",
       "  'nrKVUdGLQ3lkMZ8xQ1YR',\n",
       "  'ocwg6a7wLumqJYnyNtPC',\n",
       "  'ojXWYJtQNTOvb9uawKLm',\n",
       "  'oztZqMUoHPl4GmpWSD04',\n",
       "  'rqkJoMexn4VyNqb5Wwg5',\n",
       "  'smSJ3iRgbQ0zo219dtBu',\n",
       "  'uphOCnHLiUDC7luFSIqa',\n",
       "  'wSevHTMrkEvhskvawNcF',\n",
       "  'xtXbkAP2Eb3WNLyU440U',\n",
       "  'ytmLKHK0aJEt4pvh4rZw']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This shows the active sessions for your team\n",
    "headers_session = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/list_active_sessions\", headers=headers_session)\n",
    "active_sessions = r.json()\n",
    "active_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "variable-shareware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': 'brush_hair',\n",
       "   'end_frame': 80711,\n",
       "   'id': 881,\n",
       "   'start_frame': 80326,\n",
       "   'video_id': 881},\n",
       "  {'class': 'cartwheel',\n",
       "   'end_frame': 125969,\n",
       "   'id': 1366,\n",
       "   'start_frame': 125892,\n",
       "   'video_id': 1366},\n",
       "  {'class': 'catch',\n",
       "   'end_frame': 8277,\n",
       "   'id': 93,\n",
       "   'start_frame': 8242,\n",
       "   'video_id': 93},\n",
       "  {'class': 'chew',\n",
       "   'end_frame': 49439,\n",
       "   'id': 561,\n",
       "   'start_frame': 49341,\n",
       "   'video_id': 561},\n",
       "  {'class': 'clap',\n",
       "   'end_frame': 26696,\n",
       "   'id': 294,\n",
       "   'start_frame': 26653,\n",
       "   'video_id': 294},\n",
       "  {'class': 'climb',\n",
       "   'end_frame': 60370,\n",
       "   'id': 679,\n",
       "   'start_frame': 60278,\n",
       "   'video_id': 679},\n",
       "  {'class': 'climb_stairs',\n",
       "   'end_frame': 98319,\n",
       "   'id': 1064,\n",
       "   'start_frame': 98245,\n",
       "   'video_id': 1064},\n",
       "  {'class': 'dive',\n",
       "   'end_frame': 131732,\n",
       "   'id': 1428,\n",
       "   'start_frame': 131702,\n",
       "   'video_id': 1428},\n",
       "  {'class': 'draw_sword',\n",
       "   'end_frame': 32416,\n",
       "   'id': 360,\n",
       "   'start_frame': 32363,\n",
       "   'video_id': 360},\n",
       "  {'class': 'dribble',\n",
       "   'end_frame': 14209,\n",
       "   'id': 145,\n",
       "   'start_frame': 14132,\n",
       "   'video_id': 145},\n",
       "  {'class': 'drink',\n",
       "   'end_frame': 19673,\n",
       "   'id': 209,\n",
       "   'start_frame': 19581,\n",
       "   'video_id': 209},\n",
       "  {'class': 'eat',\n",
       "   'end_frame': 157264,\n",
       "   'id': 1697,\n",
       "   'start_frame': 157225,\n",
       "   'video_id': 1697},\n",
       "  {'class': 'fall_floor',\n",
       "   'end_frame': 10359,\n",
       "   'id': 110,\n",
       "   'start_frame': 10304,\n",
       "   'video_id': 110},\n",
       "  {'class': 'fencing',\n",
       "   'end_frame': 151179,\n",
       "   'id': 1637,\n",
       "   'start_frame': 151139,\n",
       "   'video_id': 1637},\n",
       "  {'class': 'flic_flac',\n",
       "   'end_frame': 164127,\n",
       "   'id': 1783,\n",
       "   'start_frame': 164050,\n",
       "   'video_id': 1783},\n",
       "  {'class': 'golf',\n",
       "   'end_frame': 81651,\n",
       "   'id': 893,\n",
       "   'start_frame': 81575,\n",
       "   'video_id': 893},\n",
       "  {'class': 'handstand',\n",
       "   'end_frame': 159618,\n",
       "   'id': 1726,\n",
       "   'start_frame': 159543,\n",
       "   'video_id': 1726},\n",
       "  {'class': 'hit',\n",
       "   'end_frame': 156280,\n",
       "   'id': 1689,\n",
       "   'start_frame': 156228,\n",
       "   'video_id': 1689},\n",
       "  {'class': 'hug',\n",
       "   'end_frame': 131306,\n",
       "   'id': 1424,\n",
       "   'start_frame': 131252,\n",
       "   'video_id': 1424},\n",
       "  {'class': 'jump',\n",
       "   'end_frame': 4162,\n",
       "   'id': 46,\n",
       "   'start_frame': 4109,\n",
       "   'video_id': 46},\n",
       "  {'class': 'kick',\n",
       "   'end_frame': 121483,\n",
       "   'id': 1321,\n",
       "   'start_frame': 121437,\n",
       "   'video_id': 1321},\n",
       "  {'class': 'kick_ball',\n",
       "   'end_frame': 118103,\n",
       "   'id': 1283,\n",
       "   'start_frame': 118071,\n",
       "   'video_id': 1283},\n",
       "  {'class': 'kiss',\n",
       "   'end_frame': 49988,\n",
       "   'id': 564,\n",
       "   'start_frame': 49626,\n",
       "   'video_id': 564},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 184628,\n",
       "   'id': 2017,\n",
       "   'start_frame': 184416,\n",
       "   'video_id': 2017},\n",
       "  {'class': 'pick',\n",
       "   'end_frame': 51127,\n",
       "   'id': 581,\n",
       "   'start_frame': 50991,\n",
       "   'video_id': 581},\n",
       "  {'class': 'pour',\n",
       "   'end_frame': 74351,\n",
       "   'id': 818,\n",
       "   'start_frame': 74236,\n",
       "   'video_id': 818},\n",
       "  {'class': 'pullup',\n",
       "   'end_frame': 38924,\n",
       "   'id': 443,\n",
       "   'start_frame': 38838,\n",
       "   'video_id': 443},\n",
       "  {'class': 'punch',\n",
       "   'end_frame': 23675,\n",
       "   'id': 259,\n",
       "   'start_frame': 23630,\n",
       "   'video_id': 259},\n",
       "  {'class': 'push',\n",
       "   'end_frame': 124239,\n",
       "   'id': 1343,\n",
       "   'start_frame': 124156,\n",
       "   'video_id': 1343},\n",
       "  {'class': 'pushup',\n",
       "   'end_frame': 98479,\n",
       "   'id': 1066,\n",
       "   'start_frame': 98399,\n",
       "   'video_id': 1066},\n",
       "  {'class': 'ride_bike',\n",
       "   'end_frame': 47700,\n",
       "   'id': 540,\n",
       "   'start_frame': 47589,\n",
       "   'video_id': 540},\n",
       "  {'class': 'ride_horse',\n",
       "   'end_frame': 162256,\n",
       "   'id': 1759,\n",
       "   'start_frame': 162125,\n",
       "   'video_id': 1759},\n",
       "  {'class': 'run',\n",
       "   'end_frame': 13972,\n",
       "   'id': 142,\n",
       "   'start_frame': 13949,\n",
       "   'video_id': 142},\n",
       "  {'class': 'shake_hands',\n",
       "   'end_frame': 26138,\n",
       "   'id': 287,\n",
       "   'start_frame': 26060,\n",
       "   'video_id': 287},\n",
       "  {'class': 'shoot_ball',\n",
       "   'end_frame': 153917,\n",
       "   'id': 1665,\n",
       "   'start_frame': 153838,\n",
       "   'video_id': 1665},\n",
       "  {'class': 'shoot_bow',\n",
       "   'end_frame': 128499,\n",
       "   'id': 1396,\n",
       "   'start_frame': 128309,\n",
       "   'video_id': 1396},\n",
       "  {'class': 'shoot_gun',\n",
       "   'end_frame': 90730,\n",
       "   'id': 983,\n",
       "   'start_frame': 90676,\n",
       "   'video_id': 983},\n",
       "  {'class': 'sit',\n",
       "   'end_frame': 18775,\n",
       "   'id': 198,\n",
       "   'start_frame': 18684,\n",
       "   'video_id': 198},\n",
       "  {'class': 'situp',\n",
       "   'end_frame': 67544,\n",
       "   'id': 750,\n",
       "   'start_frame': 67424,\n",
       "   'video_id': 750},\n",
       "  {'class': 'smile',\n",
       "   'end_frame': 47822,\n",
       "   'id': 542,\n",
       "   'start_frame': 47778,\n",
       "   'video_id': 542},\n",
       "  {'class': 'smoke',\n",
       "   'end_frame': 57891,\n",
       "   'id': 647,\n",
       "   'start_frame': 57784,\n",
       "   'video_id': 647},\n",
       "  {'class': 'somersault',\n",
       "   'end_frame': 7771,\n",
       "   'id': 89,\n",
       "   'start_frame': 7695,\n",
       "   'video_id': 89},\n",
       "  {'class': 'stand',\n",
       "   'end_frame': 125722,\n",
       "   'id': 1363,\n",
       "   'start_frame': 125671,\n",
       "   'video_id': 1363},\n",
       "  {'class': 'swing_baseball',\n",
       "   'end_frame': 9143,\n",
       "   'id': 103,\n",
       "   'start_frame': 9030,\n",
       "   'video_id': 103},\n",
       "  {'class': 'sword',\n",
       "   'end_frame': 186772,\n",
       "   'id': 2036,\n",
       "   'start_frame': 186663,\n",
       "   'video_id': 2036},\n",
       "  {'class': 'sword_exercise',\n",
       "   'end_frame': 170292,\n",
       "   'id': 1854,\n",
       "   'start_frame': 170037,\n",
       "   'video_id': 1854},\n",
       "  {'class': 'talk',\n",
       "   'end_frame': 63762,\n",
       "   'id': 716,\n",
       "   'start_frame': 63668,\n",
       "   'video_id': 716},\n",
       "  {'class': 'throw',\n",
       "   'end_frame': 42701,\n",
       "   'id': 484,\n",
       "   'start_frame': 42602,\n",
       "   'video_id': 484},\n",
       "  {'class': 'turn',\n",
       "   'end_frame': 20244,\n",
       "   'id': 216,\n",
       "   'start_frame': 20168,\n",
       "   'video_id': 216},\n",
       "  {'class': 'walk',\n",
       "   'end_frame': 11253,\n",
       "   'id': 118,\n",
       "   'start_frame': 11031,\n",
       "   'video_id': 118},\n",
       "  {'class': 'wave',\n",
       "   'end_frame': 33210,\n",
       "   'id': 370,\n",
       "   'start_frame': 33132,\n",
       "   'video_id': 370}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/seed_labels\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bound-retail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 51,\n",
       "  'current_dataset': {'classes': ['shoot_ball',\n",
       "    'somersault',\n",
       "    'stand',\n",
       "    'smile',\n",
       "    'pour',\n",
       "    'climb_stairs',\n",
       "    'flic_flac',\n",
       "    'situp',\n",
       "    'golf',\n",
       "    'pick',\n",
       "    'draw_sword',\n",
       "    'smoke',\n",
       "    'clap',\n",
       "    'walk',\n",
       "    'dribble',\n",
       "    'talk',\n",
       "    'pushup',\n",
       "    'fall_floor',\n",
       "    'catch',\n",
       "    'sword',\n",
       "    'kick_ball',\n",
       "    'cartwheel',\n",
       "    'punch',\n",
       "    'sword_exercise',\n",
       "    'shoot_bow',\n",
       "    'brush_hair',\n",
       "    'push',\n",
       "    'wave',\n",
       "    'eat',\n",
       "    'hug',\n",
       "    'swing_baseball',\n",
       "    'ride_horse',\n",
       "    'throw',\n",
       "    'run',\n",
       "    'sit',\n",
       "    'pullup',\n",
       "    'dive',\n",
       "    'turn',\n",
       "    'climb',\n",
       "    'chew',\n",
       "    'handstand',\n",
       "    'hit',\n",
       "    'laugh',\n",
       "    'kiss',\n",
       "    'drink',\n",
       "    'ride_bike',\n",
       "    'shake_hands',\n",
       "    'kick',\n",
       "    'fencing',\n",
       "    'jump',\n",
       "    'shoot_gun'],\n",
       "   'dataset_type': 'video_classification',\n",
       "   'license_citation': 'Kuehne, Hildegard, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre. \"HMDB: a large video database for human motion recognition.\" In 2011 International conference on computer vision, pp. 2556-2563. IEEE, 2011.',\n",
       "   'license_link': 'https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'hmdb',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 51,\n",
       "   'number_of_samples_test': 100,\n",
       "   'number_of_samples_train': 816,\n",
       "   'uid': 'hmdb'},\n",
       "  'current_label_budget_stages': [51, 102, 204, 408, 485, 577, 686, 816],\n",
       "  'date_created': 1615944140000,\n",
       "  'date_last_interacted': 1615944307536,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_video_classification',\n",
       "  'uid': 'rP42SIPvvFPYTAe56lbW',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "female-commission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['Session_Status']['budget_left_until_checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abandoned-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_images_and_classes(dataset_path: Path, session_token: str, data_type: str='sample') -> Tuple[List[str],List[str]]:\n",
    "    \"\"\"\n",
    "    Helper method to dynamically get the test labels and give us the possible classes that can be submitted\n",
    "    for the current dataset\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    \n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` dataset. \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Tuple[List[str], List[str]]\n",
    "        The list of test image ids needed to submit a prediction and the list of class names that you can predict against\n",
    "    \"\"\"\n",
    "    # Then we can just reference our current metadata to get our dataset name and use that in the path\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    current_dataset_classes = current_dataset['classes']\n",
    "\n",
    "    test_imgs_dir = dataset_path.joinpath(f\"{current_dataset_name}/{current_dataset_name}_{data_type}/test\")\n",
    "    test_imgs = [f.name for f in test_imgs_dir.iterdir() if f.is_file()]\n",
    "    return test_imgs, current_dataset_classes\n",
    "\n",
    "def generate_random_predictions_on_test_set(test_imgs: List[str], current_dataset_classes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a prediction dataframe for image classification based on random sampling from our available classes\n",
    "    \"\"\"\n",
    "    rand_lbls = [str(random.choice(current_dataset_classes)) for _ in range(len(test_imgs))]\n",
    "    df = pd.DataFrame({'id': test_imgs, 'class': rand_lbls})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "social-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = Path.home().joinpath('lwll_datasets/development')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "concrete-operations",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/lwll_datasets/development/hmdb/hmdb_sample/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f1eba067ff6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dataset_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_images_and_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASETS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-99863ed815d1>\u001b[0m in \u001b[0;36mget_test_images_and_classes\u001b[0;34m(dataset_path, session_token, data_type)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtest_imgs_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{current_dataset_name}/{current_dataset_name}_{data_type}/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_imgs_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dataset_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-99863ed815d1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtest_imgs_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{current_dataset_name}/{current_dataset_name}_{data_type}/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_imgs_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dataset_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/lwll_datasets/development/hmdb/hmdb_sample/test'"
     ]
    }
   ],
   "source": [
    "test_imgs, current_dataset_classes = get_test_images_and_classes(DATASETS_PATH, session_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "vietnamese-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_random_predictions_on_test_set(test_imgs, current_dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "professional-evidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1169.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3505.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9271.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1753.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>8127.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3822.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4874.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3425.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6397.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class\n",
       "0    4046.png     8\n",
       "1    1169.png     1\n",
       "2    3505.png     3\n",
       "3    9271.png     1\n",
       "4    1753.png     1\n",
       "..        ...   ...\n",
       "995  8127.png     4\n",
       "996  3822.png     4\n",
       "997  4874.png     4\n",
       "998  3425.png     2\n",
       "999  6397.png     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "secure-polyester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 10,\n",
       "  'budget_used': 10,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615924481881,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "altered-pound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': '0', 'id': '33665.png'},\n",
       "  {'class': '1', 'id': '6371.png'},\n",
       "  {'class': '2', 'id': '45055.png'},\n",
       "  {'class': '3', 'id': '40914.png'},\n",
       "  {'class': '4', 'id': '6733.png'},\n",
       "  {'class': '5', 'id': '16400.png'},\n",
       "  {'class': '6', 'id': '14405.png'},\n",
       "  {'class': '7', 'id': '55078.png'},\n",
       "  {'class': '8', 'id': '17808.png'},\n",
       "  {'class': '9', 'id': '10944.png'}]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.get(f\"{url}/seed_labels\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "lined-mustang",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 20,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925773325,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "caring-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, current_dataset_classes = get_test_images_and_classes(DATASETS_PATH, session_token)\n",
    "df = generate_random_predictions_on_test_set(test_imgs, current_dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "exotic-torture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 20,\n",
       "  'budget_used': 20,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925773325,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "jewish-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': '0', 'id': '49011.png'},\n",
       "  {'class': '0', 'id': '40303.png'},\n",
       "  {'class': '1', 'id': '30274.png'},\n",
       "  {'class': '1', 'id': '9251.png'},\n",
       "  {'class': '2', 'id': '38652.png'},\n",
       "  {'class': '2', 'id': '1374.png'},\n",
       "  {'class': '3', 'id': '5412.png'},\n",
       "  {'class': '3', 'id': '49882.png'},\n",
       "  {'class': '4', 'id': '32895.png'},\n",
       "  {'class': '4', 'id': '45778.png'},\n",
       "  {'class': '5', 'id': '41243.png'},\n",
       "  {'class': '5', 'id': '31863.png'},\n",
       "  {'class': '6', 'id': '2300.png'},\n",
       "  {'class': '6', 'id': '38643.png'},\n",
       "  {'class': '7', 'id': '58671.png'},\n",
       "  {'class': '7', 'id': '9538.png'},\n",
       "  {'class': '8', 'id': '22166.png'},\n",
       "  {'class': '8', 'id': '43944.png'},\n",
       "  {'class': '9', 'id': '31275.png'},\n",
       "  {'class': '9', 'id': '20434.png'}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.get(f\"{url}/seed_labels\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "interim-automation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 40,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925885014,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "muslim-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, current_dataset_classes = get_test_images_and_classes(DATASETS_PATH, session_token)\n",
    "df = generate_random_predictions_on_test_set(test_imgs, current_dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "detailed-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 40,\n",
       "  'budget_used': 40,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925885014,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "widespread-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_labels_from_train_dataset(dataset_path: Path, session_token: str, n: int=None, data_type: str='sample') -> List[str]:\n",
    "    \"\"\"\n",
    "    Helper function to get a random `n` image ids from our train dataset to request labels for\n",
    "    from the api\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` size dataset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    List[str]\n",
    "        A list of n unique image ids for the current session dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    budget_left = r.json()['Session_Status']['budget_left_until_checkpoint']\n",
    "    print(f\"budget_left is {budget_left}\")\n",
    "    if not n:\n",
    "        n = budget_left\n",
    "    \n",
    "    train_imgs_dir = dataset_path.joinpath(f\"{current_dataset_name}/{current_dataset_name}_{data_type}/train\")\n",
    "    train_imgs = [f.name for f in train_imgs_dir.iterdir() if f.is_file()]\n",
    "    print(f\"train_imgs: {train_imgs[0:4]}\")\n",
    "    \n",
    "    random_ids = random.sample(train_imgs, k=n)\n",
    "    return random_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "innovative-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget_left is 40\n",
      "train_imgs: ['5238.png', '42470.png', '2944.png', '16089.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['14160.png',\n",
       " '12840.png',\n",
       " '15889.png',\n",
       " '22010.png',\n",
       " '39328.png',\n",
       " '52250.png',\n",
       " '38606.png',\n",
       " '6371.png',\n",
       " '49069.png',\n",
       " '45703.png']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_be_labeled = get_random_labels_from_train_dataset(DATASETS_PATH, session_token, n=10)\n",
    "images_to_be_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "decent-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': '1', 'id': '6371.png'},\n",
       "  {'class': '2', 'id': '22010.png'},\n",
       "  {'class': '1', 'id': '39328.png'},\n",
       "  {'class': '7', 'id': '49069.png'},\n",
       "  {'class': '8', 'id': '38606.png'},\n",
       "  {'class': '1', 'id': '45703.png'},\n",
       "  {'class': '0', 'id': '14160.png'},\n",
       "  {'class': '8', 'id': '52250.png'},\n",
       "  {'class': '9', 'id': '12840.png'},\n",
       "  {'class': '3', 'id': '15889.png'}],\n",
       " 'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 30,\n",
       "  'budget_used': 50,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925934746,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "query = {\n",
    "    'example_ids': images_to_be_labeled\n",
    "}\n",
    "\n",
    "r = requests.post(f\"{url}/query_labels\", json=query, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "novel-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget_left is 30\n",
      "train_imgs: ['5238.png', '42470.png', '2944.png', '16089.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['35102.png',\n",
       " '18742.png',\n",
       " '29804.png',\n",
       " '3182.png',\n",
       " '29720.png',\n",
       " '13624.png',\n",
       " '18451.png',\n",
       " '1380.png',\n",
       " '5775.png',\n",
       " '15654.png',\n",
       " '29423.png',\n",
       " '44395.png',\n",
       " '59668.png',\n",
       " '46864.png',\n",
       " '52098.png',\n",
       " '2557.png',\n",
       " '4922.png',\n",
       " '41956.png',\n",
       " '33443.png',\n",
       " '58374.png',\n",
       " '49105.png',\n",
       " '58451.png',\n",
       " '42697.png',\n",
       " '39245.png',\n",
       " '36073.png',\n",
       " '5684.png',\n",
       " '23929.png',\n",
       " '57242.png',\n",
       " '50632.png',\n",
       " '34989.png']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_be_labeled = get_random_labels_from_train_dataset(DATASETS_PATH, session_token, n=30)\n",
    "images_to_be_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "satisfied-contractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': '8', 'id': '46864.png'},\n",
       "  {'class': '3', 'id': '52098.png'},\n",
       "  {'class': '0', 'id': '34989.png'},\n",
       "  {'class': '0', 'id': '2557.png'},\n",
       "  {'class': '1', 'id': '18451.png'},\n",
       "  {'class': '9', 'id': '59668.png'},\n",
       "  {'class': '4', 'id': '39245.png'},\n",
       "  {'class': '2', 'id': '44395.png'},\n",
       "  {'class': '3', 'id': '23929.png'},\n",
       "  {'class': '1', 'id': '58451.png'},\n",
       "  {'class': '4', 'id': '49105.png'},\n",
       "  {'class': '4', 'id': '1380.png'},\n",
       "  {'class': '6', 'id': '5684.png'},\n",
       "  {'class': '7', 'id': '35102.png'},\n",
       "  {'class': '4', 'id': '42697.png'},\n",
       "  {'class': '7', 'id': '29423.png'},\n",
       "  {'class': '5', 'id': '29804.png'},\n",
       "  {'class': '9', 'id': '33443.png'},\n",
       "  {'class': '5', 'id': '57242.png'},\n",
       "  {'class': '8', 'id': '58374.png'},\n",
       "  {'class': '1', 'id': '50632.png'},\n",
       "  {'class': '2', 'id': '29720.png'},\n",
       "  {'class': '4', 'id': '3182.png'},\n",
       "  {'class': '8', 'id': '5775.png'},\n",
       "  {'class': '3', 'id': '18742.png'},\n",
       "  {'class': '6', 'id': '4922.png'},\n",
       "  {'class': '1', 'id': '41956.png'},\n",
       "  {'class': '4', 'id': '36073.png'},\n",
       "  {'class': '9', 'id': '15654.png'},\n",
       "  {'class': '2', 'id': '13624.png'}],\n",
       " 'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 80,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615926392531,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "query = {\n",
    "    'example_ids': images_to_be_labeled\n",
    "}\n",
    "\n",
    "r = requests.post(f\"{url}/query_labels\", json=query, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "comparable-lesbian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 18,\n",
       "  'budget_used': 95,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615926541255,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_random_predictions_on_test_set(test_imgs, current_dataset_classes)\n",
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "environmental-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JPL:\n",
    "    \"\"\"\n",
    "    A class to interact with JPL-like APIs.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_url, team_secret, gov_team_secret, dataset_type):\n",
    "        \"\"\"\n",
    "        Create a new JPL object.\n",
    "        \"\"\"\n",
    "\n",
    "        self.team_secret = team_secret\n",
    "        self.gov_team_secret = gov_team_secret\n",
    "        self.url = api_url \n",
    "        self.session_token = ''\n",
    "        self.data_type = dataset_type\n",
    "\n",
    "\n",
    "    def get_available_tasks(self, problem_type):\n",
    "        \"\"\"\n",
    "        Get all available tasks.\n",
    "        :return: A list of tasks (problems)\n",
    "        \"\"\"\n",
    "        headers = {'user_secret': self.team_secret,\n",
    "                   'govteam_secret': self.gov_team_secret\n",
    "                   }\n",
    "        r = requests.get(self.url + \"/list_tasks\", headers=headers)\n",
    "        task_list = r.json()['tasks']\n",
    "        #print(task_list)\n",
    "\n",
    "        subset_tasks = []\n",
    "        for _task in task_list:\n",
    "            r = requests.get(self.url+\"/task_metadata/\"+_task, headers=headers)\n",
    "            task_metadata = r.json()\n",
    "            #print(task_metadata)\n",
    "            if task_metadata['task_metadata']['problem_type'] == problem_type:\n",
    "                subset_tasks.append(_task)\n",
    "        return subset_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "portable-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpl = JPL(url, secret, gov_secret, dataset_type='sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stunning-milwaukee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem_test_video_classification']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpl.get_available_tasks('video_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-shopping",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
