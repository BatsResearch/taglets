{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "twenty-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "seventh-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret = 'a5aed2a8-db80-4b22-bf72-11f2d0765572'\n",
    "gov_secret = 'mock-secret'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "thousand-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://api-dev.lollllz.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "centered-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'user_secret': secret, 'govteam_secret': gov_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "governing-description",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': ['06023f86-a66b-4b2c-8b8b-951f5edd0f22',\n",
       "  '4d924004-347e-4043-8dd2-f4f8b0f52efd',\n",
       "  '6d5e1f85-5d8f-4cc9-8184-299db03713f4',\n",
       "  '7c103ece-fd8e-483b-bede-b55e5ea57fe9',\n",
       "  '923cbe9c-1e4f-4a05-a156-dc972ef5edf5',\n",
       "  'b01a6738-0b85-46c2-9318-16c3e2ef0f6d',\n",
       "  'bbfadb2c-c7c3-4596-b548-3dd01a6d1d2c',\n",
       "  'd48f8a99-ba12-4df8-a74a-d06413b0f1ba',\n",
       "  'problem_test_image_classification',\n",
       "  'problem_test_obj_detection',\n",
       "  'problem_test_video_classification']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(f\"{url}/list_tasks\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "incorrect-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06023f86-a66b-4b2c-8b8b-951f5edd0f22',\n",
       " '4d924004-347e-4043-8dd2-f4f8b0f52efd',\n",
       " '6d5e1f85-5d8f-4cc9-8184-299db03713f4',\n",
       " '7c103ece-fd8e-483b-bede-b55e5ea57fe9',\n",
       " '923cbe9c-1e4f-4a05-a156-dc972ef5edf5',\n",
       " 'b01a6738-0b85-46c2-9318-16c3e2ef0f6d',\n",
       " 'bbfadb2c-c7c3-4596-b548-3dd01a6d1d2c',\n",
       " 'd48f8a99-ba12-4df8-a74a-d06413b0f1ba']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks = [task for task in r.json()['tasks'] if task not in ['problem_test_image_classification',\n",
    "  'problem_test_obj_detection', 'problem_test_video_classification']]\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "auburn-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"task_metadata\": {\n",
      "    \"adaptation_dataset\": \"hmdb\",\n",
      "    \"adaptation_evaluation_metrics\": [\n",
      "      \"accuracy\"\n",
      "    ],\n",
      "    \"adaptation_label_budget_full\": [\n",
      "      51,\n",
      "      102,\n",
      "      204,\n",
      "      408,\n",
      "      779,\n",
      "      1486,\n",
      "      2836,\n",
      "      5412\n",
      "    ],\n",
      "    \"adaptation_label_budget_sample\": [\n",
      "      51,\n",
      "      102,\n",
      "      204,\n",
      "      408,\n",
      "      485,\n",
      "      577,\n",
      "      686,\n",
      "      816\n",
      "    ],\n",
      "    \"base_dataset\": \"hmdb\",\n",
      "    \"base_evaluation_metrics\": [\n",
      "      \"accuracy\"\n",
      "    ],\n",
      "    \"base_label_budget_full\": [\n",
      "      51,\n",
      "      102,\n",
      "      204,\n",
      "      408,\n",
      "      779,\n",
      "      1486,\n",
      "      2836,\n",
      "      5412\n",
      "    ],\n",
      "    \"base_label_budget_sample\": [\n",
      "      51,\n",
      "      102,\n",
      "      204,\n",
      "      408,\n",
      "      485,\n",
      "      577,\n",
      "      686,\n",
      "      816\n",
      "    ],\n",
      "    \"problem_type\": \"video_classification\",\n",
      "    \"task_id\": \"problem_test_video_classification\",\n",
      "    \"whitelist\": [\n",
      "      \"imagenet_1k\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "r = requests.get(f\"{url}/task_metadata/problem_test_video_classification\", headers=headers)\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "statistical-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagenet_1k']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['task_metadata']['whitelist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "positive-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset_metadata\": {\n",
      "    \"classes\": [\n",
      "      \"Cat furniture\",\n",
      "      \"Cheese\",\n",
      "      \"Kettle\",\n",
      "      \"Bicycle\",\n",
      "      \"Chest of drawers\",\n",
      "      \"Shorts\",\n",
      "      \"Desk\",\n",
      "      \"Fox\",\n",
      "      \"Plant\",\n",
      "      \"Footwear\",\n",
      "      \"Bathroom accessory\",\n",
      "      \"Flute\",\n",
      "      \"Light switch\",\n",
      "      \"Sea lion\",\n",
      "      \"Whisk\",\n",
      "      \"Flowerpot\",\n",
      "      \"Treadmill\",\n",
      "      \"Bicycle helmet\",\n",
      "      \"Cheetah\",\n",
      "      \"Glove\",\n",
      "      \"Blue jay\",\n",
      "      \"Grape\",\n",
      "      \"Tent\",\n",
      "      \"Microphone\",\n",
      "      \"Clothing\",\n",
      "      \"Moths and butterflies\",\n",
      "      \"Radish\",\n",
      "      \"Pancake\",\n",
      "      \"Owl\",\n",
      "      \"Furniture\",\n",
      "      \"Banana\",\n",
      "      \"Helmet\",\n",
      "      \"Digital clock\",\n",
      "      \"Strawberry\",\n",
      "      \"Measuring cup\",\n",
      "      \"Girl\",\n",
      "      \"Candy\",\n",
      "      \"Bat (Animal)\",\n",
      "      \"Jaguar (Animal)\",\n",
      "      \"Scissors\",\n",
      "      \"Ipod\",\n",
      "      \"Canoe\",\n",
      "      \"Pencil sharpener\",\n",
      "      \"Willow\",\n",
      "      \"Human head\",\n",
      "      \"Submarine sandwich\",\n",
      "      \"Waste container\",\n",
      "      \"Axe\",\n",
      "      \"Spoon\",\n",
      "      \"Lavender (Plant)\",\n",
      "      \"Bell pepper\",\n",
      "      \"Accordion\",\n",
      "      \"Sandwich\",\n",
      "      \"Bicycle wheel\",\n",
      "      \"Dessert\",\n",
      "      \"Baked goods\",\n",
      "      \"Weapon\",\n",
      "      \"Bird\",\n",
      "      \"Plastic bag\",\n",
      "      \"Turkey\",\n",
      "      \"Piano\",\n",
      "      \"Koala\",\n",
      "      \"Van\",\n",
      "      \"Human foot\",\n",
      "      \"Caterpillar\",\n",
      "      \"Computer keyboard\",\n",
      "      \"Swimwear\",\n",
      "      \"Harbor seal\",\n",
      "      \"Salt and pepper shakers\",\n",
      "      \"Camera\",\n",
      "      \"Stairs\",\n",
      "      \"Fork\",\n",
      "      \"Barge\",\n",
      "      \"Snowmobile\",\n",
      "      \"Parachute\",\n",
      "      \"Tennis ball\",\n",
      "      \"Vehicle\",\n",
      "      \"Antelope\",\n",
      "      \"Poster\",\n",
      "      \"Guitar\",\n",
      "      \"Crown\",\n",
      "      \"Centipede\",\n",
      "      \"Surfboard\",\n",
      "      \"Mixer\",\n",
      "      \"Fast food\",\n",
      "      \"Bread\",\n",
      "      \"Pen\",\n",
      "      \"Bowling equipment\",\n",
      "      \"Alarm clock\",\n",
      "      \"Taco\",\n",
      "      \"Fire hydrant\",\n",
      "      \"Torch\",\n",
      "      \"Person\",\n",
      "      \"Golf cart\",\n",
      "      \"Ant\",\n",
      "      \"Hair spray\",\n",
      "      \"Wood-burning stove\",\n",
      "      \"Tomato\",\n",
      "      \"Frog\",\n",
      "      \"Rays and skates\",\n",
      "      \"Bottle\",\n",
      "      \"Coffee table\",\n",
      "      \"Mug\",\n",
      "      \"Dress\",\n",
      "      \"Pressure cooker\",\n",
      "      \"Lantern\",\n",
      "      \"Drinking straw\",\n",
      "      \"Loveseat\",\n",
      "      \"Shrimp\",\n",
      "      \"Stationary bicycle\",\n",
      "      \"Snack\",\n",
      "      \"Waffle\",\n",
      "      \"Cannon\",\n",
      "      \"Cabbage\",\n",
      "      \"Insect\",\n",
      "      \"Pretzel\",\n",
      "      \"Shelf\",\n",
      "      \"Tennis racket\",\n",
      "      \"Shotgun\",\n",
      "      \"Cookie\",\n",
      "      \"Pizza\",\n",
      "      \"Red panda\",\n",
      "      \"Skateboard\",\n",
      "      \"Turtle\",\n",
      "      \"Cattle\",\n",
      "      \"Wine rack\",\n",
      "      \"Cosmetics\",\n",
      "      \"Door handle\",\n",
      "      \"Computer mouse\",\n",
      "      \"Infant bed\",\n",
      "      \"Castle\",\n",
      "      \"Sword\",\n",
      "      \"Doughnut\",\n",
      "      \"Goggles\",\n",
      "      \"Monkey\",\n",
      "      \"Seat belt\",\n",
      "      \"Crutch\",\n",
      "      \"Maracas\",\n",
      "      \"Zebra\",\n",
      "      \"Kitchen appliance\",\n",
      "      \"Toothbrush\",\n",
      "      \"Spice rack\",\n",
      "      \"Beer\",\n",
      "      \"Polar bear\",\n",
      "      \"Paper towel\",\n",
      "      \"Ski\",\n",
      "      \"Missile\",\n",
      "      \"Racket\",\n",
      "      \"Golf ball\",\n",
      "      \"Nail (Construction)\",\n",
      "      \"Swim cap\",\n",
      "      \"Billboard\",\n",
      "      \"Mammal\",\n",
      "      \"Roller skates\",\n",
      "      \"Eagle\",\n",
      "      \"Kitchen knife\",\n",
      "      \"Billiard table\",\n",
      "      \"Coconut\",\n",
      "      \"Lily\",\n",
      "      \"Harmonica\",\n",
      "      \"Backpack\",\n",
      "      \"Candle\",\n",
      "      \"Bottle opener\",\n",
      "      \"Indoor rower\",\n",
      "      \"Training bench\",\n",
      "      \"Door\",\n",
      "      \"Couch\",\n",
      "      \"Dog\",\n",
      "      \"Towel\",\n",
      "      \"Flying disc\",\n",
      "      \"Jacuzzi\",\n",
      "      \"Miniskirt\",\n",
      "      \"Woman\",\n",
      "      \"Ball\",\n",
      "      \"Bow and arrow\",\n",
      "      \"Tree house\",\n",
      "      \"Potato\",\n",
      "      \"Woodpecker\",\n",
      "      \"Handbag\",\n",
      "      \"Sock\",\n",
      "      \"Cream\",\n",
      "      \"Doll\",\n",
      "      \"Tablet computer\",\n",
      "      \"Carrot\",\n",
      "      \"Tripod\",\n",
      "      \"Sheep\",\n",
      "      \"Table tennis racket\",\n",
      "      \"Hot dog\",\n",
      "      \"Hedgehog\",\n",
      "      \"Bull\",\n",
      "      \"Convenience store\",\n",
      "      \"Falcon\",\n",
      "      \"Ambulance\",\n",
      "      \"Panda\",\n",
      "      \"Deer\",\n",
      "      \"Suit\",\n",
      "      \"Tank\",\n",
      "      \"Wardrobe\",\n",
      "      \"Hair dryer\",\n",
      "      \"Window\",\n",
      "      \"Beetle\",\n",
      "      \"Fashion accessory\",\n",
      "      \"Chicken\",\n",
      "      \"Wheelchair\",\n",
      "      \"Drum\",\n",
      "      \"Fruit\",\n",
      "      \"Microwave oven\",\n",
      "      \"Stool\",\n",
      "      \"Watermelon\",\n",
      "      \"Traffic sign\",\n",
      "      \"Pineapple\",\n",
      "      \"Kite\",\n",
      "      \"Ladybug\",\n",
      "      \"Dolphin\",\n",
      "      \"Lemon\",\n",
      "      \"House\",\n",
      "      \"Ostrich\",\n",
      "      \"Sink\",\n",
      "      \"Bust\",\n",
      "      \"Marine mammal\",\n",
      "      \"Dragonfly\",\n",
      "      \"Balloon\",\n",
      "      \"Calculator\",\n",
      "      \"Bowl\",\n",
      "      \"Fax\",\n",
      "      \"Boat\",\n",
      "      \"Sofa bed\",\n",
      "      \"Tableware\",\n",
      "      \"Countertop\",\n",
      "      \"Food processor\",\n",
      "      \"Sparrow\",\n",
      "      \"Laptop\",\n",
      "      \"Telephone\",\n",
      "      \"Lion\",\n",
      "      \"Snake\",\n",
      "      \"Balance beam\",\n",
      "      \"Canary\",\n",
      "      \"Wheel\",\n",
      "      \"Hamburger\",\n",
      "      \"Tower\",\n",
      "      \"Shower\",\n",
      "      \"Soap dispenser\",\n",
      "      \"Garden Asparagus\",\n",
      "      \"Coat\",\n",
      "      \"Mule\",\n",
      "      \"Boy\",\n",
      "      \"Taxi\",\n",
      "      \"Paper cutter\",\n",
      "      \"Seafood\",\n",
      "      \"Nightstand\",\n",
      "      \"Mouse\",\n",
      "      \"Tart\",\n",
      "      \"Beehive\",\n",
      "      \"Picture frame\",\n",
      "      \"Cucumber\",\n",
      "      \"Toilet\",\n",
      "      \"Washing machine\",\n",
      "      \"Sports uniform\",\n",
      "      \"Tortoise\",\n",
      "      \"Office building\",\n",
      "      \"Sewing machine\",\n",
      "      \"Rugby ball\",\n",
      "      \"Leopard\",\n",
      "      \"Sandal\",\n",
      "      \"Raccoon\",\n",
      "      \"Horse\",\n",
      "      \"Skyscraper\",\n",
      "      \"Slow cooker\",\n",
      "      \"Hiking equipment\",\n",
      "      \"Motorcycle\",\n",
      "      \"Squash (Plant)\",\n",
      "      \"Serving tray\",\n",
      "      \"Scale\",\n",
      "      \"Ruler\",\n",
      "      \"Curtain\",\n",
      "      \"Artichoke\",\n",
      "      \"Pitcher (Container)\",\n",
      "      \"Ice cream\",\n",
      "      \"Human nose\",\n",
      "      \"Tap\",\n",
      "      \"Earrings\",\n",
      "      \"Mushroom\",\n",
      "      \"Wine glass\",\n",
      "      \"Cello\",\n",
      "      \"Dumbbell\",\n",
      "      \"Beaker\",\n",
      "      \"Harpsichord\",\n",
      "      \"Snail\",\n",
      "      \"Lizard\",\n",
      "      \"Broccoli\",\n",
      "      \"Skull\",\n",
      "      \"Light bulb\",\n",
      "      \"Box\",\n",
      "      \"Fedora\",\n",
      "      \"Pumpkin\",\n",
      "      \"Sun hat\",\n",
      "      \"Violin\",\n",
      "      \"Crocodile\",\n",
      "      \"Scarf\",\n",
      "      \"Teddy bear\",\n",
      "      \"Burrito\",\n",
      "      \"Parking meter\",\n",
      "      \"Grapefruit\",\n",
      "      \"Shirt\",\n",
      "      \"Trombone\",\n",
      "      \"Winter melon\",\n",
      "      \"Briefcase\",\n",
      "      \"Dinosaur\",\n",
      "      \"Drawer\",\n",
      "      \"Ratchet (Device)\",\n",
      "      \"Vegetable\",\n",
      "      \"Milk\",\n",
      "      \"Boot\",\n",
      "      \"Helicopter\",\n",
      "      \"Gas stove\",\n",
      "      \"Toy\",\n",
      "      \"Egg (Food)\",\n",
      "      \"Swan\",\n",
      "      \"Corded phone\",\n",
      "      \"Human arm\",\n",
      "      \"Guacamole\",\n",
      "      \"Swimming pool\",\n",
      "      \"Lamp\",\n",
      "      \"Toaster\",\n",
      "      \"Necklace\",\n",
      "      \"Car\",\n",
      "      \"Land vehicle\",\n",
      "      \"Sombrero\",\n",
      "      \"Rocket\",\n",
      "      \"Magpie\",\n",
      "      \"Human eye\",\n",
      "      \"Vehicle registration plate\",\n",
      "      \"Fountain\",\n",
      "      \"Ladle\",\n",
      "      \"Cassette deck\",\n",
      "      \"Hat\",\n",
      "      \"Eraser\",\n",
      "      \"Human beard\",\n",
      "      \"Television\",\n",
      "      \"Mechanical fan\",\n",
      "      \"Reptile\",\n",
      "      \"Can opener\",\n",
      "      \"Snowboard\",\n",
      "      \"Pasta\",\n",
      "      \"Gondola\",\n",
      "      \"Otter\",\n",
      "      \"Barrel\",\n",
      "      \"Human leg\",\n",
      "      \"Chopsticks\",\n",
      "      \"Waffle iron\",\n",
      "      \"Sea turtle\",\n",
      "      \"Baseball bat\",\n",
      "      \"Human mouth\",\n",
      "      \"Human hand\",\n",
      "      \"Stapler\",\n",
      "      \"Tea\",\n",
      "      \"Medical equipment\",\n",
      "      \"Facial tissue holder\",\n",
      "      \"Human hair\",\n",
      "      \"Lobster\",\n",
      "      \"Seahorse\",\n",
      "      \"Starfish\",\n",
      "      \"Musical instrument\",\n",
      "      \"Pomegranate\",\n",
      "      \"Sculpture\",\n",
      "      \"Screwdriver\",\n",
      "      \"Flashlight\",\n",
      "      \"Bear\",\n",
      "      \"Dagger\",\n",
      "      \"Blender\",\n",
      "      \"Umbrella\",\n",
      "      \"Grinder\",\n",
      "      \"Bee\",\n",
      "      \"Human body\",\n",
      "      \"Pizza cutter\",\n",
      "      \"Cooking spray\",\n",
      "      \"Truck\",\n",
      "      \"Goat\",\n",
      "      \"Kitchen utensil\",\n",
      "      \"Vase\",\n",
      "      \"Invertebrate\",\n",
      "      \"Oven\",\n",
      "      \"Palm tree\",\n",
      "      \"Cupboard\",\n",
      "      \"Watercraft\",\n",
      "      \"Saucer\",\n",
      "      \"Penguin\",\n",
      "      \"Alpaca\",\n",
      "      \"Spider\",\n",
      "      \"Personal flotation device\",\n",
      "      \"Saxophone\",\n",
      "      \"Jet ski\",\n",
      "      \"Pillow\",\n",
      "      \"Kitchen & dining room table\",\n",
      "      \"Chair\",\n",
      "      \"Dishwasher\",\n",
      "      \"Christmas tree\",\n",
      "      \"Punching bag\",\n",
      "      \"Traffic light\",\n",
      "      \"Rose\",\n",
      "      \"Tick\",\n",
      "      \"Bed\",\n",
      "      \"Human ear\",\n",
      "      \"Flag\",\n",
      "      \"Sushi\",\n",
      "      \"Carnivore\",\n",
      "      \"Clock\",\n",
      "      \"Football helmet\",\n",
      "      \"Plate\",\n",
      "      \"Hammer\",\n",
      "      \"Chime\",\n",
      "      \"Tiara\",\n",
      "      \"Bathroom cabinet\",\n",
      "      \"Power plugs and sockets\",\n",
      "      \"Tire\",\n",
      "      \"Window blind\",\n",
      "      \"Trumpet\",\n",
      "      \"Goose\",\n",
      "      \"Porch\",\n",
      "      \"Auto part\",\n",
      "      \"Cutting board\",\n",
      "      \"French horn\",\n",
      "      \"Mobile phone\",\n",
      "      \"Common sunflower\",\n",
      "      \"Coffee\",\n",
      "      \"Banjo\",\n",
      "      \"Spatula\",\n",
      "      \"Popcorn\",\n",
      "      \"Glasses\",\n",
      "      \"Zucchini\",\n",
      "      \"Shellfish\",\n",
      "      \"Stethoscope\",\n",
      "      \"Snowman\",\n",
      "      \"Croissant\",\n",
      "      \"Personal care\",\n",
      "      \"Brown bear\",\n",
      "      \"Sports equipment\",\n",
      "      \"Camel\",\n",
      "      \"Honeycomb\",\n",
      "      \"Kangaroo\",\n",
      "      \"Peach\",\n",
      "      \"Office supplies\",\n",
      "      \"Trousers\",\n",
      "      \"Rabbit\",\n",
      "      \"Duck\",\n",
      "      \"Table\",\n",
      "      \"Goldfish\",\n",
      "      \"Salad\",\n",
      "      \"Tree\",\n",
      "      \"Baseball glove\",\n",
      "      \"Home appliance\",\n",
      "      \"Porcupine\",\n",
      "      \"Man\",\n",
      "      \"Scoreboard\",\n",
      "      \"Jug\",\n",
      "      \"Ring binder\",\n",
      "      \"Chisel\",\n",
      "      \"Remote control\",\n",
      "      \"Book\",\n",
      "      \"Dice\",\n",
      "      \"Isopod\",\n",
      "      \"Building\",\n",
      "      \"Rifle\",\n",
      "      \"Oboe\",\n",
      "      \"Studio couch\",\n",
      "      \"Harp\",\n",
      "      \"High heels\",\n",
      "      \"Segway\",\n",
      "      \"Humidifier\",\n",
      "      \"Pencil case\",\n",
      "      \"Skirt\",\n",
      "      \"Pear\",\n",
      "      \"Cricket ball\",\n",
      "      \"Jellyfish\",\n",
      "      \"Brassiere\",\n",
      "      \"Bagel\",\n",
      "      \"Drill (Tool)\",\n",
      "      \"Tiger\",\n",
      "      \"Horizontal bar\",\n",
      "      \"Plumbing fixture\",\n",
      "      \"Submarine\",\n",
      "      \"Hand dryer\",\n",
      "      \"Heater\",\n",
      "      \"Animal\",\n",
      "      \"Food\",\n",
      "      \"Houseplant\",\n",
      "      \"Snowplow\",\n",
      "      \"Organ (Musical Instrument)\",\n",
      "      \"Fireplace\",\n",
      "      \"Closet\",\n",
      "      \"Dairy Product\",\n",
      "      \"Squid\",\n",
      "      \"Chainsaw\",\n",
      "      \"Common fig\",\n",
      "      \"Ceiling fan\",\n",
      "      \"Whale\",\n",
      "      \"Bathtub\",\n",
      "      \"Platter\",\n",
      "      \"Belt\",\n",
      "      \"Handgun\",\n",
      "      \"Giraffe\",\n",
      "      \"Unicycle\",\n",
      "      \"Perfume\",\n",
      "      \"Tin can\",\n",
      "      \"French fries\",\n",
      "      \"Orange\",\n",
      "      \"Ladder\",\n",
      "      \"Cake stand\",\n",
      "      \"Band-aid\",\n",
      "      \"Marine invertebrates\",\n",
      "      \"Wine\",\n",
      "      \"Maple\",\n",
      "      \"Raven\",\n",
      "      \"Picnic basket\",\n",
      "      \"Sunglasses\",\n",
      "      \"Cart\",\n",
      "      \"Street light\",\n",
      "      \"Oyster\",\n",
      "      \"Mango\",\n",
      "      \"Crab\",\n",
      "      \"Face powder\",\n",
      "      \"Parrot\",\n",
      "      \"Lynx\",\n",
      "      \"Refrigerator\",\n",
      "      \"Scorpion\",\n",
      "      \"Pastry\",\n",
      "      \"Watch\",\n",
      "      \"Fish\",\n",
      "      \"Envelope\",\n",
      "      \"Cocktail shaker\",\n",
      "      \"Skunk\",\n",
      "      \"Drink\",\n",
      "      \"Teapot\",\n",
      "      \"Human face\",\n",
      "      \"Apple\",\n",
      "      \"Cantaloupe\",\n",
      "      \"Lighthouse\",\n",
      "      \"Shark\",\n",
      "      \"Cocktail\",\n",
      "      \"Bidet\",\n",
      "      \"Computer monitor\",\n",
      "      \"Airplane\",\n",
      "      \"Rhinoceros\",\n",
      "      \"Paddle\",\n",
      "      \"Bronze sculpture\",\n",
      "      \"Juice\",\n",
      "      \"Aircraft\",\n",
      "      \"Coffeemaker\",\n",
      "      \"Cabinetry\",\n",
      "      \"Stop sign\",\n",
      "      \"Toilet paper\",\n",
      "      \"Bomb\",\n",
      "      \"Adhesive tape\",\n",
      "      \"Hippopotamus\",\n",
      "      \"Pig\",\n",
      "      \"Diaper\",\n",
      "      \"Cat\",\n",
      "      \"Coffee cup\",\n",
      "      \"Suitcase\",\n",
      "      \"Luggage and bags\",\n",
      "      \"Bookcase\",\n",
      "      \"Train\",\n",
      "      \"Stretcher\",\n",
      "      \"Squirrel\",\n",
      "      \"Wrench\",\n",
      "      \"Musical keyboard\",\n",
      "      \"Tie\",\n",
      "      \"Jeans\",\n",
      "      \"Limousine\",\n",
      "      \"Wok\",\n",
      "      \"Volleyball (Ball)\",\n",
      "      \"Hamster\",\n",
      "      \"Knife\",\n",
      "      \"Tool\",\n",
      "      \"Bench\",\n",
      "      \"Elephant\",\n",
      "      \"Armadillo\",\n",
      "      \"Wall clock\",\n",
      "      \"Headphones\",\n",
      "      \"Whiteboard\",\n",
      "      \"Flower\",\n",
      "      \"Mixing bowl\",\n",
      "      \"Frying pan\",\n",
      "      \"Bus\",\n",
      "      \"Football\",\n",
      "      \"Syringe\",\n",
      "      \"Lipstick\",\n",
      "      \"Jacket\",\n",
      "      \"Filing cabinet\",\n",
      "      \"Container\",\n",
      "      \"Dog bed\",\n",
      "      \"Muffin\",\n",
      "      \"Coin\",\n",
      "      \"Kitchenware\",\n",
      "      \"Butterfly\",\n",
      "      \"Cake\",\n",
      "      \"Cowboy hat\",\n",
      "      \"Binoculars\",\n",
      "      \"Printer\",\n",
      "      \"Worm\",\n",
      "      \"Mirror\"\n",
      "    ],\n",
      "    \"dataset_type\": \"object_detection\",\n",
      "    \"full_number_of_classes\": 601,\n",
      "    \"full_number_of_samples_test\": 37306,\n",
      "    \"full_number_of_samples_train\": 1743042,\n",
      "    \"license_citation\": \"@article{kuznetsova2018open,title={The open images dataset v4:                                 Unified image classification, object detection, and visual relationship                                 detection at scale}, author={Kuznetsova, Alina and Rom, Hassan and Alldrin,                                 Neil and Uijlings, Jasper and Krasin, Ivan and Pont-Tuset, Jordi and Kamali,                                 Shahab and Popov, Stefan and Malloci, Matteo and Duerig, Tom and others},                                 journal={arXiv preprint arXiv:1811.00982}, year={2018}}\",\n",
      "    \"license_link\": \"https://storage.googleapis.com/openimages/web/factsfigures.html\",\n",
      "    \"license_requirements\": \"The annotations are licensed by Google LLC under CC BY 4.0                                 license. The images are listed as having a CC BY 2.0 license. Note: while we                                 tried to identify images that are licensed under a Creative Commons Attribution                                 license, we make no representations or warranties regarding the license status                                 of each image and you should verify the license for each image yourself.\",\n",
      "    \"name\": \"google_open_image\",\n",
      "    \"number_of_channels\": 3,\n",
      "    \"sample_number_of_classes\": 601,\n",
      "    \"sample_number_of_samples_test\": 1000,\n",
      "    \"sample_number_of_samples_train\": 20000,\n",
      "    \"uid\": \"google_open_image\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "r = requests.get(f\"{url}/dataset_metadata/google_open_image\", headers=headers)\n",
    "print(json.dumps(r.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confident-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def get_task_subset_by_type(subset_type: str, url: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Helper function that returns the task ids in a list that match a specified\n",
    "    problem type\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    subset_type : str\n",
    "        The task_type subset you want to get back\n",
    "    \"\"\"\n",
    "    headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "    tasks = requests.get(f\"{url}/list_tasks\", headers=headers)\n",
    "    task_list = tasks.json()['tasks']\n",
    "    subset_tasks = []\n",
    "    for _task in task_list:\n",
    "        r = requests.get(f\"{url}/task_metadata/{_task}\", headers=headers)\n",
    "        task_metadata = r.json()\n",
    "        try:\n",
    "            if task_metadata['task_metadata']['problem_type'] == subset_type:\n",
    "                subset_tasks.append(_task)\n",
    "        except Exception as e:\n",
    "            print(_task)\n",
    "            print(e)\n",
    "    return subset_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "large-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_classification_tasks = get_task_subset_by_type('video_classification', url)\n",
    "img_classification_tasks = get_task_subset_by_type('image_classification', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "opening-liabilities",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem_test_video_classification']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_classification_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "designed-parallel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6d5e1f85-5d8f-4cc9-8184-299db03713f4',\n",
       " 'b01a6738-0b85-46c2-9318-16c3e2ef0f6d',\n",
       " 'bbfadb2c-c7c3-4596-b548-3dd01a6d1d2c',\n",
       " 'problem_test_image_classification']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_classification_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "built-consistency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_token': 'rP42SIPvvFPYTAe56lbW'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "\n",
    "# This is a convenience for development purposes, IN EVAL ALWAYS USE `full`\n",
    "data_type = 'sample' # can either be `sample` or `full`\n",
    "\n",
    "# Option to customize the session name \n",
    "r = requests.post(f\"{url}/auth/create_session\", json={'session_name': 'testing', 'data_type': data_type, \n",
    "                                                      'task_id': 'problem_test_video_classification'},\n",
    "                  headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "billion-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_token = r.json()['session_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "conditional-jewelry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 51,\n",
       "  'budget_used': 0,\n",
       "  'current_dataset': {'classes': ['shoot_ball',\n",
       "    'somersault',\n",
       "    'stand',\n",
       "    'smile',\n",
       "    'pour',\n",
       "    'climb_stairs',\n",
       "    'flic_flac',\n",
       "    'situp',\n",
       "    'golf',\n",
       "    'pick',\n",
       "    'draw_sword',\n",
       "    'smoke',\n",
       "    'clap',\n",
       "    'walk',\n",
       "    'dribble',\n",
       "    'talk',\n",
       "    'pushup',\n",
       "    'fall_floor',\n",
       "    'catch',\n",
       "    'sword',\n",
       "    'kick_ball',\n",
       "    'cartwheel',\n",
       "    'punch',\n",
       "    'sword_exercise',\n",
       "    'shoot_bow',\n",
       "    'brush_hair',\n",
       "    'push',\n",
       "    'wave',\n",
       "    'eat',\n",
       "    'hug',\n",
       "    'swing_baseball',\n",
       "    'ride_horse',\n",
       "    'throw',\n",
       "    'run',\n",
       "    'sit',\n",
       "    'pullup',\n",
       "    'dive',\n",
       "    'turn',\n",
       "    'climb',\n",
       "    'chew',\n",
       "    'handstand',\n",
       "    'hit',\n",
       "    'laugh',\n",
       "    'kiss',\n",
       "    'drink',\n",
       "    'ride_bike',\n",
       "    'shake_hands',\n",
       "    'kick',\n",
       "    'fencing',\n",
       "    'jump',\n",
       "    'shoot_gun'],\n",
       "   'dataset_type': 'video_classification',\n",
       "   'license_citation': 'Kuehne, Hildegard, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre. \"HMDB: a large video database for human motion recognition.\" In 2011 International conference on computer vision, pp. 2556-2563. IEEE, 2011.',\n",
       "   'license_link': 'https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'hmdb',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 51,\n",
       "   'number_of_samples_test': 100,\n",
       "   'number_of_samples_train': 816,\n",
       "   'uid': 'hmdb'},\n",
       "  'current_label_budget_stages': [51, 102, 204, 408, 485, 577, 686, 816],\n",
       "  'date_created': 1615944140000,\n",
       "  'date_last_interacted': 1615944140000,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_video_classification',\n",
       "  'uid': 'rP42SIPvvFPYTAe56lbW',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "graphic-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_sessions': ['07HRMjQx2FhKg5ePG9ES',\n",
       "  '0axbLnk9q8Edbe8Uto6B',\n",
       "  '2hiyDBNkIvjSxfsAJiWE',\n",
       "  '31IT4UtOCge9Z4588186',\n",
       "  '3LnrRHLKTcv39xguM7SM',\n",
       "  '3TuOcOxeOlqBRWntguk3',\n",
       "  '44RHjL8nBADJqHRwdyaF',\n",
       "  '4l47oy8FJiYfvN4bOb8U',\n",
       "  '5Jca2i4tNkZtW0XJQX6y',\n",
       "  '5WmYxgcTdXUZbGxOQVHT',\n",
       "  '5gM8ximMNgsogk9md5NX',\n",
       "  '5x1qcLiikkWPtdKO9BpM',\n",
       "  '6UmGVewydWxxgVBScAQp',\n",
       "  '828JXK1wA7BFLYjWDLo8',\n",
       "  '8UtrWLtmswwDQvv5VhaK',\n",
       "  '8zjJi4Xoaqf41er56neT',\n",
       "  '9R0iWvrberOt3DiCUdcw',\n",
       "  'Ba3Co8fSrhH1x8TuygA4',\n",
       "  'BtRQMbs75CRyd044cIRo',\n",
       "  'CHJuyAawICW1xeC9uOXQ',\n",
       "  'Dqa1NuHE4ik7rp7Ns1nj',\n",
       "  'EafoOLXGie384F4slQIO',\n",
       "  'EipSnGK0q8WeFdyyBtH8',\n",
       "  'FEve9SZoGkKwkgD17RUs',\n",
       "  'Gj5N3bfuX6TXVZ7eKaZy',\n",
       "  'J81dKtsVxLqsQbpvhouP',\n",
       "  'JjwONCZK0GnI3nQgwRMg',\n",
       "  'K5xPNejwR7FQInPFdwi3',\n",
       "  'LY7rsV9S0bohJQQWQfIQ',\n",
       "  'MnCVhHzptNsQs8w3X3w4',\n",
       "  'NHcd7GvqPKQvUe9TGrGU',\n",
       "  'NMFa4DG6i7cautR3aZvX',\n",
       "  'Ota4oh4wSha0ZxOzHWJl',\n",
       "  'TOxPWTXjFqeaYduMWz7Z',\n",
       "  'UIM9qlksZjJwAJDYUtsl',\n",
       "  'UdsuSn03PL07nKGPQaec',\n",
       "  'UpCLBHcG3EEHSPl9cDvV',\n",
       "  'aTDsEM7mz5uUoAH67op1',\n",
       "  'bOGZbfRDlk4IIXdB9HIV',\n",
       "  'c02DKrCCuCww4H4UlNal',\n",
       "  'ctzxDl5zOiPNi7r138aL',\n",
       "  'el21fLZRB171YS7L0Hws',\n",
       "  'gAZ860ExLfRW5uW5PG4H',\n",
       "  'hch5L9KmsbRWUeofslRi',\n",
       "  'jIBIEKSUYdw9baMFCE2r',\n",
       "  'jdrCPyFGQ2AQfdkCbnHb',\n",
       "  'kfo9ZiNqTE8WbZoKCWNA',\n",
       "  'l0qskSkOG4yPlbQxSK5V',\n",
       "  'lSg8Qk3Q7uxcDlXmCBde',\n",
       "  'nOWbG1WlaDtoUunwNOj2',\n",
       "  'nio5bytmO3rKbOvxZLFF',\n",
       "  'nrKVUdGLQ3lkMZ8xQ1YR',\n",
       "  'ocwg6a7wLumqJYnyNtPC',\n",
       "  'ojXWYJtQNTOvb9uawKLm',\n",
       "  'oztZqMUoHPl4GmpWSD04',\n",
       "  'rqkJoMexn4VyNqb5Wwg5',\n",
       "  'smSJ3iRgbQ0zo219dtBu',\n",
       "  'uphOCnHLiUDC7luFSIqa',\n",
       "  'wSevHTMrkEvhskvawNcF',\n",
       "  'xtXbkAP2Eb3WNLyU440U',\n",
       "  'ytmLKHK0aJEt4pvh4rZw']}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This shows the active sessions for your team\n",
    "headers_session = {'user_secret': secret, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/list_active_sessions\", headers=headers_session)\n",
    "active_sessions = r.json()\n",
    "active_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "variable-shareware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': 'brush_hair',\n",
       "   'end_frame': 80711,\n",
       "   'id': 881,\n",
       "   'start_frame': 80326,\n",
       "   'video_id': 881},\n",
       "  {'class': 'cartwheel',\n",
       "   'end_frame': 125969,\n",
       "   'id': 1366,\n",
       "   'start_frame': 125892,\n",
       "   'video_id': 1366},\n",
       "  {'class': 'catch',\n",
       "   'end_frame': 8277,\n",
       "   'id': 93,\n",
       "   'start_frame': 8242,\n",
       "   'video_id': 93},\n",
       "  {'class': 'chew',\n",
       "   'end_frame': 49439,\n",
       "   'id': 561,\n",
       "   'start_frame': 49341,\n",
       "   'video_id': 561},\n",
       "  {'class': 'clap',\n",
       "   'end_frame': 26696,\n",
       "   'id': 294,\n",
       "   'start_frame': 26653,\n",
       "   'video_id': 294},\n",
       "  {'class': 'climb',\n",
       "   'end_frame': 60370,\n",
       "   'id': 679,\n",
       "   'start_frame': 60278,\n",
       "   'video_id': 679},\n",
       "  {'class': 'climb_stairs',\n",
       "   'end_frame': 98319,\n",
       "   'id': 1064,\n",
       "   'start_frame': 98245,\n",
       "   'video_id': 1064},\n",
       "  {'class': 'dive',\n",
       "   'end_frame': 131732,\n",
       "   'id': 1428,\n",
       "   'start_frame': 131702,\n",
       "   'video_id': 1428},\n",
       "  {'class': 'draw_sword',\n",
       "   'end_frame': 32416,\n",
       "   'id': 360,\n",
       "   'start_frame': 32363,\n",
       "   'video_id': 360},\n",
       "  {'class': 'dribble',\n",
       "   'end_frame': 14209,\n",
       "   'id': 145,\n",
       "   'start_frame': 14132,\n",
       "   'video_id': 145},\n",
       "  {'class': 'drink',\n",
       "   'end_frame': 19673,\n",
       "   'id': 209,\n",
       "   'start_frame': 19581,\n",
       "   'video_id': 209},\n",
       "  {'class': 'eat',\n",
       "   'end_frame': 157264,\n",
       "   'id': 1697,\n",
       "   'start_frame': 157225,\n",
       "   'video_id': 1697},\n",
       "  {'class': 'fall_floor',\n",
       "   'end_frame': 10359,\n",
       "   'id': 110,\n",
       "   'start_frame': 10304,\n",
       "   'video_id': 110},\n",
       "  {'class': 'fencing',\n",
       "   'end_frame': 151179,\n",
       "   'id': 1637,\n",
       "   'start_frame': 151139,\n",
       "   'video_id': 1637},\n",
       "  {'class': 'flic_flac',\n",
       "   'end_frame': 164127,\n",
       "   'id': 1783,\n",
       "   'start_frame': 164050,\n",
       "   'video_id': 1783},\n",
       "  {'class': 'golf',\n",
       "   'end_frame': 81651,\n",
       "   'id': 893,\n",
       "   'start_frame': 81575,\n",
       "   'video_id': 893},\n",
       "  {'class': 'handstand',\n",
       "   'end_frame': 159618,\n",
       "   'id': 1726,\n",
       "   'start_frame': 159543,\n",
       "   'video_id': 1726},\n",
       "  {'class': 'hit',\n",
       "   'end_frame': 156280,\n",
       "   'id': 1689,\n",
       "   'start_frame': 156228,\n",
       "   'video_id': 1689},\n",
       "  {'class': 'hug',\n",
       "   'end_frame': 131306,\n",
       "   'id': 1424,\n",
       "   'start_frame': 131252,\n",
       "   'video_id': 1424},\n",
       "  {'class': 'jump',\n",
       "   'end_frame': 4162,\n",
       "   'id': 46,\n",
       "   'start_frame': 4109,\n",
       "   'video_id': 46},\n",
       "  {'class': 'kick',\n",
       "   'end_frame': 121483,\n",
       "   'id': 1321,\n",
       "   'start_frame': 121437,\n",
       "   'video_id': 1321},\n",
       "  {'class': 'kick_ball',\n",
       "   'end_frame': 118103,\n",
       "   'id': 1283,\n",
       "   'start_frame': 118071,\n",
       "   'video_id': 1283},\n",
       "  {'class': 'kiss',\n",
       "   'end_frame': 49988,\n",
       "   'id': 564,\n",
       "   'start_frame': 49626,\n",
       "   'video_id': 564},\n",
       "  {'class': 'laugh',\n",
       "   'end_frame': 184628,\n",
       "   'id': 2017,\n",
       "   'start_frame': 184416,\n",
       "   'video_id': 2017},\n",
       "  {'class': 'pick',\n",
       "   'end_frame': 51127,\n",
       "   'id': 581,\n",
       "   'start_frame': 50991,\n",
       "   'video_id': 581},\n",
       "  {'class': 'pour',\n",
       "   'end_frame': 74351,\n",
       "   'id': 818,\n",
       "   'start_frame': 74236,\n",
       "   'video_id': 818},\n",
       "  {'class': 'pullup',\n",
       "   'end_frame': 38924,\n",
       "   'id': 443,\n",
       "   'start_frame': 38838,\n",
       "   'video_id': 443},\n",
       "  {'class': 'punch',\n",
       "   'end_frame': 23675,\n",
       "   'id': 259,\n",
       "   'start_frame': 23630,\n",
       "   'video_id': 259},\n",
       "  {'class': 'push',\n",
       "   'end_frame': 124239,\n",
       "   'id': 1343,\n",
       "   'start_frame': 124156,\n",
       "   'video_id': 1343},\n",
       "  {'class': 'pushup',\n",
       "   'end_frame': 98479,\n",
       "   'id': 1066,\n",
       "   'start_frame': 98399,\n",
       "   'video_id': 1066},\n",
       "  {'class': 'ride_bike',\n",
       "   'end_frame': 47700,\n",
       "   'id': 540,\n",
       "   'start_frame': 47589,\n",
       "   'video_id': 540},\n",
       "  {'class': 'ride_horse',\n",
       "   'end_frame': 162256,\n",
       "   'id': 1759,\n",
       "   'start_frame': 162125,\n",
       "   'video_id': 1759},\n",
       "  {'class': 'run',\n",
       "   'end_frame': 13972,\n",
       "   'id': 142,\n",
       "   'start_frame': 13949,\n",
       "   'video_id': 142},\n",
       "  {'class': 'shake_hands',\n",
       "   'end_frame': 26138,\n",
       "   'id': 287,\n",
       "   'start_frame': 26060,\n",
       "   'video_id': 287},\n",
       "  {'class': 'shoot_ball',\n",
       "   'end_frame': 153917,\n",
       "   'id': 1665,\n",
       "   'start_frame': 153838,\n",
       "   'video_id': 1665},\n",
       "  {'class': 'shoot_bow',\n",
       "   'end_frame': 128499,\n",
       "   'id': 1396,\n",
       "   'start_frame': 128309,\n",
       "   'video_id': 1396},\n",
       "  {'class': 'shoot_gun',\n",
       "   'end_frame': 90730,\n",
       "   'id': 983,\n",
       "   'start_frame': 90676,\n",
       "   'video_id': 983},\n",
       "  {'class': 'sit',\n",
       "   'end_frame': 18775,\n",
       "   'id': 198,\n",
       "   'start_frame': 18684,\n",
       "   'video_id': 198},\n",
       "  {'class': 'situp',\n",
       "   'end_frame': 67544,\n",
       "   'id': 750,\n",
       "   'start_frame': 67424,\n",
       "   'video_id': 750},\n",
       "  {'class': 'smile',\n",
       "   'end_frame': 47822,\n",
       "   'id': 542,\n",
       "   'start_frame': 47778,\n",
       "   'video_id': 542},\n",
       "  {'class': 'smoke',\n",
       "   'end_frame': 57891,\n",
       "   'id': 647,\n",
       "   'start_frame': 57784,\n",
       "   'video_id': 647},\n",
       "  {'class': 'somersault',\n",
       "   'end_frame': 7771,\n",
       "   'id': 89,\n",
       "   'start_frame': 7695,\n",
       "   'video_id': 89},\n",
       "  {'class': 'stand',\n",
       "   'end_frame': 125722,\n",
       "   'id': 1363,\n",
       "   'start_frame': 125671,\n",
       "   'video_id': 1363},\n",
       "  {'class': 'swing_baseball',\n",
       "   'end_frame': 9143,\n",
       "   'id': 103,\n",
       "   'start_frame': 9030,\n",
       "   'video_id': 103},\n",
       "  {'class': 'sword',\n",
       "   'end_frame': 186772,\n",
       "   'id': 2036,\n",
       "   'start_frame': 186663,\n",
       "   'video_id': 2036},\n",
       "  {'class': 'sword_exercise',\n",
       "   'end_frame': 170292,\n",
       "   'id': 1854,\n",
       "   'start_frame': 170037,\n",
       "   'video_id': 1854},\n",
       "  {'class': 'talk',\n",
       "   'end_frame': 63762,\n",
       "   'id': 716,\n",
       "   'start_frame': 63668,\n",
       "   'video_id': 716},\n",
       "  {'class': 'throw',\n",
       "   'end_frame': 42701,\n",
       "   'id': 484,\n",
       "   'start_frame': 42602,\n",
       "   'video_id': 484},\n",
       "  {'class': 'turn',\n",
       "   'end_frame': 20244,\n",
       "   'id': 216,\n",
       "   'start_frame': 20168,\n",
       "   'video_id': 216},\n",
       "  {'class': 'walk',\n",
       "   'end_frame': 11253,\n",
       "   'id': 118,\n",
       "   'start_frame': 11031,\n",
       "   'video_id': 118},\n",
       "  {'class': 'wave',\n",
       "   'end_frame': 33210,\n",
       "   'id': 370,\n",
       "   'start_frame': 33132,\n",
       "   'video_id': 370}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/seed_labels\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bound-retail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 51,\n",
       "  'current_dataset': {'classes': ['shoot_ball',\n",
       "    'somersault',\n",
       "    'stand',\n",
       "    'smile',\n",
       "    'pour',\n",
       "    'climb_stairs',\n",
       "    'flic_flac',\n",
       "    'situp',\n",
       "    'golf',\n",
       "    'pick',\n",
       "    'draw_sword',\n",
       "    'smoke',\n",
       "    'clap',\n",
       "    'walk',\n",
       "    'dribble',\n",
       "    'talk',\n",
       "    'pushup',\n",
       "    'fall_floor',\n",
       "    'catch',\n",
       "    'sword',\n",
       "    'kick_ball',\n",
       "    'cartwheel',\n",
       "    'punch',\n",
       "    'sword_exercise',\n",
       "    'shoot_bow',\n",
       "    'brush_hair',\n",
       "    'push',\n",
       "    'wave',\n",
       "    'eat',\n",
       "    'hug',\n",
       "    'swing_baseball',\n",
       "    'ride_horse',\n",
       "    'throw',\n",
       "    'run',\n",
       "    'sit',\n",
       "    'pullup',\n",
       "    'dive',\n",
       "    'turn',\n",
       "    'climb',\n",
       "    'chew',\n",
       "    'handstand',\n",
       "    'hit',\n",
       "    'laugh',\n",
       "    'kiss',\n",
       "    'drink',\n",
       "    'ride_bike',\n",
       "    'shake_hands',\n",
       "    'kick',\n",
       "    'fencing',\n",
       "    'jump',\n",
       "    'shoot_gun'],\n",
       "   'dataset_type': 'video_classification',\n",
       "   'license_citation': 'Kuehne, Hildegard, Hueihan Jhuang, Estíbaliz Garrote, Tomaso Poggio, and Thomas Serre. \"HMDB: a large video database for human motion recognition.\" In 2011 International conference on computer vision, pp. 2556-2563. IEEE, 2011.',\n",
       "   'license_link': 'https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#Downloads',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'hmdb',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 51,\n",
       "   'number_of_samples_test': 100,\n",
       "   'number_of_samples_train': 816,\n",
       "   'uid': 'hmdb'},\n",
       "  'current_label_budget_stages': [51, 102, 204, 408, 485, 577, 686, 816],\n",
       "  'date_created': 1615944140000,\n",
       "  'date_last_interacted': 1615944307536,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_video_classification',\n",
       "  'uid': 'rP42SIPvvFPYTAe56lbW',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "female-commission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.json()['Session_Status']['budget_left_until_checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abandoned-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_images_and_classes(dataset_path: Path, session_token: str, data_type: str='sample') -> Tuple[List[str],List[str]]:\n",
    "    \"\"\"\n",
    "    Helper method to dynamically get the test labels and give us the possible classes that can be submitted\n",
    "    for the current dataset\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    \n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` dataset. \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Tuple[List[str], List[str]]\n",
    "        The list of test image ids needed to submit a prediction and the list of class names that you can predict against\n",
    "    \"\"\"\n",
    "    # Then we can just reference our current metadata to get our dataset name and use that in the path\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    current_dataset_classes = current_dataset['classes']\n",
    "\n",
    "    test_imgs_dir = dataset_path.joinpath(f\"{current_dataset_name}/{current_dataset_name}_{data_type}/test\")\n",
    "    test_imgs = [f.name for f in test_imgs_dir.iterdir() if f.is_file()]\n",
    "    return test_imgs, current_dataset_classes\n",
    "\n",
    "def generate_random_predictions_on_test_set(test_imgs: List[str], current_dataset_classes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a prediction dataframe for image classification based on random sampling from our available classes\n",
    "    \"\"\"\n",
    "    rand_lbls = [str(random.choice(current_dataset_classes)) for _ in range(len(test_imgs))]\n",
    "    df = pd.DataFrame({'id': test_imgs, 'class': rand_lbls})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "social-authorization",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = Path.home().joinpath('lwll_datasets/development')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "concrete-operations",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/lwll_datasets/development/hmdb/hmdb_sample/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f1eba067ff6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dataset_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_images_and_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASETS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-99863ed815d1>\u001b[0m in \u001b[0;36mget_test_images_and_classes\u001b[0;34m(dataset_path, session_token, data_type)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtest_imgs_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{current_dataset_name}/{current_dataset_name}_{data_type}/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_imgs_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dataset_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-99863ed815d1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtest_imgs_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{current_dataset_name}/{current_dataset_name}_{data_type}/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtest_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_imgs_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtest_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_dataset_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/lwll_datasets/development/hmdb/hmdb_sample/test'"
     ]
    }
   ],
   "source": [
    "test_imgs, current_dataset_classes = get_test_images_and_classes(DATASETS_PATH, session_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "vietnamese-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_random_predictions_on_test_set(test_imgs, current_dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "professional-evidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4046.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1169.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3505.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9271.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1753.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>8127.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3822.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>4874.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3425.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>6397.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id class\n",
       "0    4046.png     8\n",
       "1    1169.png     1\n",
       "2    3505.png     3\n",
       "3    9271.png     1\n",
       "4    1753.png     1\n",
       "..        ...   ...\n",
       "995  8127.png     4\n",
       "996  3822.png     4\n",
       "997  4874.png     4\n",
       "998  3425.png     2\n",
       "999  6397.png     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "secure-polyester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 10,\n",
       "  'budget_used': 10,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615924481881,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "altered-pound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': '0', 'id': '33665.png'},\n",
       "  {'class': '1', 'id': '6371.png'},\n",
       "  {'class': '2', 'id': '45055.png'},\n",
       "  {'class': '3', 'id': '40914.png'},\n",
       "  {'class': '4', 'id': '6733.png'},\n",
       "  {'class': '5', 'id': '16400.png'},\n",
       "  {'class': '6', 'id': '14405.png'},\n",
       "  {'class': '7', 'id': '55078.png'},\n",
       "  {'class': '8', 'id': '17808.png'},\n",
       "  {'class': '9', 'id': '10944.png'}]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.get(f\"{url}/seed_labels\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "lined-mustang",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 20,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925773325,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "caring-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, current_dataset_classes = get_test_images_and_classes(DATASETS_PATH, session_token)\n",
    "df = generate_random_predictions_on_test_set(test_imgs, current_dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "exotic-torture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 20,\n",
       "  'budget_used': 20,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925773325,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "jewish-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': '0', 'id': '49011.png'},\n",
       "  {'class': '0', 'id': '40303.png'},\n",
       "  {'class': '1', 'id': '30274.png'},\n",
       "  {'class': '1', 'id': '9251.png'},\n",
       "  {'class': '2', 'id': '38652.png'},\n",
       "  {'class': '2', 'id': '1374.png'},\n",
       "  {'class': '3', 'id': '5412.png'},\n",
       "  {'class': '3', 'id': '49882.png'},\n",
       "  {'class': '4', 'id': '32895.png'},\n",
       "  {'class': '4', 'id': '45778.png'},\n",
       "  {'class': '5', 'id': '41243.png'},\n",
       "  {'class': '5', 'id': '31863.png'},\n",
       "  {'class': '6', 'id': '2300.png'},\n",
       "  {'class': '6', 'id': '38643.png'},\n",
       "  {'class': '7', 'id': '58671.png'},\n",
       "  {'class': '7', 'id': '9538.png'},\n",
       "  {'class': '8', 'id': '22166.png'},\n",
       "  {'class': '8', 'id': '43944.png'},\n",
       "  {'class': '9', 'id': '31275.png'},\n",
       "  {'class': '9', 'id': '20434.png'}]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.get(f\"{url}/seed_labels\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "interim-automation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 40,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925885014,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "muslim-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, current_dataset_classes = get_test_images_and_classes(DATASETS_PATH, session_token)\n",
    "df = generate_random_predictions_on_test_set(test_imgs, current_dataset_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "detailed-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 40,\n",
       "  'budget_used': 40,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925885014,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': os.environ.get('GOVTEAM_SECRET')}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "widespread-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_labels_from_train_dataset(dataset_path: Path, session_token: str, n: int=None, data_type: str='sample') -> List[str]:\n",
    "    \"\"\"\n",
    "    Helper function to get a random `n` image ids from our train dataset to request labels for\n",
    "    from the api\n",
    "    \n",
    "    Params\n",
    "    ------\n",
    "    \n",
    "    dataset_path : Path\n",
    "        The path to the `development` dataset downloads\n",
    "    \n",
    "    session_token : str\n",
    "        Your current session token so that we can look up the current session metadata\n",
    "    data_type: str\n",
    "        Indicates whether you are using the `sample` or `full` size dataset\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    List[str]\n",
    "        A list of n unique image ids for the current session dataset\n",
    "        \n",
    "    \"\"\"\n",
    "    headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "    r = requests.get(f\"{url}/session_status\", headers=headers)\n",
    "    current_dataset = r.json()['Session_Status']['current_dataset']\n",
    "    current_dataset_name = current_dataset['name']\n",
    "    budget_left = r.json()['Session_Status']['budget_left_until_checkpoint']\n",
    "    print(f\"budget_left is {budget_left}\")\n",
    "    if not n:\n",
    "        n = budget_left\n",
    "    \n",
    "    train_imgs_dir = dataset_path.joinpath(f\"{current_dataset_name}/{current_dataset_name}_{data_type}/train\")\n",
    "    train_imgs = [f.name for f in train_imgs_dir.iterdir() if f.is_file()]\n",
    "    print(f\"train_imgs: {train_imgs[0:4]}\")\n",
    "    \n",
    "    random_ids = random.sample(train_imgs, k=n)\n",
    "    return random_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "innovative-mailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget_left is 40\n",
      "train_imgs: ['5238.png', '42470.png', '2944.png', '16089.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['14160.png',\n",
       " '12840.png',\n",
       " '15889.png',\n",
       " '22010.png',\n",
       " '39328.png',\n",
       " '52250.png',\n",
       " '38606.png',\n",
       " '6371.png',\n",
       " '49069.png',\n",
       " '45703.png']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_be_labeled = get_random_labels_from_train_dataset(DATASETS_PATH, session_token, n=10)\n",
    "images_to_be_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "decent-bubble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': '1', 'id': '6371.png'},\n",
       "  {'class': '2', 'id': '22010.png'},\n",
       "  {'class': '1', 'id': '39328.png'},\n",
       "  {'class': '7', 'id': '49069.png'},\n",
       "  {'class': '8', 'id': '38606.png'},\n",
       "  {'class': '1', 'id': '45703.png'},\n",
       "  {'class': '0', 'id': '14160.png'},\n",
       "  {'class': '8', 'id': '52250.png'},\n",
       "  {'class': '9', 'id': '12840.png'},\n",
       "  {'class': '3', 'id': '15889.png'}],\n",
       " 'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 30,\n",
       "  'budget_used': 50,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615925934746,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "query = {\n",
    "    'example_ids': images_to_be_labeled\n",
    "}\n",
    "\n",
    "r = requests.post(f\"{url}/query_labels\", json=query, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "novel-sandwich",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "budget_left is 30\n",
      "train_imgs: ['5238.png', '42470.png', '2944.png', '16089.png']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['35102.png',\n",
       " '18742.png',\n",
       " '29804.png',\n",
       " '3182.png',\n",
       " '29720.png',\n",
       " '13624.png',\n",
       " '18451.png',\n",
       " '1380.png',\n",
       " '5775.png',\n",
       " '15654.png',\n",
       " '29423.png',\n",
       " '44395.png',\n",
       " '59668.png',\n",
       " '46864.png',\n",
       " '52098.png',\n",
       " '2557.png',\n",
       " '4922.png',\n",
       " '41956.png',\n",
       " '33443.png',\n",
       " '58374.png',\n",
       " '49105.png',\n",
       " '58451.png',\n",
       " '42697.png',\n",
       " '39245.png',\n",
       " '36073.png',\n",
       " '5684.png',\n",
       " '23929.png',\n",
       " '57242.png',\n",
       " '50632.png',\n",
       " '34989.png']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_to_be_labeled = get_random_labels_from_train_dataset(DATASETS_PATH, session_token, n=30)\n",
    "images_to_be_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "satisfied-contractor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Labels': [{'class': '8', 'id': '46864.png'},\n",
       "  {'class': '3', 'id': '52098.png'},\n",
       "  {'class': '0', 'id': '34989.png'},\n",
       "  {'class': '0', 'id': '2557.png'},\n",
       "  {'class': '1', 'id': '18451.png'},\n",
       "  {'class': '9', 'id': '59668.png'},\n",
       "  {'class': '4', 'id': '39245.png'},\n",
       "  {'class': '2', 'id': '44395.png'},\n",
       "  {'class': '3', 'id': '23929.png'},\n",
       "  {'class': '1', 'id': '58451.png'},\n",
       "  {'class': '4', 'id': '49105.png'},\n",
       "  {'class': '4', 'id': '1380.png'},\n",
       "  {'class': '6', 'id': '5684.png'},\n",
       "  {'class': '7', 'id': '35102.png'},\n",
       "  {'class': '4', 'id': '42697.png'},\n",
       "  {'class': '7', 'id': '29423.png'},\n",
       "  {'class': '5', 'id': '29804.png'},\n",
       "  {'class': '9', 'id': '33443.png'},\n",
       "  {'class': '5', 'id': '57242.png'},\n",
       "  {'class': '8', 'id': '58374.png'},\n",
       "  {'class': '1', 'id': '50632.png'},\n",
       "  {'class': '2', 'id': '29720.png'},\n",
       "  {'class': '4', 'id': '3182.png'},\n",
       "  {'class': '8', 'id': '5775.png'},\n",
       "  {'class': '3', 'id': '18742.png'},\n",
       "  {'class': '6', 'id': '4922.png'},\n",
       "  {'class': '1', 'id': '41956.png'},\n",
       "  {'class': '4', 'id': '36073.png'},\n",
       "  {'class': '9', 'id': '15654.png'},\n",
       "  {'class': '2', 'id': '13624.png'}],\n",
       " 'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 0,\n",
       "  'budget_used': 80,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615926392531,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "query = {\n",
    "    'example_ids': images_to_be_labeled\n",
    "}\n",
    "\n",
    "r = requests.post(f\"{url}/query_labels\", json=query, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "comparable-lesbian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Session_Status': {'active': 'In Progress',\n",
       "  'budget_left_until_checkpoint': 18,\n",
       "  'budget_used': 95,\n",
       "  'current_dataset': {'classes': ['0',\n",
       "    '1',\n",
       "    '2',\n",
       "    '3',\n",
       "    '4',\n",
       "    '5',\n",
       "    '6',\n",
       "    '7',\n",
       "    '8',\n",
       "    '9'],\n",
       "   'dataset_type': 'image_classification',\n",
       "   'license_citation': '[LeCun et al., 1998a] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998. http://yann.lecun.com/exdb/publis/index.html#lecun-98',\n",
       "   'license_link': 'http://yann.lecun.com/exdb/mnist/',\n",
       "   'license_requirements': 'None',\n",
       "   'name': 'mnist',\n",
       "   'number_of_channels': 1,\n",
       "   'number_of_classes': 10,\n",
       "   'number_of_samples_test': 1000,\n",
       "   'number_of_samples_train': 160,\n",
       "   'uid': 'mnist'},\n",
       "  'current_label_budget_stages': [10, 20, 40, 80, 95, 113, 135, 160],\n",
       "  'date_created': 1615924043000,\n",
       "  'date_last_interacted': 1615926541255,\n",
       "  'pair_stage': 'base',\n",
       "  'session_name': 'testing',\n",
       "  'task_id': 'problem_test_image_classification',\n",
       "  'uid': '9R0iWvrberOt3DiCUdcw',\n",
       "  'user_name': 'Brown',\n",
       "  'using_sample_datasets': True}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = generate_random_predictions_on_test_set(test_imgs, current_dataset_classes)\n",
    "headers = {'user_secret': secret, 'session_token': session_token, 'govteam_secret': gov_secret}\n",
    "\n",
    "r = requests.post(f\"{url}/submit_predictions\", json={'predictions': df.to_dict()}, headers=headers)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "environmental-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JPL:\n",
    "    \"\"\"\n",
    "    A class to interact with JPL-like APIs.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_url, team_secret, gov_team_secret, dataset_type):\n",
    "        \"\"\"\n",
    "        Create a new JPL object.\n",
    "        \"\"\"\n",
    "\n",
    "        self.team_secret = team_secret\n",
    "        self.gov_team_secret = gov_team_secret\n",
    "        self.url = api_url \n",
    "        self.session_token = ''\n",
    "        self.data_type = dataset_type\n",
    "\n",
    "\n",
    "    def get_available_tasks(self, problem_type):\n",
    "        \"\"\"\n",
    "        Get all available tasks.\n",
    "        :return: A list of tasks (problems)\n",
    "        \"\"\"\n",
    "        headers = {'user_secret': self.team_secret,\n",
    "                   'govteam_secret': self.gov_team_secret\n",
    "                   }\n",
    "        r = requests.get(self.url + \"/list_tasks\", headers=headers)\n",
    "        task_list = r.json()['tasks']\n",
    "        #print(task_list)\n",
    "\n",
    "        subset_tasks = []\n",
    "        for _task in task_list:\n",
    "            r = requests.get(self.url+\"/task_metadata/\"+_task, headers=headers)\n",
    "            task_metadata = r.json()\n",
    "            #print(task_metadata)\n",
    "            if task_metadata['task_metadata']['problem_type'] == problem_type:\n",
    "                subset_tasks.append(_task)\n",
    "        return subset_tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "pending-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "jpl = JPL(url, secret, gov_secret, dataset_type='sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "preceding-nickel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['problem_test_video_classification']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpl.get_available_tasks('video_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-maryland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
