{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "steady-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "ready-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can add all the methods we have/want\n",
    "models_list = ['clip_baseline',\n",
    "    'coop_baseline', 'coop_pseudo_baseline',\n",
    "    'vpt_baseline', 'vpt_pseudo_baseline', \n",
    "    'teacher_student',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "single-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher_student\n"
     ]
    }
   ],
   "source": [
    "model = models_list[-1]\n",
    "print(model)\n",
    "filename = f\"results/results_model_{model}.json\"\n",
    "\n",
    "data = [json.loads(i) for i in open(filename,'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "monetary-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean STD accuracy: nan\n",
      "Std STD accuracy: nan\n",
      "95% STD confidence interval nan\n",
      "\n",
      "\n",
      "Mean SEEN accuracy: nan\n",
      "Std SEEN accuracy: nan\n",
      "95% SEEN confidence interval nan\n",
      "\n",
      "\n",
      "Mean UNSEEN accuracy: nan\n",
      "Std UNSEEN accuracy: nan\n",
      "95% UNSEEN confidence interval nan\n",
      "\n",
      "\n",
      "Mean HARMONIC accuracy: nan\n",
      "Std HARMONIC accuracy: nan\n",
      "95% HARMONIC confidence interval nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-478-0d360a50c546>:30: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"Mean STD accuracy: {round((np.sum(std_accuracies)/len(std_accuracies))*100, 2)}\")\n",
      "/Users/menga/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/menga/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "/Users/menga/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/menga/miniconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/menga/miniconda3/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-478-0d360a50c546>:33: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"95% STD confidence interval {round((np.sum(std_accuracies)/len(std_accuracies) - interval[0])*100, 2)}\")\n",
      "<ipython-input-478-0d360a50c546>:36: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"Mean SEEN accuracy: {round((np.sum(seen_accuracies)/len(seen_accuracies))*100, 2)}\")\n",
      "<ipython-input-478-0d360a50c546>:39: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"95% SEEN confidence interval {round((np.sum(seen_accuracies)/len(seen_accuracies) - interval[0])*100, 2)}\")\n",
      "<ipython-input-478-0d360a50c546>:42: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"Mean UNSEEN accuracy: {round((np.sum(unseen_accuracies)/len(unseen_accuracies))*100,2)}\")\n",
      "<ipython-input-478-0d360a50c546>:45: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"95% UNSEEN confidence interval {round((np.sum(unseen_accuracies)/len(unseen_accuracies) - interval[0])*100,2)}\")\n",
      "<ipython-input-478-0d360a50c546>:48: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"Mean HARMONIC accuracy: {round((np.sum(harmonic_accuracies)/len(harmonic_accuracies))*100, 2)}\")\n",
      "<ipython-input-478-0d360a50c546>:51: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  print(f\"95% HARMONIC confidence interval {round((np.sum(harmonic_accuracies)/len(harmonic_accuracies) - interval[0])*100, 2)}\")\n"
     ]
    }
   ],
   "source": [
    "std_accuracies = []\n",
    "gen_accuracies = []\n",
    "seen_accuracies = []\n",
    "unseen_accuracies = []\n",
    "harmonic_accuracies = []\n",
    "\n",
    "fix_num = 0\n",
    "\n",
    "\n",
    "for m in data:\n",
    "    # Here change and filter data depending on what results we want/\n",
    "    # For instance, let's assume we want \n",
    "    if (\n",
    "        (m['config']['DATASET_NAME'] == 'DTD')  \\\n",
    "         and (m['config']['VIS_ENCODER'] == 'ViT-B/32') \\\n",
    "         and (m['config']['SPLIT_SEED'] == 500) \\\n",
    "    ):\n",
    "        std_accuracies.append(m['std_accuracy'])\n",
    "        gen_accuracies.append(m['gen_accuracy'])\n",
    "        seen_accuracies.append(m['gen_seen'])\n",
    "        unseen_accuracies.append(m['gen_unseen'])\n",
    "        harmonic_accuracies.append(st.hmean([m['gen_seen'], m['gen_unseen']]))\n",
    "        \n",
    "std_accuracies = std_accuracies[fix_num:]\n",
    "gen_accuracies = gen_accuracies[fix_num:]\n",
    "seen_accuracies = seen_accuracies[fix_num:]\n",
    "unseen_accuracies = unseen_accuracies[fix_num:]\n",
    "harmonic_accuracies = harmonic_accuracies[fix_num:]\n",
    "\n",
    "print(f\"Mean STD accuracy: {round((np.sum(std_accuracies)/len(std_accuracies))*100, 2)}\")\n",
    "print(f\"Std STD accuracy: {np.std(std_accuracies)}\")\n",
    "interval = st.t.interval(alpha=0.95, df=len(std_accuracies)-1, loc=np.mean(std_accuracies), scale=st.sem(std_accuracies)) \n",
    "print(f\"95% STD confidence interval {round((np.sum(std_accuracies)/len(std_accuracies) - interval[0])*100, 2)}\")\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Mean SEEN accuracy: {round((np.sum(seen_accuracies)/len(seen_accuracies))*100, 2)}\")\n",
    "print(f\"Std SEEN accuracy: {np.std(seen_accuracies)}\")\n",
    "interval = st.t.interval(alpha=0.95, df=len(seen_accuracies)-1, loc=np.mean(seen_accuracies), scale=st.sem(seen_accuracies)) \n",
    "print(f\"95% SEEN confidence interval {round((np.sum(seen_accuracies)/len(seen_accuracies) - interval[0])*100, 2)}\")\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Mean UNSEEN accuracy: {round((np.sum(unseen_accuracies)/len(unseen_accuracies))*100,2)}\")\n",
    "print(f\"Std UNSEEN accuracy: {np.std(unseen_accuracies)}\")\n",
    "interval = st.t.interval(alpha=0.95, df=len(unseen_accuracies)-1, loc=np.mean(unseen_accuracies), scale=st.sem(unseen_accuracies)) \n",
    "print(f\"95% UNSEEN confidence interval {round((np.sum(unseen_accuracies)/len(unseen_accuracies) - interval[0])*100,2)}\")\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Mean HARMONIC accuracy: {round((np.sum(harmonic_accuracies)/len(harmonic_accuracies))*100, 2)}\")\n",
    "print(f\"Std HARMONIC accuracy: {np.std(harmonic_accuracies)}\")\n",
    "interval = st.t.interval(alpha=0.95, df=len(harmonic_accuracies)-1, loc=np.mean(harmonic_accuracies), scale=st.sem(harmonic_accuracies)) \n",
    "print(f\"95% HARMONIC confidence interval {round((np.sum(harmonic_accuracies)/len(harmonic_accuracies) - interval[0])*100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "literary-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7559820538384845,\n",
       " 0.7619641076769691,\n",
       " 0.7485044865403788,\n",
       " 0.7597208374875374,\n",
       " 0.7627118644067796]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "advanced-nudist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7810014038371549,\n",
       " 0.789424426766495,\n",
       " 0.7903603182030885,\n",
       " 0.8034627983153955,\n",
       " 0.7819372952737482]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "friendly-document",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7682880936356221,\n",
       " 0.7754512368306479,\n",
       " 0.7688631806185371,\n",
       " 0.7809798107472069,\n",
       " 0.7722049354570382]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harmonic_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "valued-coating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8207767898923725,\n",
       " 0.8235844642021526,\n",
       " 0.8296677585400094,\n",
       " 0.8390266729059429,\n",
       " 0.8249883013570426]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-developer",
   "metadata": {},
   "source": [
    "In the google sheets, I report the mean and the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "forty-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.906, 0.772, 0.567, 0.8936]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "rising-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [0.8175, 0.8405, 0.8705, 0.7975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "entertaining-combat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7984508171723251"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(st.hmean([a, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respected-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "framed-sheet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'banded',\n",
       " 1: 'blotchy',\n",
       " 2: 'braided',\n",
       " 3: 'bubbly',\n",
       " 4: 'bumpy',\n",
       " 5: 'chequered',\n",
       " 6: 'cobwebbed',\n",
       " 7: 'cracked',\n",
       " 8: 'crosshatched',\n",
       " 9: 'crystalline',\n",
       " 10: 'dotted',\n",
       " 11: 'fibrous',\n",
       " 12: 'flecked',\n",
       " 13: 'freckled',\n",
       " 14: 'frilly',\n",
       " 15: 'gauzy',\n",
       " 16: 'grid',\n",
       " 17: 'grooved',\n",
       " 18: 'honeycombed',\n",
       " 19: 'interlaced',\n",
       " 20: 'knitted',\n",
       " 21: 'lacelike',\n",
       " 22: 'lined',\n",
       " 23: 'marbled',\n",
       " 24: 'matted',\n",
       " 25: 'meshed',\n",
       " 26: 'paisley',\n",
       " 27: 'perforated',\n",
       " 28: 'pitted',\n",
       " 29: 'pleated',\n",
       " 30: 'polka-dotted',\n",
       " 31: 'porous',\n",
       " 32: 'potholed',\n",
       " 33: 'scaly',\n",
       " 34: 'smeared',\n",
       " 35: 'spiralled',\n",
       " 36: 'sprinkled',\n",
       " 37: 'stained',\n",
       " 38: 'stratified',\n",
       " 39: 'striped',\n",
       " 40: 'studded',\n",
       " 41: 'swirly',\n",
       " 42: 'veined',\n",
       " 43: 'waffled',\n",
       " 44: 'woven',\n",
       " 45: 'wrinkled',\n",
       " 46: 'zigzagged'}"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes = []\n",
    "# with open(f\"pseudolabels/train.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "#     for d in data[\"categories\"]:\n",
    "#         classes.append(d[\"name\"].replace(\"_\", \" \"))\n",
    "\n",
    "classes = []\n",
    "with open(f\"pseudolabels/dtd_classes.txt\", 'r') as file:\n",
    "    for l in file:\n",
    "        classes.append(l.strip())\n",
    "\n",
    "class_dict = {i:c for i,c in enumerate(classes)}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "ongoing-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pseudolabels/RESICS45_ViT-B32_14_pseudolabels.pickle', 'rb') as f:\n",
    "    clip = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "developing-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('pseudolabels/Flowers102_ablation_teacher_student_ViT-B32_teacher_iter_4_pseudolabels_spl_500.pickle', 'rb') as f:\n",
    "with open('pseudolabels/DTD_teacher_student_ViT-B32_teacher_iter_3_pseudolabels_spl_500.pickle', 'rb') as f:\n",
    "    teacher = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "working-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pseudolabels/DTD_teacher_student_ViT-B32_student_iter_3_pseudolabels_spl_500.pickle', 'rb') as f:\n",
    "    student = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "considerable-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pseudolabels/Flowers102_ablation_teacher_student_ViT-B32_teacher_iter_2_pseudolabels_spl_500.pickle', 'rb') as f:\n",
    "#     student = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "needed-section",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clip['filepaths'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "enormous-current",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 564,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(zip(teacher['filepaths'], teacher['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "smaller-petroleum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(zip(student['filepaths'], student['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "overall-cocktail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "361\n",
      "0.8356481481481481\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for f, l in list(zip(teacher['filepaths'], teacher['labels'])):\n",
    "    #print(f)\n",
    "    #cls = ' '.join(f.split('/')[-1].split('_')[:-1]).strip()\n",
    "    #cls = class_dict[int(f.split('/')[-2])]\n",
    "    cls = (f.split('/')[-2])\n",
    "    #print(cls)\n",
    "    true_cls = class_dict[int(l)]\n",
    "    #print(cls, true_cls)\n",
    "    if cls == true_cls:\n",
    "        correct += 1\n",
    "    else:\n",
    "        continue\n",
    "        print(cls, true_cls)\n",
    "        \n",
    "print(len(teacher['filepaths']))\n",
    "print(correct)\n",
    "print(correct/len(teacher['filepaths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "quality-operation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432\n",
      "357\n",
      "0.8263888888888888\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for f, l in list(zip(student['filepaths'], student['labels'])):\n",
    "    # cls = ' '.join(f.split('/')[-1].split('_')[:-1]).strip()\n",
    "    # cls = class_dict[int(f.split('/')[-2])]\n",
    "    cls = (f.split('/')[-2])\n",
    "    true_cls = class_dict[int(l)]\n",
    "    if cls == true_cls:\n",
    "        correct += 1\n",
    "    else:\n",
    "        continue\n",
    "        print(cls, true_cls)\n",
    "\n",
    "print(len(student['filepaths']))\n",
    "print(correct)\n",
    "print(correct/len(student['filepaths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "suspended-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "split-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for f, l in list(zip(clip['filepaths'], clip['labels'])):\n",
    "    cls = ' '.join(f.split('/')[-1].split('_')[:-1]).strip()\n",
    "    true_cls = class_dict[int(l)]\n",
    "    if cls == true_cls:\n",
    "        correct += 1\n",
    "    else:\n",
    "        continue\n",
    "        print(cls, true_cls)\n",
    "        \n",
    "print(len(clip['filepaths']))\n",
    "print(correct)\n",
    "print(correct/len(clip['filepaths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "reflected-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "fresh-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "with open(f\"../development/RESICS45/train.json\", \"r\") as f:\n",
    "    datas = json.load(f)\n",
    "    for d in datas[\"categories\"]:\n",
    "        classes.append(d[\"name\"].replace(\"_\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "african-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(data['labels']):\n",
    "    print(classes[i], data['filepaths'][idx].split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-harvey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
