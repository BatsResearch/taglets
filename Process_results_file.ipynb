{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "steady-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ready-warren",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we can add all the methods we have/want\n",
    "models_list = ['clip_baseline',\n",
    "    'coop_baseline', 'coop_pseudo_baseline',\n",
    "    'vpt_baseline', 'vpt_pseudo_baseline', \n",
    "    'teacher_student',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "single-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher_student\n"
     ]
    }
   ],
   "source": [
    "model = models_list[-1]\n",
    "print(model)\n",
    "filename = f\"results/results_model_{model}.json\"\n",
    "\n",
    "data = [json.loads(i) for i in open(filename,'r').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "monetary-lewis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean STD accuracy: 82.76\n",
      "Std STD accuracy: 0.006392898964132173\n",
      "95% STD confidence interval 0.89\n",
      "\n",
      "\n",
      "Mean SEEN accuracy: 75.78\n",
      "Std SEEN accuracy: 0.005193545968350561\n",
      "95% SEEN confidence interval 0.72\n",
      "\n",
      "\n",
      "Mean UNSEEN accuracy: 78.92\n",
      "Std UNSEEN accuracy: 0.008059541466209097\n",
      "95% UNSEEN confidence interval 1.12\n",
      "\n",
      "\n",
      "Mean HARMONIC accuracy: 77.32\n",
      "Std HARMONIC accuracy: 0.004679945524518792\n",
      "95% HARMONIC confidence interval 0.65\n"
     ]
    }
   ],
   "source": [
    "std_accuracies = []\n",
    "gen_accuracies = []\n",
    "seen_accuracies = []\n",
    "unseen_accuracies = []\n",
    "harmonic_accuracies = []\n",
    "\n",
    "fix_num = 0\n",
    "\n",
    "\n",
    "for m in data:\n",
    "    # Here change and filter data depending on what results we want/\n",
    "    # For instance, let's assume we want \n",
    "    if (\n",
    "        (m['config']['DATASET_NAME'] == 'Flowers102')  \\\n",
    "         and (m['config']['VIS_ENCODER'] == 'ViT-B/32') \\\n",
    "         and (m['config']['SPLIT_SEED'] == 500) \\\n",
    "    ):\n",
    "        std_accuracies.append(m['std_accuracy'])\n",
    "        gen_accuracies.append(m['gen_accuracy'])\n",
    "        seen_accuracies.append(m['gen_seen'])\n",
    "        unseen_accuracies.append(m['gen_unseen'])\n",
    "        harmonic_accuracies.append(st.hmean([m['gen_seen'], m['gen_unseen']]))\n",
    "        \n",
    "std_accuracies = std_accuracies[fix_num:]\n",
    "gen_accuracies = gen_accuracies[fix_num:]\n",
    "seen_accuracies = seen_accuracies[fix_num:]\n",
    "unseen_accuracies = unseen_accuracies[fix_num:]\n",
    "harmonic_accuracies = harmonic_accuracies[fix_num:]\n",
    "\n",
    "print(f\"Mean STD accuracy: {round((np.sum(std_accuracies)/len(std_accuracies))*100, 2)}\")\n",
    "print(f\"Std STD accuracy: {np.std(std_accuracies)}\")\n",
    "interval = st.t.interval(alpha=0.95, df=len(std_accuracies)-1, loc=np.mean(std_accuracies), scale=st.sem(std_accuracies)) \n",
    "print(f\"95% STD confidence interval {round((np.sum(std_accuracies)/len(std_accuracies) - interval[0])*100, 2)}\")\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Mean SEEN accuracy: {round((np.sum(seen_accuracies)/len(seen_accuracies))*100, 2)}\")\n",
    "print(f\"Std SEEN accuracy: {np.std(seen_accuracies)}\")\n",
    "interval = st.t.interval(alpha=0.95, df=len(seen_accuracies)-1, loc=np.mean(seen_accuracies), scale=st.sem(seen_accuracies)) \n",
    "print(f\"95% SEEN confidence interval {round((np.sum(seen_accuracies)/len(seen_accuracies) - interval[0])*100, 2)}\")\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Mean UNSEEN accuracy: {round((np.sum(unseen_accuracies)/len(unseen_accuracies))*100,2)}\")\n",
    "print(f\"Std UNSEEN accuracy: {np.std(unseen_accuracies)}\")\n",
    "interval = st.t.interval(alpha=0.95, df=len(unseen_accuracies)-1, loc=np.mean(unseen_accuracies), scale=st.sem(unseen_accuracies)) \n",
    "print(f\"95% UNSEEN confidence interval {round((np.sum(unseen_accuracies)/len(unseen_accuracies) - interval[0])*100,2)}\")\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Mean HARMONIC accuracy: {round((np.sum(harmonic_accuracies)/len(harmonic_accuracies))*100, 2)}\")\n",
    "print(f\"Std HARMONIC accuracy: {np.std(harmonic_accuracies)}\")\n",
    "interval = st.t.interval(alpha=0.95, df=len(harmonic_accuracies)-1, loc=np.mean(harmonic_accuracies), scale=st.sem(harmonic_accuracies)) \n",
    "print(f\"95% HARMONIC confidence interval {round((np.sum(harmonic_accuracies)/len(harmonic_accuracies) - interval[0])*100, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "literary-israeli",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7559820538384845,\n",
       " 0.7619641076769691,\n",
       " 0.7485044865403788,\n",
       " 0.7597208374875374,\n",
       " 0.7627118644067796]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seen_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advanced-nudist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7810014038371549,\n",
       " 0.789424426766495,\n",
       " 0.7903603182030885,\n",
       " 0.8034627983153955,\n",
       " 0.7819372952737482]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "friendly-document",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7682880936356221,\n",
       " 0.7754512368306479,\n",
       " 0.7688631806185371,\n",
       " 0.7809798107472069,\n",
       " 0.7722049354570382]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harmonic_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "valued-coating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8207767898923725,\n",
       " 0.8235844642021526,\n",
       " 0.8296677585400094,\n",
       " 0.8390266729059429,\n",
       " 0.8249883013570426]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-developer",
   "metadata": {},
   "source": [
    "In the google sheets, I report the mean and the confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "forty-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0.906, 0.772, 0.567, 0.8936]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rising-citizenship",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [0.8175, 0.8405, 0.8705, 0.7975]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "entertaining-combat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7984508171723251"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(st.hmean([a, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "respected-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "framed-sheet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'airplane',\n",
       " 1: 'airport',\n",
       " 2: 'baseball diamond',\n",
       " 3: 'basketball court',\n",
       " 4: 'beach',\n",
       " 5: 'bridge',\n",
       " 6: 'chaparral',\n",
       " 7: 'church',\n",
       " 8: 'circular farmland',\n",
       " 9: 'cloud',\n",
       " 10: 'commercial area',\n",
       " 11: 'dense residential',\n",
       " 12: 'desert',\n",
       " 13: 'forest',\n",
       " 14: 'freeway',\n",
       " 15: 'golf course',\n",
       " 16: 'ground track field',\n",
       " 17: 'harbor',\n",
       " 18: 'industrial area',\n",
       " 19: 'intersection',\n",
       " 20: 'island',\n",
       " 21: 'lake',\n",
       " 22: 'meadow',\n",
       " 23: 'medium residential',\n",
       " 24: 'mobile home park',\n",
       " 25: 'mountain',\n",
       " 26: 'overpass',\n",
       " 27: 'palace',\n",
       " 28: 'parking lot',\n",
       " 29: 'railway',\n",
       " 30: 'railway station',\n",
       " 31: 'rectangular farmland',\n",
       " 32: 'river',\n",
       " 33: 'roundabout',\n",
       " 34: 'runway',\n",
       " 35: 'sea ice',\n",
       " 36: 'ship',\n",
       " 37: 'snowberg',\n",
       " 38: 'sparse residential',\n",
       " 39: 'stadium',\n",
       " 40: 'storage tank',\n",
       " 41: 'tennis court',\n",
       " 42: 'terrace',\n",
       " 43: 'thermal power station',\n",
       " 44: 'wetland'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = []\n",
    "with open(f\"pseudolabels/train.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    for d in data[\"categories\"]:\n",
    "        classes.append(d[\"name\"].replace(\"_\", \" \"))\n",
    "\n",
    "# classes = []\n",
    "# with open(f\"pseudolabels/flo_classes.txt\", 'r') as file:\n",
    "#     for l in file:\n",
    "#         classes.append(l.strip())\n",
    "\n",
    "class_dict = {i:c for i,c in enumerate(classes)}\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ongoing-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pseudolabels/RESICS45_ViT-B32_14_pseudolabels_split_500.pickle', 'rb') as f:\n",
    "    clip = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-blackberry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "developing-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pseudolabels/Flowers102_teacher_student_ViT-B32_teacher_iter_1_opt_1_pseudolabels_spl_500_s_epochs_50_before_student.pickle', 'rb') as f:\n",
    "#with open('pseudolabels/DTD_teacher_student_ViT-B32_teacher_iter_3_pseudolabels_spl_500.pickle', 'rb') as f:\n",
    "    teacher_bef = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "working-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pseudolabels/Flowers102_teacher_student_ViT-B32_teacher_iter_1_opt_1_pseudolabels_spl_500_s_epochs_50.pickle', 'rb') as f:\n",
    "    teacher = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "facial-capability",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pseudolabels/Flowers102_teacher_student_ViT-B32_student_iter_0_opt_1_pseudolabels_spl_500_s_epochs_50.pickle', 'rb') as f:\n",
    "    student = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hybrid-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('pseudolabels/Flowers102_ablation_teacher_student_ViT-B32_teacher_iter_2_pseudolabels_spl_500.pickle', 'rb') as f:\n",
    "#     student = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "needed-section",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(zip(teacher_bef['filepaths'], teacher_bef['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "enormous-current",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(zip(teacher['filepaths'], teacher['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "smaller-petroleum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(zip(student['filepaths'], student['labels'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "short-marijuana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((set(teacher['filepaths'])).intersection(set(student['filepaths'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "brutal-faculty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "70\n",
      "0.8974358974358975\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for f, l in list(zip(teacher_bef['filepaths'], teacher_bef['labels'])):\n",
    "    #print(f)\n",
    "    #cls = ' '.join(f.split('/')[-1].split('_')[:-1]).strip()\n",
    "    cls = class_dict[int(f.split('/')[-2])]\n",
    "    #cls = (f.split('/')[-2])\n",
    "    #print(cls)\n",
    "    true_cls = class_dict[int(l)]\n",
    "    #print(cls, true_cls)\n",
    "    if cls == true_cls:\n",
    "        correct += 1\n",
    "    else:\n",
    "        continue\n",
    "        print(cls, true_cls)\n",
    "        \n",
    "print(len(teacher_bef['filepaths']))\n",
    "print(correct)\n",
    "print(correct/len(teacher_bef['filepaths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "overall-cocktail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\n",
      "143\n",
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for f, l in list(zip(teacher['filepaths'], teacher['labels'])):\n",
    "    #print(f)\n",
    "    #cls = ' '.join(f.split('/')[-1].split('_')[:-1]).strip()\n",
    "    cls = class_dict[int(f.split('/')[-2])]\n",
    "    #cls = (f.split('/')[-2])\n",
    "    #print(cls)\n",
    "    true_cls = class_dict[int(l)]\n",
    "    #print(cls, true_cls)\n",
    "    if cls == true_cls:\n",
    "        correct += 1\n",
    "    else:\n",
    "        continue\n",
    "        print(cls, true_cls)\n",
    "        \n",
    "print(len(teacher['filepaths']))\n",
    "print(correct)\n",
    "print(correct/len(teacher['filepaths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "quality-operation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "69\n",
      "0.8846153846153846\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for f, l in list(zip(student['filepaths'], student['labels'])):\n",
    "    # cls = ' '.join(f.split('/')[-1].split('_')[:-1]).strip()\n",
    "    cls = class_dict[int(f.split('/')[-2])]\n",
    "    #cls = (f.split('/')[-2])\n",
    "    true_cls = class_dict[int(l)]\n",
    "    if cls == true_cls:\n",
    "        correct += 1\n",
    "    else:\n",
    "        continue\n",
    "        print(cls, true_cls)\n",
    "\n",
    "print(len(student['filepaths']))\n",
    "print(correct)\n",
    "print(correct/len(student['filepaths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "suspended-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "split-january",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "223\n",
      "0.8849206349206349\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for f, l in list(zip(clip['filepaths'], clip['labels'])):\n",
    "    cls = ' '.join(f.split('/')[-1].split('_')[:-1]).strip()\n",
    "    #cls = class_dict[int(f.split('/')[-2])]\n",
    "    #cls = (f.split('/')[-2])\n",
    "    true_cls = class_dict[int(l)]\n",
    "    if cls == true_cls:\n",
    "        correct += 1\n",
    "    else:\n",
    "        #print(cls, true_cls)\n",
    "        continue\n",
    "        \n",
    "        \n",
    "print(len(clip['filepaths']))\n",
    "print(correct)\n",
    "print(correct/len(clip['filepaths']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "reflected-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "hidden-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.tensor([[0.32, 0.21, 0, 0], [0.32, 0.31, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "needed-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute entropies\n",
    "entropies = Categorical(probs=probabilities).entropy().float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "illegal-skating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6715, 0.6930])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "talented-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entopy distribution and define threshold\n",
    "threshold = torch.quantile(entropies, 0.1, dim=0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "patient-final",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6736088395118713"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "better-wallace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "certain_samples = torch.where(entropies <= threshold)[0]\n",
    "certain_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "radio-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertain_samples = torch.where(entropies > threshold)[0]\n",
    "uncertain_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-harvey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute entropies\n",
    "entropies = Categorical(probs=probabilities).entropy().float()\n",
    "\n",
    "# Get entopy distribution and define threshold\n",
    "threshold = torch.quantile(entropies, quantile, dim=0).item()\n",
    "#print(f\"Entropy threshold: {threshold}\")\n",
    "\n",
    "# Get set of certain and uncertain predictions\n",
    "certain_samples = torch.where(entropies <= threshold)[0]\n",
    "uncertain_samples = torch.where(entropies > threshold)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "formal-gospel",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 5)\n",
    "y = torch.randn(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dental-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_x = torch.argsort(x, descending=True)\n",
    "sort_y = torch.argsort(y, descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "guided-arbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 5\n",
      "x_k: 5\n",
      "x_d: 1\n",
      "a_d: 1.0\n",
      "x_d: 1\n",
      "a_d: 0.5\n",
      "x_d: 2\n",
      "a_d: 0.6666666666666666\n",
      "x_d: 3\n",
      "a_d: 0.75\n",
      "x_d: 5\n",
      "a_d: 1.0\n",
      "k: 5\n",
      "x_k: 5\n",
      "x_d: 1\n",
      "a_d: 1.0\n",
      "x_d: 2\n",
      "a_d: 1.0\n",
      "x_d: 2\n",
      "a_d: 0.6666666666666666\n",
      "x_d: 4\n",
      "a_d: 1.0\n",
      "x_d: 5\n",
      "a_d: 1.0\n"
     ]
    }
   ],
   "source": [
    "rank_list = []\n",
    "for i in range(sort_x.size()[0]):\n",
    "    l_S = sort_x[i]\n",
    "    l_U = sort_y[i]\n",
    "    rank_list.append(1 - i_rank_biased_overlap(l_S, l_U, p=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "passing-chinese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1172)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.tensor(rank_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "single-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "preliminary-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i_rank_biased_overlap([c.item() for c in l_S], [c.item() for c in l_U], p=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "compound-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def i_rank_biased_overlap(S,T, p=0.9):\n",
    "#     \"\"\" Takes two lists S and T of any lengths and gives out the RBO Score\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     S, T : Lists (str, integers)\n",
    "#     p : Weight parameter, giving the influence of the first d\n",
    "#         elements on the final score. p<0<1. Default 0.9 give the top 10 \n",
    "#         elements 86% of the contribution in the final score.\n",
    "    \n",
    "#     Returns\n",
    "#     -------\n",
    "#     Float of RBO score\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Fixed Terms\n",
    "#     k = max(len(S), len(T))\n",
    "#     print(f\"k: {k}\")\n",
    "#     x_k = len(set(S).intersection(set(T)))\n",
    "#     print(f\"x_k: {x_k}\")\n",
    "    \n",
    "#     summation_term = 0\n",
    "\n",
    "#     # Loop for summation\n",
    "#     # k+1 for the loop to reach the last element (at k) in the bigger list    \n",
    "#     for d in range (1, k+1): \n",
    "#             # Create sets from the lists\n",
    "#             set1 = set(S[:d]) if d < len(S) else set(S)\n",
    "#             set2 = set(T[:d]) if d < len(T) else set(T)\n",
    "            \n",
    "#             # Intersection at depth d\n",
    "#             x_d = len(set1.intersection(set2))\n",
    "#             print(f\"x_d: {x_d}\")\n",
    "#             # Agreement at depth d\n",
    "#             a_d = x_d/d   \n",
    "#             print(f\"a_d: {a_d}\")\n",
    "#             # Summation\n",
    "#             summation_term = summation_term + math.pow(p, d) * a_d\n",
    "\n",
    "#     # Rank Biased Overlap - extrapolated\n",
    "#     rbo_ext = (x_k/k) * math.pow(p, k) + ((1-p)/p * summation_term)\n",
    "\n",
    "#     return rbo_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "dressed-department",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 5\n",
      "x_k: 5\n",
      "x_d: 1\n",
      "a_d: 1.0\n",
      "x_d: 2\n",
      "a_d: 1.0\n",
      "x_d: 2\n",
      "a_d: 0.6666666666666666\n",
      "x_d: 4\n",
      "a_d: 1.0\n",
      "x_d: 5\n",
      "a_d: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9730)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "creative-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_rank_biased_overlap(S, T, p=0.9):\n",
    "    \"\"\" Takes two lists S and T of any lengths and gives out the RBO Score\n",
    "    Parameters\n",
    "    ----------\n",
    "    S, T : Lists (str, integers)\n",
    "    p : Weight parameter, giving the influence of the first d\n",
    "        elements on the final score. p<0<1. Default 0.9 give the top 10 \n",
    "        elements 86% of the contribution in the final score.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Float of RBO score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Fixed Terms\n",
    "    k = torch.max(torch.tensor([S.size(), T.size()]))\n",
    "    print(f\"k: {k}\")\n",
    "    x_k = (S[(S.view(1, -1) == T.view(-1, 1)).any(dim=0)]).size()[0]\n",
    "    #x_k = len(set(S).intersection(set(T)))\n",
    "    print(f\"x_k: {x_k}\")\n",
    "    \n",
    "    summation_term = 0\n",
    "\n",
    "    # Loop for summation\n",
    "    # k+1 for the loop to reach the last element (at k) in the bigger list    \n",
    "    for d in range (1, k+1): \n",
    "        # Create sets from the lists\n",
    "        set1 = S[:d] if d < S.size()[0] else S\n",
    "        set2 = T[:d] if d < T.size()[0] else T\n",
    "\n",
    "        # Intersection at depth d\n",
    "        #x_d = len(set1.intersection(set2))\n",
    "        x_d = (set1[(set1.view(1, -1) == set2.view(-1, 1)).any(dim=0)]).size()[0]\n",
    "        print(f\"x_d: {x_d}\")\n",
    "        # Agreement at depth d\n",
    "        a_d = x_d/d  \n",
    "        print(f\"a_d: {a_d}\")\n",
    "\n",
    "        # Summation\n",
    "        summation_term = summation_term + math.pow(p, d) * a_d\n",
    "\n",
    "    # Rank Biased Overlap - extrapolated\n",
    "    rbo_ext = (x_k/k) * math.pow(p, k) + ((1-p)/p * summation_term)\n",
    "\n",
    "    return rbo_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "controlled-making",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6735,  0.9478, -0.2213,  1.6973, -1.2357],\n",
       "        [-0.2100,  0.2180,  0.9389,  1.1782, -0.1748]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "characteristic-refrigerator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x, y], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "american-awareness",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'vmap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-048dd73ea137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbatched_pow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbatched_pow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [5, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'vmap'"
     ]
    }
   ],
   "source": [
    "f = lambda x: x ** 2\n",
    "x = torch.randn(2, 5)\n",
    "batched_pow = torch.vmap(f, out_dims=1)\n",
    "batched_pow(x) # [5, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-curve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
