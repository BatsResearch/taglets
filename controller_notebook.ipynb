{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from JPL_interface import JPL\n",
    "from modules.module import TransferModule\n",
    "from modules.active_learning import RandomActiveLearning, LeastConfidenceActiveLearning\n",
    "from taglets.taglet_executer import TagletExecutor\n",
    "from task import Task\n",
    "from label_model import get_label_distribution\n",
    "from custom_dataset import CustomDataSet, SoftLabelDataSet\n",
    "import torch\n",
    "from taglets.end_model import EndModel\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task():\n",
    "    task_names = api.get_available_tasks()\n",
    "    task_name = task_names[0]  # Image classification task\n",
    "    api.create_session(task_name)\n",
    "    task_metadata = api.get_task_metadata(task_name)\n",
    "\n",
    "    num_base_checkpoints = len(task_metadata['base_label_budget'])\n",
    "    num_adapt_checkpoints = len(task_metadata['adaptation_label_budget'])\n",
    "\n",
    "    task = Task(task_name, task_metadata)\n",
    "    session_status = api.get_session_status()\n",
    "    current_dataset = session_status['current_dataset']\n",
    "    task.classes = current_dataset['classes']\n",
    "    task.number_of_channels = current_dataset['number_of_channels']\n",
    "    task.dataset_name = current_dataset['name']\n",
    "\n",
    "    task.unlabeled_image_path = \"/data/bats/datasets/lwll/lwll_datasets/mnist/mnist_sample/train\"\n",
    "    task.evaluation_image_path = \"/data/bats/datasets/lwll/lwll_datasets/mnist/mnist_sample/test\"  # Should be updated later\n",
    "\n",
    "    # task.unlabeled_image_path = \"./sql_data/MNIST/train\"\n",
    "    # task.evaluation_image_path = \"./sql_data/MNIST/test\"  # Should be updated later\n",
    "    task.phase = session_status['pair_stage']\n",
    "    if session_status['pair_stage'] == 'adaptation':\n",
    "        task.labeled_images = []\n",
    "        task.pretrained = task_metadata['adaptation_can_use_pretrained_model']\n",
    "    elif session_status['pair_stage'] == 'base':\n",
    "        task.labeled_images = api.get_seed_labels()\n",
    "        task.pretrained = task_metadata['base_can_use_pretrained_model']\n",
    "    return task, num_base_checkpoints, num_adapt_checkpoints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = JPL()\n",
    "task, num_base_checkpoints, num_adapt_checkpoints = get_task()\n",
    "random_active_learning = RandomActiveLearning()\n",
    "confidence_active_learning = LeastConfidenceActiveLearning()\n",
    "taglet_executor = TagletExecutor()\n",
    "end_model = EndModel(task)\n",
    "# task.get_related_concepts()\n",
    "batch_size = 32\n",
    "num_workers = 2\n",
    "use_gpu = False\n",
    "testing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_checkpoints():\n",
    "    run_checkpoints_base()\n",
    "    run_checkpoints_adapt()\n",
    "\n",
    "def run_checkpoints_base():\n",
    "    update_task()\n",
    "    for i in range(num_base_checkpoints):\n",
    "        run_one_checkpoint(i)\n",
    "\n",
    "def run_one_checkpoint( checkpoint_num):\n",
    "    session_status = api.get_session_status()\n",
    "    assert session_status['pair_stage'] == 'base'\n",
    "    print('------------------------------------------------------------')\n",
    "    print('--------------------base check point: {}'.format(checkpoint_num)+'---------------------')\n",
    "    print('------------------------------------------------------------')\n",
    "\n",
    "    available_budget = get_available_budget()\n",
    "    unlabeled_image_names = task.get_unlabeled_image_names()\n",
    "    print('number of unlabeled data: {}'.format(len(unlabeled_image_names)))\n",
    "    if checkpoint_num == 0:\n",
    "        candidates = random_active_learning.find_candidates(available_budget, unlabeled_image_names)\n",
    "    else:\n",
    "        candidates = confidence_active_learning.find_candidates(available_budget, unlabeled_image_names)\n",
    "    request_labels(candidates)\n",
    "    predictions = get_predictions(session_status['pair_stage'])\n",
    "    submit_predictions(predictions)\n",
    "\n",
    "def run_checkpoints_adapt():\n",
    "    update_task()\n",
    "    print()\n",
    "    for i in range(num_adapt_checkpoints):\n",
    "        session_status = api.get_session_status()\n",
    "        # assert session_status['pair_stage'] == 'adaptation'\n",
    "        print('------------------------------------------------------------')\n",
    "        print('--------------------Adapt check point: {}'.format(i)+'---------------------')\n",
    "        print('------------------------------------------------------------')\n",
    "\n",
    "        available_budget = get_available_budget()\n",
    "        unlabeled_image_names = task.get_unlabeled_image_names()\n",
    "        print('number of unlabeled data: {}'.format(len(unlabeled_image_names)))\n",
    "        if i == 0:\n",
    "            candidates = random_active_learning.find_candidates(available_budget, unlabeled_image_names)\n",
    "        else:\n",
    "            candidates = confidence_active_learning.find_candidates(available_budget, unlabeled_image_names)\n",
    "        request_labels(candidates)\n",
    "        predictions = get_predictions(session_status['pair_stage'])\n",
    "        submit_predictions(predictions)\n",
    "\n",
    "def get_task():\n",
    "    task_names = api.get_available_tasks()\n",
    "    task_name = task_names[0]  # Image classification task\n",
    "    api.create_session(task_name)\n",
    "    task_metadata = api.get_task_metadata(task_name)\n",
    "\n",
    "    num_base_checkpoints = len(task_metadata['base_label_budget'])\n",
    "    num_adapt_checkpoints = len(task_metadata['adaptation_label_budget'])\n",
    "\n",
    "    task = Task(task_name, task_metadata)\n",
    "    session_status = api.get_session_status()\n",
    "    current_dataset = session_status['current_dataset']\n",
    "    task.classes = current_dataset['classes']\n",
    "    task.number_of_channels = current_dataset['number_of_channels']\n",
    "    task.dataset_name = current_dataset['name']\n",
    "\n",
    "#     task.unlabeled_image_path = \"/data/bats/datasets/lwll/lwll_datasets/mnist/mnist_sample/train\"\n",
    "#     task.evaluation_image_path = \"/data/bats/datasets/lwll/lwll_datasets/mnist/mnist_sample/test\"  # Should be updated later\n",
    "\n",
    "    task.unlabeled_image_path = \"./sql_data/MNIST/train\"\n",
    "    task.evaluation_image_path = \"./sql_data/MNIST/test\"  # Should be updated later\n",
    "    task.phase = session_status['pair_stage']\n",
    "    if session_status['pair_stage'] == 'adaptation':\n",
    "        task.labeled_images = []\n",
    "        task.pretrained = task_metadata['adaptation_can_use_pretrained_model']\n",
    "    elif session_status['pair_stage'] == 'base':\n",
    "        task.labeled_images = api.get_seed_labels()\n",
    "        task.pretrained = task_metadata['base_can_use_pretrained_model']\n",
    "    return task, num_base_checkpoints, num_adapt_checkpoints\n",
    "\n",
    "def update_task():\n",
    "    task_metadata = api.get_task_metadata(task.name)\n",
    "    session_status = api.get_session_status()\n",
    "    current_dataset = session_status['current_dataset']\n",
    "    task.classes = current_dataset['classes']\n",
    "    task.number_of_channels = current_dataset['number_of_channels']\n",
    "    task.dataset_name = current_dataset['name']\n",
    "\n",
    "#     task.unlabeled_image_path = \"/data/bats/datasets/lwll/lwll_datasets/mnist/mnist_sample/train\"\n",
    "#     task.evaluation_image_path = \"/data/bats/datasets/lwll/lwll_datasets/mnist/mnist_sample/test\"  # Should be updated later\n",
    "\n",
    "    task.unlabeled_image_path = \"./sql_data/MNIST/train\"\n",
    "    task.evaluation_image_path = \"./sql_data/MNIST/test\"  # Should be updated later\n",
    "    task.phase = session_status['pair_stage']\n",
    "    if session_status['pair_stage'] == 'adaptation':\n",
    "        task.labeled_images = []\n",
    "        task.pretrained = task_metadata['adaptation_can_use_pretrained_model']\n",
    "    elif session_status['pair_stage'] == 'base':\n",
    "        task.labeled_images = api.get_seed_labels()\n",
    "        task.pretrained = task_metadata['base_can_use_pretrained_model']\n",
    "\n",
    "def get_available_budget():\n",
    "    session_status = api.get_session_status()\n",
    "    available_budget = session_status['budget_left_until_checkpoint']\n",
    "\n",
    "    if testing:\n",
    "        available_budget = available_budget // 10\n",
    "    return available_budget\n",
    "\n",
    "def request_labels( examples):\n",
    "    query = {'example_ids': examples}\n",
    "    labeled_images = api.request_label(query)\n",
    "    task.add_labeled_images(labeled_images)\n",
    "    print(\"New labeled images:\", len(labeled_images))\n",
    "    print(\"Total labeled images:\", len(task.labeled_images))\n",
    "\n",
    "def combine_soft_labels( unlabeled_labels, unlabeled_names, train_image_names, train_image_labels):\n",
    "    def to_soft_one_hot(l):\n",
    "        soh = [0.15] * len(task.classes)\n",
    "        soh[l] = 0.85\n",
    "        return soh\n",
    "\n",
    "    soft_labels_labeled_images = []\n",
    "    for image_label in train_image_labels:\n",
    "        soft_labels_labeled_images.append(to_soft_one_hot(int(image_label)))\n",
    "\n",
    "    all_soft_labels = np.concatenate((unlabeled_labels, np.array(soft_labels_labeled_images)), axis=0)\n",
    "    all_names = unlabeled_names + train_image_names\n",
    "\n",
    "    end_model_train_data = SoftLabelDataSet(task.unlabeled_image_path,\n",
    "                                      all_names,\n",
    "                                      all_soft_labels,\n",
    "                                      task.transform_image(),\n",
    "                                      task.number_of_channels)\n",
    "\n",
    "    train_data = torch.utils.data.DataLoader(end_model_train_data,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=True,\n",
    "                                       num_workers=num_workers)\n",
    "\n",
    "    return train_data\n",
    "\n",
    "def get_predictions( phase):\n",
    "    \"\"\"train taglets, label model, and endmodel, and return prediction\n",
    "    :param phase: 'base' or 'adapt'\n",
    "    \"\"\"\n",
    "    train_data_loader, val_data_loader,  train_image_names, train_image_labels = task.load_labeled_data(\n",
    "        batch_size,\n",
    "        num_workers)\n",
    "\n",
    "    unlabeled_data_loader, unlabeled_image_names = task.load_unlabeled_data(batch_size,\n",
    "                                                                                 num_workers)\n",
    "\n",
    "    mnist_module = TransferModule(task=task)\n",
    "\n",
    "    print(\"**********Training taglets on labeled data**********\")\n",
    "    t1 = datetime.datetime.now()\n",
    "    mnist_module.train_taglets(train_data_loader, val_data_loader, use_gpu, phase, testing)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print()\n",
    "    print(\".....Taglet training time: {}\".format((t2 - t1).seconds))\n",
    "\n",
    "    taglets = mnist_module.get_taglets()\n",
    "    taglet_executor.set_taglets(taglets)\n",
    "\n",
    "    print(\"**********Executing taglets on unlabled data**********\")\n",
    "    t1 = datetime.datetime.now()\n",
    "    label_matrix, candidates = taglet_executor.execute(unlabeled_data_loader, use_gpu, testing)\n",
    "    confidence_active_learning.set_candidates(candidates)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print()\n",
    "    print(\".....Taglet executing time: {}\".format((t2 - t1).seconds))\n",
    "\n",
    "\n",
    "    print(\"**********Label Model**********\")\n",
    "    t1 = datetime.datetime.now()\n",
    "    soft_labels_unlabeled_images = get_label_distribution(label_matrix, len(task.classes), testing)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print()\n",
    "    print(\".....Label Model time: {}\".format((t2 - t1).seconds))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"**********End Model**********\")\n",
    "    t1 = datetime.datetime.now()\n",
    "    if testing:\n",
    "        unlabeled_image_names = unlabeled_image_names[:len(soft_labels_unlabeled_images)]\n",
    "    end_model_train_data_loader = combine_soft_labels(soft_labels_unlabeled_images,\n",
    "                                                     unlabeled_image_names,\n",
    "                                                     train_image_names, train_image_labels)\n",
    "    end_model.train(end_model_train_data_loader, val_data_loader, use_gpu, testing)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print()\n",
    "    print(\".....End Model time: {}\".format((t2 - t1).seconds))\n",
    "\n",
    "    return end_model.predict(task.evaluation_image_path,\n",
    "                                  task.number_of_channels,\n",
    "                                  task.transform_image(),\n",
    "                                  use_gpu)\n",
    "\n",
    "def submit_predictions( predictions):\n",
    "    submit_status = api.submit_prediction(predictions)\n",
    "    session_status = api.get_session_status()\n",
    "    print(\"Checkpoint scores\", session_status['checkpoint_scores'])\n",
    "    print(\"Phase:\", session_status['pair_stage'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "--------------------base check point: 0---------------------\n",
      "------------------------------------------------------------\n",
      "number of unlabeled data: 4990\n",
      "New labeled images: 300\n",
      "Total labeled images: 310\n",
      "number of training data: 248\n",
      "number of validation data: 62\n",
      "**********Training taglets on labeled data**********\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0097\n",
      "validation loss: 0.0745\n",
      "validation acc: 8.0645%\n",
      "Deep copying new best model.(validation of 0.0806%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0097\n",
      "Average validation loss: 0.0745\n",
      "Average validation accuracy: 8.0645%\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0097\n",
      "validation loss: 0.0745\n",
      "validation acc: 8.0645%\n",
      "Deep copying new best model.(validation of 0.0806%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0097\n",
      "Average validation loss: 0.0745\n",
      "Average validation accuracy: 8.0645%\n",
      "...........finetune...........\n",
      "epoch: 0\n",
      "train loss: 0.0107\n",
      "train acc: 1.2097%\n",
      "validation loss: 0.0749\n",
      "validation acc: 4.8387%\n",
      "Deep copying new best model.(validation of 0.0484%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0107\n",
      "Average training accuracy: 1.2097%\n",
      "Average validation loss: 0.0749\n",
      "Average validation accuracy: 4.8387%\n",
      "\n",
      ".....Taglet training time: 3\n",
      "**********Executing taglets on unlabled data**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elahehraisi/Desktop/Postdoc/code/taglets/taglets/taglet.py:282: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  candidate_probabilities.append(torch.max(torch.nn.functional.softmax(outputs)).item())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ".....Taglet executing time: 1\n",
      "**********Label Model**********\n",
      "\n",
      ".....Label Model time: 0\n",
      "**********End Model**********\n",
      "...........end model...........\n",
      "epoch: 0\n",
      "train loss: 0.0180\n",
      "train acc: 1.0714%\n",
      "validation loss: 0.0769\n",
      "validation acc: 3.2258%\n",
      "Deep copying new best model.(validation of 0.0323%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0180\n",
      "Average training accuracy: 1.0714%\n",
      "Average validation loss: 0.0769\n",
      "Average validation accuracy: 3.2258%\n",
      "\n",
      ".....End Model time: 1\n",
      "Checkpoint scores [{'accuracy': 0.047}]\n",
      "Phase: base\n",
      "------------------------------------------------------------\n",
      "--------------------base check point: 1---------------------\n",
      "------------------------------------------------------------\n",
      "number of unlabeled data: 4690\n",
      "New labeled images: 32\n",
      "Total labeled images: 342\n",
      "number of training data: 273\n",
      "number of validation data: 69\n",
      "**********Training taglets on labeled data**********\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0088\n",
      "validation loss: 0.0669\n",
      "validation acc: 11.5942%\n",
      "Deep copying new best model.(validation of 0.1159%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0088\n",
      "Average validation loss: 0.0669\n",
      "Average validation accuracy: 11.5942%\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0088\n",
      "validation loss: 0.0669\n",
      "validation acc: 11.5942%\n",
      "Deep copying new best model.(validation of 0.1159%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0088\n",
      "Average validation loss: 0.0669\n",
      "Average validation accuracy: 11.5942%\n",
      "...........finetune...........\n",
      "epoch: 0\n",
      "train loss: 0.0099\n",
      "train acc: 0.3663%\n",
      "validation loss: 0.0679\n",
      "validation acc: 4.3478%\n",
      "Deep copying new best model.(validation of 0.0435%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0099\n",
      "Average training accuracy: 0.3663%\n",
      "Average validation loss: 0.0679\n",
      "Average validation accuracy: 4.3478%\n",
      "\n",
      ".....Taglet training time: 2\n",
      "**********Executing taglets on unlabled data**********\n",
      "\n",
      ".....Taglet executing time: 1\n",
      "**********Label Model**********\n",
      "\n",
      ".....Label Model time: 0\n",
      "**********End Model**********\n",
      "...........end model...........\n",
      "epoch: 0\n",
      "train loss: 0.0163\n",
      "train acc: 4.9180%\n",
      "validation loss: 0.0670\n",
      "validation acc: 10.1449%\n",
      "Deep copying new best model.(validation of 0.1014%, over 0.0323%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0163\n",
      "Average training accuracy: 4.9180%\n",
      "Average validation loss: 0.0670\n",
      "Average validation accuracy: 10.1449%\n",
      "\n",
      ".....End Model time: 1\n",
      "Checkpoint scores [{'accuracy': 0.047}, {'accuracy': 0.12}]\n",
      "Phase: base\n",
      "------------------------------------------------------------\n",
      "--------------------base check point: 2---------------------\n",
      "------------------------------------------------------------\n",
      "number of unlabeled data: 4658\n",
      "New labeled images: 32\n",
      "Total labeled images: 374\n",
      "number of training data: 299\n",
      "number of validation data: 75\n",
      "**********Training taglets on labeled data**********\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0080\n",
      "validation loss: 0.0614\n",
      "validation acc: 12.0000%\n",
      "Deep copying new best model.(validation of 0.1200%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0080\n",
      "Average validation loss: 0.0614\n",
      "Average validation accuracy: 12.0000%\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0080\n",
      "validation loss: 0.0614\n",
      "validation acc: 12.0000%\n",
      "Deep copying new best model.(validation of 0.1200%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0080\n",
      "Average validation loss: 0.0614\n",
      "Average validation accuracy: 12.0000%\n",
      "...........finetune...........\n",
      "epoch: 0\n",
      "train loss: 0.0090\n",
      "train acc: 1.0033%\n",
      "validation loss: 0.0611\n",
      "validation acc: 4.0000%\n",
      "Deep copying new best model.(validation of 0.0400%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0090\n",
      "Average training accuracy: 1.0033%\n",
      "Average validation loss: 0.0611\n",
      "Average validation accuracy: 4.0000%\n",
      "\n",
      ".....Taglet training time: 2\n",
      "**********Executing taglets on unlabled data**********\n",
      "\n",
      ".....Taglet executing time: 1\n",
      "**********Label Model**********\n",
      "\n",
      ".....Label Model time: 0\n",
      "**********End Model**********\n",
      "...........end model...........\n",
      "epoch: 0\n",
      "train loss: 0.0157\n",
      "train acc: 3.9275%\n",
      "validation loss: 0.0602\n",
      "validation acc: 14.6667%\n",
      "Deep copying new best model.(validation of 0.1467%, over 0.1014%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0157\n",
      "Average training accuracy: 3.9275%\n",
      "Average validation loss: 0.0602\n",
      "Average validation accuracy: 14.6667%\n",
      "\n",
      ".....End Model time: 1\n",
      "Checkpoint scores [{'accuracy': 0.047}, {'accuracy': 0.12}, {'accuracy': 0.181}]\n",
      "Phase: adaptation\n",
      "\n",
      "------------------------------------------------------------\n",
      "--------------------Adapt check point: 0---------------------\n",
      "------------------------------------------------------------\n",
      "number of unlabeled data: 5000\n",
      "New labeled images: 100\n",
      "Total labeled images: 100\n",
      "number of training data: 80\n",
      "number of validation data: 20\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "**********Training taglets on labeled data**********\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0310\n",
      "validation loss: 0.1157\n",
      "validation acc: 5.0000%\n",
      "Deep copying new best model.(validation of 0.0500%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0310\n",
      "Average validation loss: 0.1157\n",
      "Average validation accuracy: 5.0000%\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0310\n",
      "validation loss: 0.1157\n",
      "validation acc: 5.0000%\n",
      "Deep copying new best model.(validation of 0.0500%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0310\n",
      "Average validation loss: 0.1157\n",
      "Average validation accuracy: 5.0000%\n",
      "...........finetune...........\n",
      "epoch: 0\n",
      "train loss: 0.0273\n",
      "train acc: 8.7500%\n",
      "validation loss: 0.1140\n",
      "validation acc: 15.0000%\n",
      "Deep copying new best model.(validation of 0.1500%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0273\n",
      "Average training accuracy: 8.7500%\n",
      "Average validation loss: 0.1140\n",
      "Average validation accuracy: 15.0000%\n",
      "\n",
      ".....Taglet training time: 2\n",
      "**********Executing taglets on unlabled data**********\n",
      "\n",
      ".....Taglet executing time: 2\n",
      "**********Label Model**********\n",
      "\n",
      ".....Label Model time: 0\n",
      "**********End Model**********\n",
      "...........end model...........\n",
      "epoch: 0\n",
      "train loss: 0.0366\n",
      "train acc: 6.2500%\n",
      "validation loss: 0.1142\n",
      "validation acc: 15.0000%\n",
      "Deep copying new best model.(validation of 0.1500%, over 0.1467%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0366\n",
      "Average training accuracy: 6.2500%\n",
      "Average validation loss: 0.1142\n",
      "Average validation accuracy: 15.0000%\n",
      "\n",
      ".....End Model time: 1\n",
      "Checkpoint scores [{'accuracy': 0.047}, {'accuracy': 0.12}, {'accuracy': 0.181}, {'accuracy': 0.133}]\n",
      "Phase: adaptation\n",
      "------------------------------------------------------------\n",
      "--------------------Adapt check point: 1---------------------\n",
      "------------------------------------------------------------\n",
      "number of unlabeled data: 4900\n",
      "New labeled images: 32\n",
      "Total labeled images: 132\n",
      "number of training data: 105\n",
      "number of validation data: 27\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "**********Training taglets on labeled data**********\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0226\n",
      "validation loss: 0.0858\n",
      "validation acc: 3.7037%\n",
      "Deep copying new best model.(validation of 0.0370%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0226\n",
      "Average validation loss: 0.0858\n",
      "Average validation accuracy: 3.7037%\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0226\n",
      "validation loss: 0.0858\n",
      "validation acc: 3.7037%\n",
      "Deep copying new best model.(validation of 0.0370%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0226\n",
      "Average validation loss: 0.0858\n",
      "Average validation accuracy: 3.7037%\n",
      "...........finetune...........\n",
      "epoch: 0\n",
      "train loss: 0.0188\n",
      "train acc: 10.4762%\n",
      "validation loss: 0.0839\n",
      "validation acc: 11.1111%\n",
      "Deep copying new best model.(validation of 0.1111%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0188\n",
      "Average training accuracy: 10.4762%\n",
      "Average validation loss: 0.0839\n",
      "Average validation accuracy: 11.1111%\n",
      "\n",
      ".....Taglet training time: 2\n",
      "**********Executing taglets on unlabled data**********\n",
      "\n",
      ".....Taglet executing time: 1\n",
      "**********Label Model**********\n",
      "\n",
      ".....Label Model time: 0\n",
      "**********End Model**********\n",
      "...........end model...........\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.0375\n",
      "train acc: 5.1095%\n",
      "validation loss: 0.0838\n",
      "validation acc: 14.8148%\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0375\n",
      "Average training accuracy: 5.1095%\n",
      "Average validation loss: 0.0838\n",
      "Average validation accuracy: 14.8148%\n",
      "\n",
      ".....End Model time: 1\n",
      "Checkpoint scores [{'accuracy': 0.047}, {'accuracy': 0.12}, {'accuracy': 0.181}, {'accuracy': 0.133}, {'accuracy': 0.183}]\n",
      "Phase: adaptation\n",
      "------------------------------------------------------------\n",
      "--------------------Adapt check point: 2---------------------\n",
      "------------------------------------------------------------\n",
      "number of unlabeled data: 4868\n",
      "New labeled images: 32\n",
      "Total labeled images: 164\n",
      "number of training data: 131\n",
      "number of validation data: 33\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "^^^^^^^^^ adaptation: loading from base\n",
      "**********Training taglets on labeled data**********\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0185\n",
      "validation loss: 0.1401\n",
      "validation acc: 3.0303%\n",
      "Deep copying new best model.(validation of 0.0303%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0185\n",
      "Average validation loss: 0.1401\n",
      "Average validation accuracy: 3.0303%\n",
      "...........prototype...........\n",
      "epoch: 0\n",
      "train loss: 0.0185\n",
      "validation loss: 0.1401\n",
      "validation acc: 3.0303%\n",
      "Deep copying new best model.(validation of 0.0303%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0185\n",
      "Average validation loss: 0.1401\n",
      "Average validation accuracy: 3.0303%\n",
      "...........finetune...........\n",
      "epoch: 0\n",
      "train loss: 0.0118\n",
      "train acc: 12.9771%\n",
      "validation loss: 0.1484\n",
      "validation acc: 9.0909%\n",
      "Deep copying new best model.(validation of 0.0909%, over 0.0000%)\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0118\n",
      "Average training accuracy: 12.9771%\n",
      "Average validation loss: 0.1484\n",
      "Average validation accuracy: 9.0909%\n",
      "\n",
      ".....Taglet training time: 2\n",
      "**********Executing taglets on unlabled data**********\n",
      "\n",
      ".....Taglet executing time: 1\n",
      "**********Label Model**********\n",
      "\n",
      ".....Label Model time: 0\n",
      "**********End Model**********\n",
      "...........end model...........\n",
      "epoch: 0\n",
      "train loss: 0.0314\n",
      "train acc: 7.9755%\n",
      "validation loss: 0.1369\n",
      "validation acc: 3.0303%\n",
      "Epoch 1 result: \n",
      "Average training loss: 0.0314\n",
      "Average training accuracy: 7.9755%\n",
      "Average validation loss: 0.1369\n",
      "Average validation accuracy: 3.0303%\n",
      "\n",
      ".....End Model time: 1\n",
      "Checkpoint scores [{'accuracy': 0.047}, {'accuracy': 0.12}, {'accuracy': 0.181}, {'accuracy': 0.133}, {'accuracy': 0.183}, {'accuracy': 0.12}]\n",
      "Phase: adaptation\n"
     ]
    }
   ],
   "source": [
    "run_checkpoints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
