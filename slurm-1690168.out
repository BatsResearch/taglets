## SLURM PROLOG ###############################################################
##    Job ID : 1690168
##  Job Name : run_taglets-ps.sh
##  Nodelist : gpu1404
##      CPUs : 1
##  Mem/Node : 65536 MB
## Directory : /gpfs/data/sbach/bats/projects/taglets-project/taglets-pseudoshots
##   Started : Tue Jul  6 10:46:23 EDT 2021
###############################################################################
module: loading 'cuda/9.2.148'
module: unloading 'python/2.7.12'
module: loading 'python/3.7.4'
/users/rbriden/data/rbriden/anaconda3/lib/python3.8/site-packages/torch/distributed/launch.py:163: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead
  logger.warn(
The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : ./run_jpl.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 2
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_m53k3il1/none_cv24eeln
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/users/rbriden/data/rbriden/anaconda3/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1]
  role_ranks=[0, 1]
  global_ranks=[0, 1]
  role_world_sizes=[2, 2]
  global_world_sizes=[2, 2]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_m53k3il1/none_cv24eeln/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_m53k3il1/none_cv24eeln/attempt_0/1/error.json
Traceback (most recent call last):
  File "./run_jpl.py", line 1, in <module>
    import taglets.task.jpl as jpl
  File "/gpfs/data/sbach/bats/projects/taglets-project/taglets-pseudoshots/taglets/__init__.py", line 1, in <module>
Traceback (most recent call last):
  File "./run_jpl.py", line 1, in <module>
    from .controller import Controller
  File "/gpfs/data/sbach/bats/projects/taglets-project/taglets-pseudoshots/taglets/controller.py", line 44, in <module>
    import taglets.task.jpl as jpl
      File "/gpfs/data/sbach/bats/projects/taglets-project/taglets-pseudoshots/taglets/__init__.py", line 1, in <module>
import logger
ModuleNotFoundError: No module named 'logger'
    from .controller import Controller
  File "/gpfs/data/sbach/bats/projects/taglets-project/taglets-pseudoshots/taglets/controller.py", line 44, in <module>
    import logger
ModuleNotFoundError: No module named 'logger'
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 19559) of binary: /users/rbriden/data/rbriden/anaconda3/bin/python
ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed
INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 3/3 attempts left; will restart worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=1
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1]
  role_ranks=[0, 1]
  global_ranks=[0, 1]
  role_world_sizes=[2, 2]
  global_world_sizes=[2, 2]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_m53k3il1/none_cv24eeln/attempt_1/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_m53k3il1/none_cv24eeln/attempt_1/1/error.json
slurmstepd: error: *** JOB 1690168 ON gpu1404 CANCELLED AT 2021-07-06T10:58:17 ***
